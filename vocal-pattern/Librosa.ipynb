{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import pickle # to save model after training\n",
    "from sklearn.model_selection import train_test_split # for splitting training and testing\n",
    "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
    "from sklearn.metrics import accuracy_score # to measure how good we are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all emotions on RAVDESS dataset\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# we allow only these emotions ( feel free to tune this on your need )\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X, y = [], []\n",
    "    for file in glob.glob(\"data/Actor_*/*.wav\"):\n",
    "        # get the base name of the audio file\n",
    "        basename = os.path.basename(file)\n",
    "        # get the emotion label\n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        # we allow only AVAILABLE_EMOTIONS we set\n",
    "        if emotion not in AVAILABLE_EMOTIONS:\n",
    "            continue\n",
    "        # extract speech features\n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        # add to data\n",
    "        X.append(features)\n",
    "        y.append(emotion)\n",
    "    # split the data to training and testing and return it\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RAVDESS dataset, 75% training 25% testing\n",
    "X, y = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 504\n",
      "[+] Number of testing samples: 168\n",
      "[+] Number of features: 180\n"
     ]
    }
   ],
   "source": [
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "# number of features used\n",
    "# this is a vector of features extracted \n",
    "# using extract_features() function\n",
    "print(\"[+] Number of features:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model, determined by a grid search\n",
    "model_params = {\n",
    "    'alpha': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'hidden_layer_sizes': (300, 150),\n",
    "    'learning_rate': 'adaptive',\n",
    "    'max_iter': 5000,\n",
    "    'verbose': True,\n",
    "    'tol': 1e-8,\n",
    "    'activation': 'logistic',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(**model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n",
      "Iteration 1, loss = 1.44413300\n",
      "Iteration 2, loss = 1.35082562\n",
      "Iteration 3, loss = 1.35841207\n",
      "Iteration 4, loss = 1.35469475\n",
      "Iteration 5, loss = 1.33553241\n",
      "Iteration 6, loss = 1.31171738\n",
      "Iteration 7, loss = 1.28789403\n",
      "Iteration 8, loss = 1.27095878\n",
      "Iteration 9, loss = 1.25395670\n",
      "Iteration 10, loss = 1.23312513\n",
      "Iteration 11, loss = 1.21096144\n",
      "Iteration 12, loss = 1.19003820\n",
      "Iteration 13, loss = 1.16934865\n",
      "Iteration 14, loss = 1.15126434\n",
      "Iteration 15, loss = 1.13277754\n",
      "Iteration 16, loss = 1.11573053\n",
      "Iteration 17, loss = 1.09872054\n",
      "Iteration 18, loss = 1.08059078\n",
      "Iteration 19, loss = 1.06366340\n",
      "Iteration 20, loss = 1.04781983\n",
      "Iteration 21, loss = 1.03942906\n",
      "Iteration 22, loss = 1.01881372\n",
      "Iteration 23, loss = 1.00710576\n",
      "Iteration 24, loss = 0.99414769\n",
      "Iteration 25, loss = 0.97920382\n",
      "Iteration 26, loss = 0.96701948\n",
      "Iteration 27, loss = 0.95101463\n",
      "Iteration 28, loss = 0.94231831\n",
      "Iteration 29, loss = 0.92616544\n",
      "Iteration 30, loss = 0.91447744\n",
      "Iteration 31, loss = 0.90066404\n",
      "Iteration 32, loss = 0.88764454\n",
      "Iteration 33, loss = 0.87918043\n",
      "Iteration 34, loss = 0.86604200\n",
      "Iteration 35, loss = 0.85284222\n",
      "Iteration 36, loss = 0.84078904\n",
      "Iteration 37, loss = 0.82963618\n",
      "Iteration 38, loss = 0.81541786\n",
      "Iteration 39, loss = 0.80759256\n",
      "Iteration 40, loss = 0.79335164\n",
      "Iteration 41, loss = 0.78792456\n",
      "Iteration 42, loss = 0.77156506\n",
      "Iteration 43, loss = 0.76595140\n",
      "Iteration 44, loss = 0.75572145\n",
      "Iteration 45, loss = 0.74490288\n",
      "Iteration 46, loss = 0.73496773\n",
      "Iteration 47, loss = 0.72602889\n",
      "Iteration 48, loss = 0.71488304\n",
      "Iteration 49, loss = 0.70723459\n",
      "Iteration 50, loss = 0.69476673\n",
      "Iteration 51, loss = 0.68810289\n",
      "Iteration 52, loss = 0.68329761\n",
      "Iteration 53, loss = 0.67163243\n",
      "Iteration 54, loss = 0.67004219\n",
      "Iteration 55, loss = 0.65713260\n",
      "Iteration 56, loss = 0.64392731\n",
      "Iteration 57, loss = 0.64383307\n",
      "Iteration 58, loss = 0.63572088\n",
      "Iteration 59, loss = 0.62162552\n",
      "Iteration 60, loss = 0.61401870\n",
      "Iteration 61, loss = 0.60280544\n",
      "Iteration 62, loss = 0.59659606\n",
      "Iteration 63, loss = 0.60215732\n",
      "Iteration 64, loss = 0.59026241\n",
      "Iteration 65, loss = 0.59816902\n",
      "Iteration 66, loss = 0.58130786\n",
      "Iteration 67, loss = 0.57517272\n",
      "Iteration 68, loss = 0.56750672\n",
      "Iteration 69, loss = 0.55113470\n",
      "Iteration 70, loss = 0.54702568\n",
      "Iteration 71, loss = 0.53130773\n",
      "Iteration 72, loss = 0.53578930\n",
      "Iteration 73, loss = 0.52698695\n",
      "Iteration 74, loss = 0.50647483\n",
      "Iteration 75, loss = 0.51947976\n",
      "Iteration 76, loss = 0.51923834\n",
      "Iteration 77, loss = 0.50941695\n",
      "Iteration 78, loss = 0.49739335\n",
      "Iteration 79, loss = 0.48943640\n",
      "Iteration 80, loss = 0.47663900\n",
      "Iteration 81, loss = 0.46745238\n",
      "Iteration 82, loss = 0.46267218\n",
      "Iteration 83, loss = 0.46010817\n",
      "Iteration 84, loss = 0.45034309\n",
      "Iteration 85, loss = 0.44413220\n",
      "Iteration 86, loss = 0.43839439\n",
      "Iteration 87, loss = 0.43596854\n",
      "Iteration 88, loss = 0.42436466\n",
      "Iteration 89, loss = 0.42314210\n",
      "Iteration 90, loss = 0.41871570\n",
      "Iteration 91, loss = 0.41870064\n",
      "Iteration 92, loss = 0.40515923\n",
      "Iteration 93, loss = 0.40698489\n",
      "Iteration 94, loss = 0.39291523\n",
      "Iteration 95, loss = 0.39264322\n",
      "Iteration 96, loss = 0.38700459\n",
      "Iteration 97, loss = 0.38317967\n",
      "Iteration 98, loss = 0.37265152\n",
      "Iteration 99, loss = 0.36668623\n",
      "Iteration 100, loss = 0.36515957\n",
      "Iteration 101, loss = 0.35482874\n",
      "Iteration 102, loss = 0.35091429\n",
      "Iteration 103, loss = 0.34332196\n",
      "Iteration 104, loss = 0.34157747\n",
      "Iteration 105, loss = 0.33977412\n",
      "Iteration 106, loss = 0.32901584\n",
      "Iteration 107, loss = 0.32465475\n",
      "Iteration 108, loss = 0.32572911\n",
      "Iteration 109, loss = 0.31477075\n",
      "Iteration 110, loss = 0.31095723\n",
      "Iteration 111, loss = 0.30701216\n",
      "Iteration 112, loss = 0.30222903\n",
      "Iteration 113, loss = 0.30366039\n",
      "Iteration 114, loss = 0.29777949\n",
      "Iteration 115, loss = 0.28932515\n",
      "Iteration 116, loss = 0.29548005\n",
      "Iteration 117, loss = 0.29245538\n",
      "Iteration 118, loss = 0.28259772\n",
      "Iteration 119, loss = 0.27679224\n",
      "Iteration 120, loss = 0.27504051\n",
      "Iteration 121, loss = 0.26675519\n",
      "Iteration 122, loss = 0.26004775\n",
      "Iteration 123, loss = 0.26052122\n",
      "Iteration 124, loss = 0.25476488\n",
      "Iteration 125, loss = 0.24987359\n",
      "Iteration 126, loss = 0.24603384\n",
      "Iteration 127, loss = 0.24018914\n",
      "Iteration 128, loss = 0.24518555\n",
      "Iteration 129, loss = 0.23904251\n",
      "Iteration 130, loss = 0.23207257\n",
      "Iteration 131, loss = 0.23252454\n",
      "Iteration 132, loss = 0.23213709\n",
      "Iteration 133, loss = 0.23081301\n",
      "Iteration 134, loss = 0.21864598\n",
      "Iteration 135, loss = 0.22935773\n",
      "Iteration 136, loss = 0.21971580\n",
      "Iteration 137, loss = 0.22360367\n",
      "Iteration 138, loss = 0.21667811\n",
      "Iteration 139, loss = 0.20756059\n",
      "Iteration 140, loss = 0.20104901\n",
      "Iteration 141, loss = 0.19910854\n",
      "Iteration 142, loss = 0.19208140\n",
      "Iteration 143, loss = 0.18971613\n",
      "Iteration 144, loss = 0.19244194\n",
      "Iteration 145, loss = 0.18672926\n",
      "Iteration 146, loss = 0.18418924\n",
      "Iteration 147, loss = 0.18234279\n",
      "Iteration 148, loss = 0.17786790\n",
      "Iteration 149, loss = 0.17337105\n",
      "Iteration 150, loss = 0.17277366\n",
      "Iteration 151, loss = 0.16823144\n",
      "Iteration 152, loss = 0.16717362\n",
      "Iteration 153, loss = 0.16290572\n",
      "Iteration 154, loss = 0.16109841\n",
      "Iteration 155, loss = 0.16176398\n",
      "Iteration 156, loss = 0.15600333\n",
      "Iteration 157, loss = 0.15467460\n",
      "Iteration 158, loss = 0.15204894\n",
      "Iteration 159, loss = 0.14857055\n",
      "Iteration 160, loss = 0.14723000\n",
      "Iteration 161, loss = 0.14562848\n",
      "Iteration 162, loss = 0.14326838\n",
      "Iteration 163, loss = 0.14129760\n",
      "Iteration 164, loss = 0.14000333\n",
      "Iteration 165, loss = 0.13658227\n",
      "Iteration 166, loss = 0.13772507\n",
      "Iteration 167, loss = 0.13432535\n",
      "Iteration 168, loss = 0.13339042\n",
      "Iteration 169, loss = 0.13103665\n",
      "Iteration 170, loss = 0.13183430\n",
      "Iteration 171, loss = 0.12835637\n",
      "Iteration 172, loss = 0.12430724\n",
      "Iteration 173, loss = 0.12508082\n",
      "Iteration 174, loss = 0.11873693\n",
      "Iteration 175, loss = 0.11916876\n",
      "Iteration 176, loss = 0.11771721\n",
      "Iteration 177, loss = 0.11439906\n",
      "Iteration 178, loss = 0.11338542\n",
      "Iteration 179, loss = 0.11394045\n",
      "Iteration 180, loss = 0.10871576\n",
      "Iteration 181, loss = 0.10839389\n",
      "Iteration 182, loss = 0.10657533\n",
      "Iteration 183, loss = 0.10604834\n",
      "Iteration 184, loss = 0.10821555\n",
      "Iteration 185, loss = 0.11181207\n",
      "Iteration 186, loss = 0.10156126\n",
      "Iteration 187, loss = 0.10346558\n",
      "Iteration 188, loss = 0.10351746\n",
      "Iteration 189, loss = 0.09818690\n",
      "Iteration 190, loss = 0.09285543\n",
      "Iteration 191, loss = 0.09730665\n",
      "Iteration 192, loss = 0.09324657\n",
      "Iteration 193, loss = 0.09270840\n",
      "Iteration 194, loss = 0.08788395\n",
      "Iteration 195, loss = 0.08990510\n",
      "Iteration 196, loss = 0.08434739\n",
      "Iteration 197, loss = 0.08475581\n",
      "Iteration 198, loss = 0.08097646\n",
      "Iteration 199, loss = 0.08256239\n",
      "Iteration 200, loss = 0.07907459\n",
      "Iteration 201, loss = 0.07818334\n",
      "Iteration 202, loss = 0.07729947\n",
      "Iteration 203, loss = 0.07627002\n",
      "Iteration 204, loss = 0.07452585\n",
      "Iteration 205, loss = 0.07190544\n",
      "Iteration 206, loss = 0.07300950\n",
      "Iteration 207, loss = 0.07183340\n",
      "Iteration 208, loss = 0.06831015\n",
      "Iteration 209, loss = 0.06940358\n",
      "Iteration 210, loss = 0.07406938\n",
      "Iteration 211, loss = 0.07006424\n",
      "Iteration 212, loss = 0.06514193\n",
      "Iteration 213, loss = 0.06742248\n",
      "Iteration 214, loss = 0.06533329\n",
      "Iteration 215, loss = 0.06069628\n",
      "Iteration 216, loss = 0.06252079\n",
      "Iteration 217, loss = 0.06081563\n",
      "Iteration 218, loss = 0.05740158\n",
      "Iteration 219, loss = 0.05838247\n",
      "Iteration 220, loss = 0.05628840\n",
      "Iteration 221, loss = 0.05488344\n",
      "Iteration 222, loss = 0.05541078\n",
      "Iteration 223, loss = 0.05356123\n",
      "Iteration 224, loss = 0.05228365\n",
      "Iteration 225, loss = 0.05287978\n",
      "Iteration 226, loss = 0.05018108\n",
      "Iteration 227, loss = 0.05022942\n",
      "Iteration 228, loss = 0.04907543\n",
      "Iteration 229, loss = 0.04819897\n",
      "Iteration 230, loss = 0.04753749\n",
      "Iteration 231, loss = 0.04934045\n",
      "Iteration 232, loss = 0.04753282\n",
      "Iteration 233, loss = 0.04857909\n",
      "Iteration 234, loss = 0.04564363\n",
      "Iteration 235, loss = 0.04535960\n",
      "Iteration 236, loss = 0.04308808\n",
      "Iteration 237, loss = 0.04243293\n",
      "Iteration 238, loss = 0.04270309\n",
      "Iteration 239, loss = 0.04087145\n",
      "Iteration 240, loss = 0.04130540\n",
      "Iteration 241, loss = 0.04025444\n",
      "Iteration 242, loss = 0.04070792\n",
      "Iteration 243, loss = 0.03794816\n",
      "Iteration 244, loss = 0.03869654\n",
      "Iteration 245, loss = 0.03769738\n",
      "Iteration 246, loss = 0.03761746\n",
      "Iteration 247, loss = 0.03578351\n",
      "Iteration 248, loss = 0.03595203\n",
      "Iteration 249, loss = 0.03485309\n",
      "Iteration 250, loss = 0.03605410\n",
      "Iteration 251, loss = 0.03374358\n",
      "Iteration 252, loss = 0.03364695\n",
      "Iteration 253, loss = 0.03300403\n",
      "Iteration 254, loss = 0.03245980\n",
      "Iteration 255, loss = 0.03162759\n",
      "Iteration 256, loss = 0.03148478\n",
      "Iteration 257, loss = 0.03104109\n",
      "Iteration 258, loss = 0.03028673\n",
      "Iteration 259, loss = 0.03056420\n",
      "Iteration 260, loss = 0.02963365\n",
      "Iteration 261, loss = 0.02939139\n",
      "Iteration 262, loss = 0.02871685\n",
      "Iteration 263, loss = 0.02833726\n",
      "Iteration 264, loss = 0.02809037\n",
      "Iteration 265, loss = 0.02719550\n",
      "Iteration 266, loss = 0.02730703\n",
      "Iteration 267, loss = 0.02699427\n",
      "Iteration 268, loss = 0.02661076\n",
      "Iteration 269, loss = 0.02645143\n",
      "Iteration 270, loss = 0.02592881\n",
      "Iteration 271, loss = 0.02537543\n",
      "Iteration 272, loss = 0.02505893\n",
      "Iteration 273, loss = 0.02456159\n",
      "Iteration 274, loss = 0.02433525\n",
      "Iteration 275, loss = 0.02387561\n",
      "Iteration 276, loss = 0.02414594\n",
      "Iteration 277, loss = 0.02322080\n",
      "Iteration 278, loss = 0.02334987\n",
      "Iteration 279, loss = 0.02305526\n",
      "Iteration 280, loss = 0.02231500\n",
      "Iteration 281, loss = 0.02244869\n",
      "Iteration 282, loss = 0.02165362\n",
      "Iteration 283, loss = 0.02159897\n",
      "Iteration 284, loss = 0.02125707\n",
      "Iteration 285, loss = 0.02109387\n",
      "Iteration 286, loss = 0.02079785\n",
      "Iteration 287, loss = 0.02060456\n",
      "Iteration 288, loss = 0.02076060\n",
      "Iteration 289, loss = 0.02026864\n",
      "Iteration 290, loss = 0.02007605\n",
      "Iteration 291, loss = 0.01967711\n",
      "Iteration 292, loss = 0.01964352\n",
      "Iteration 293, loss = 0.01961299\n",
      "Iteration 294, loss = 0.01892463\n",
      "Iteration 295, loss = 0.01908918\n",
      "Iteration 296, loss = 0.01867442\n",
      "Iteration 297, loss = 0.01852140\n",
      "Iteration 298, loss = 0.01824381\n",
      "Iteration 299, loss = 0.01812286\n",
      "Iteration 300, loss = 0.01794220\n",
      "Iteration 301, loss = 0.01821483\n",
      "Iteration 302, loss = 0.01772449\n",
      "Iteration 303, loss = 0.01753759\n",
      "Iteration 304, loss = 0.01744996\n",
      "Iteration 305, loss = 0.01720755\n",
      "Iteration 306, loss = 0.01684909\n",
      "Iteration 307, loss = 0.01677284\n",
      "Iteration 308, loss = 0.01654293\n",
      "Iteration 309, loss = 0.01631209\n",
      "Iteration 310, loss = 0.01602526\n",
      "Iteration 311, loss = 0.01620531\n",
      "Iteration 312, loss = 0.01567744\n",
      "Iteration 313, loss = 0.01585338\n",
      "Iteration 314, loss = 0.01534489\n",
      "Iteration 315, loss = 0.01543370\n",
      "Iteration 316, loss = 0.01513639\n",
      "Iteration 317, loss = 0.01495455\n",
      "Iteration 318, loss = 0.01487242\n",
      "Iteration 319, loss = 0.01477274\n",
      "Iteration 320, loss = 0.01458530\n",
      "Iteration 321, loss = 0.01443837\n",
      "Iteration 322, loss = 0.01436868\n",
      "Iteration 323, loss = 0.01412363\n",
      "Iteration 324, loss = 0.01423460\n",
      "Iteration 325, loss = 0.01389727\n",
      "Iteration 326, loss = 0.01392629\n",
      "Iteration 327, loss = 0.01391607\n",
      "Iteration 328, loss = 0.01363253\n",
      "Iteration 329, loss = 0.01350852\n",
      "Iteration 330, loss = 0.01342591\n",
      "Iteration 331, loss = 0.01332241\n",
      "Iteration 332, loss = 0.01312068\n",
      "Iteration 333, loss = 0.01303831\n",
      "Iteration 334, loss = 0.01308377\n",
      "Iteration 335, loss = 0.01280753\n",
      "Iteration 336, loss = 0.01284316\n",
      "Iteration 337, loss = 0.01268719\n",
      "Iteration 338, loss = 0.01259888\n",
      "Iteration 339, loss = 0.01247949\n",
      "Iteration 340, loss = 0.01245357\n",
      "Iteration 341, loss = 0.01214542\n",
      "Iteration 342, loss = 0.01231748\n",
      "Iteration 343, loss = 0.01202885\n",
      "Iteration 344, loss = 0.01203767\n",
      "Iteration 345, loss = 0.01193809\n",
      "Iteration 346, loss = 0.01185297\n",
      "Iteration 347, loss = 0.01164886\n",
      "Iteration 348, loss = 0.01178294\n",
      "Iteration 349, loss = 0.01150942\n",
      "Iteration 350, loss = 0.01151506\n",
      "Iteration 351, loss = 0.01155601\n",
      "Iteration 352, loss = 0.01137157\n",
      "Iteration 353, loss = 0.01116039\n",
      "Iteration 354, loss = 0.01120574\n",
      "Iteration 355, loss = 0.01098804\n",
      "Iteration 356, loss = 0.01103082\n",
      "Iteration 357, loss = 0.01088980\n",
      "Iteration 358, loss = 0.01105067\n",
      "Iteration 359, loss = 0.01071156\n",
      "Iteration 360, loss = 0.01080606\n",
      "Iteration 361, loss = 0.01072060\n",
      "Iteration 362, loss = 0.01056098\n",
      "Iteration 363, loss = 0.01063601\n",
      "Iteration 364, loss = 0.01038832\n",
      "Iteration 365, loss = 0.01028799\n",
      "Iteration 366, loss = 0.01029171\n",
      "Iteration 367, loss = 0.01015159\n",
      "Iteration 368, loss = 0.01010666\n",
      "Iteration 369, loss = 0.01002756\n",
      "Iteration 370, loss = 0.00994415\n",
      "Iteration 371, loss = 0.00992248\n",
      "Iteration 372, loss = 0.00982506\n",
      "Iteration 373, loss = 0.00976246\n",
      "Iteration 374, loss = 0.00971524\n",
      "Iteration 375, loss = 0.00966714\n",
      "Iteration 376, loss = 0.00959486\n",
      "Iteration 377, loss = 0.00953992\n",
      "Iteration 378, loss = 0.00952090\n",
      "Iteration 379, loss = 0.00943084\n",
      "Iteration 380, loss = 0.00938017\n",
      "Iteration 381, loss = 0.00934913\n",
      "Iteration 382, loss = 0.00924550\n",
      "Iteration 383, loss = 0.00919504\n",
      "Iteration 384, loss = 0.00915593\n",
      "Iteration 385, loss = 0.00909446\n",
      "Iteration 386, loss = 0.00903601\n",
      "Iteration 387, loss = 0.00897825\n",
      "Iteration 388, loss = 0.00896301\n",
      "Iteration 389, loss = 0.00890854\n",
      "Iteration 390, loss = 0.00881841\n",
      "Iteration 391, loss = 0.00882120\n",
      "Iteration 392, loss = 0.00872672\n",
      "Iteration 393, loss = 0.00869347\n",
      "Iteration 394, loss = 0.00865907\n",
      "Iteration 395, loss = 0.00859720\n",
      "Iteration 396, loss = 0.00858932\n",
      "Iteration 397, loss = 0.00850077\n",
      "Iteration 398, loss = 0.00854139\n",
      "Iteration 399, loss = 0.00843919\n",
      "Iteration 400, loss = 0.00848571\n",
      "Iteration 401, loss = 0.00830755\n",
      "Iteration 402, loss = 0.00833203\n",
      "Iteration 403, loss = 0.00828314\n",
      "Iteration 404, loss = 0.00835239\n",
      "Iteration 405, loss = 0.00817492\n",
      "Iteration 406, loss = 0.00812205\n",
      "Iteration 407, loss = 0.00814629\n",
      "Iteration 408, loss = 0.00804582\n",
      "Iteration 409, loss = 0.00801969\n",
      "Iteration 410, loss = 0.00807259\n",
      "Iteration 411, loss = 0.00793723\n",
      "Iteration 412, loss = 0.00788116\n",
      "Iteration 413, loss = 0.00785453\n",
      "Iteration 414, loss = 0.00779888\n",
      "Iteration 415, loss = 0.00785960\n",
      "Iteration 416, loss = 0.00771251\n",
      "Iteration 417, loss = 0.00772070\n",
      "Iteration 418, loss = 0.00768367\n",
      "Iteration 419, loss = 0.00763372\n",
      "Iteration 420, loss = 0.00764000\n",
      "Iteration 421, loss = 0.00752877\n",
      "Iteration 422, loss = 0.00755294\n",
      "Iteration 423, loss = 0.00748880\n",
      "Iteration 424, loss = 0.00744828\n",
      "Iteration 425, loss = 0.00746410\n",
      "Iteration 426, loss = 0.00735474\n",
      "Iteration 427, loss = 0.00739829\n",
      "Iteration 428, loss = 0.00732624\n",
      "Iteration 429, loss = 0.00726310\n",
      "Iteration 430, loss = 0.00727341\n",
      "Iteration 431, loss = 0.00722062\n",
      "Iteration 432, loss = 0.00719490\n",
      "Iteration 433, loss = 0.00716185\n",
      "Iteration 434, loss = 0.00712407\n",
      "Iteration 435, loss = 0.00713209\n",
      "Iteration 436, loss = 0.00706428\n",
      "Iteration 437, loss = 0.00706125\n",
      "Iteration 438, loss = 0.00703854\n",
      "Iteration 439, loss = 0.00698658\n",
      "Iteration 440, loss = 0.00698577\n",
      "Iteration 441, loss = 0.00691996\n",
      "Iteration 442, loss = 0.00692275\n",
      "Iteration 443, loss = 0.00687277\n",
      "Iteration 444, loss = 0.00683309\n",
      "Iteration 445, loss = 0.00682731\n",
      "Iteration 446, loss = 0.00680252\n",
      "Iteration 447, loss = 0.00677028\n",
      "Iteration 448, loss = 0.00675303\n",
      "Iteration 449, loss = 0.00672065\n",
      "Iteration 450, loss = 0.00667438\n",
      "Iteration 451, loss = 0.00665468\n",
      "Iteration 452, loss = 0.00664444\n",
      "Iteration 453, loss = 0.00665178\n",
      "Iteration 454, loss = 0.00659098\n",
      "Iteration 455, loss = 0.00655528\n",
      "Iteration 456, loss = 0.00653526\n",
      "Iteration 457, loss = 0.00652537\n",
      "Iteration 458, loss = 0.00648245\n",
      "Iteration 459, loss = 0.00647981\n",
      "Iteration 460, loss = 0.00644377\n",
      "Iteration 461, loss = 0.00641555\n",
      "Iteration 462, loss = 0.00639105\n",
      "Iteration 463, loss = 0.00636998\n",
      "Iteration 464, loss = 0.00635081\n",
      "Iteration 465, loss = 0.00633197\n",
      "Iteration 466, loss = 0.00630008\n",
      "Iteration 467, loss = 0.00628449\n",
      "Iteration 468, loss = 0.00626125\n",
      "Iteration 469, loss = 0.00623345\n",
      "Iteration 470, loss = 0.00621844\n",
      "Iteration 471, loss = 0.00619618\n",
      "Iteration 472, loss = 0.00617831\n",
      "Iteration 473, loss = 0.00616691\n",
      "Iteration 474, loss = 0.00613751\n",
      "Iteration 475, loss = 0.00611417\n",
      "Iteration 476, loss = 0.00609608\n",
      "Iteration 477, loss = 0.00607932\n",
      "Iteration 478, loss = 0.00606821\n",
      "Iteration 479, loss = 0.00603680\n",
      "Iteration 480, loss = 0.00602962\n",
      "Iteration 481, loss = 0.00600493\n",
      "Iteration 482, loss = 0.00598950\n",
      "Iteration 483, loss = 0.00596790\n",
      "Iteration 484, loss = 0.00595112\n",
      "Iteration 485, loss = 0.00593518\n",
      "Iteration 486, loss = 0.00590014\n",
      "Iteration 487, loss = 0.00588665\n",
      "Iteration 488, loss = 0.00587489\n",
      "Iteration 489, loss = 0.00584887\n",
      "Iteration 490, loss = 0.00583035\n",
      "Iteration 491, loss = 0.00583333\n",
      "Iteration 492, loss = 0.00581485\n",
      "Iteration 493, loss = 0.00578528\n",
      "Iteration 494, loss = 0.00576141\n",
      "Iteration 495, loss = 0.00574725\n",
      "Iteration 496, loss = 0.00572781\n",
      "Iteration 497, loss = 0.00571492\n",
      "Iteration 498, loss = 0.00569829\n",
      "Iteration 499, loss = 0.00568294\n",
      "Iteration 500, loss = 0.00567272\n",
      "Iteration 501, loss = 0.00565743\n",
      "Iteration 502, loss = 0.00563629\n",
      "Iteration 503, loss = 0.00562645\n",
      "Iteration 504, loss = 0.00560232\n",
      "Iteration 505, loss = 0.00559010\n",
      "Iteration 506, loss = 0.00557780\n",
      "Iteration 507, loss = 0.00555748\n",
      "Iteration 508, loss = 0.00553985\n",
      "Iteration 509, loss = 0.00553447\n",
      "Iteration 510, loss = 0.00551467\n",
      "Iteration 511, loss = 0.00550336\n",
      "Iteration 512, loss = 0.00548422\n",
      "Iteration 513, loss = 0.00547059\n",
      "Iteration 514, loss = 0.00545505\n",
      "Iteration 515, loss = 0.00543928\n",
      "Iteration 516, loss = 0.00542191\n",
      "Iteration 517, loss = 0.00540942\n",
      "Iteration 518, loss = 0.00539606\n",
      "Iteration 519, loss = 0.00537823\n",
      "Iteration 520, loss = 0.00537078\n",
      "Iteration 521, loss = 0.00535617\n",
      "Iteration 522, loss = 0.00534299\n",
      "Iteration 523, loss = 0.00532598\n",
      "Iteration 524, loss = 0.00531956\n",
      "Iteration 525, loss = 0.00531172\n",
      "Iteration 526, loss = 0.00528733\n",
      "Iteration 527, loss = 0.00527057\n",
      "Iteration 528, loss = 0.00525986\n",
      "Iteration 529, loss = 0.00524406\n",
      "Iteration 530, loss = 0.00523142\n",
      "Iteration 531, loss = 0.00523131\n",
      "Iteration 532, loss = 0.00520873\n",
      "Iteration 533, loss = 0.00519518\n",
      "Iteration 534, loss = 0.00520802\n",
      "Iteration 535, loss = 0.00516568\n",
      "Iteration 536, loss = 0.00516853\n",
      "Iteration 537, loss = 0.00515156\n",
      "Iteration 538, loss = 0.00513040\n",
      "Iteration 539, loss = 0.00512260\n",
      "Iteration 540, loss = 0.00511217\n",
      "Iteration 541, loss = 0.00510655\n",
      "Iteration 542, loss = 0.00509084\n",
      "Iteration 543, loss = 0.00507605\n",
      "Iteration 544, loss = 0.00505850\n",
      "Iteration 545, loss = 0.00506436\n",
      "Iteration 546, loss = 0.00503553\n",
      "Iteration 547, loss = 0.00502890\n",
      "Iteration 548, loss = 0.00502240\n",
      "Iteration 549, loss = 0.00500500\n",
      "Iteration 550, loss = 0.00498962\n",
      "Iteration 551, loss = 0.00497586\n",
      "Iteration 552, loss = 0.00496979\n",
      "Iteration 553, loss = 0.00495828\n",
      "Iteration 554, loss = 0.00494435\n",
      "Iteration 555, loss = 0.00493497\n",
      "Iteration 556, loss = 0.00492014\n",
      "Iteration 557, loss = 0.00492651\n",
      "Iteration 558, loss = 0.00490321\n",
      "Iteration 559, loss = 0.00491452\n",
      "Iteration 560, loss = 0.00488835\n",
      "Iteration 561, loss = 0.00486344\n",
      "Iteration 562, loss = 0.00485673\n",
      "Iteration 563, loss = 0.00485219\n",
      "Iteration 564, loss = 0.00483428\n",
      "Iteration 565, loss = 0.00482311\n",
      "Iteration 566, loss = 0.00482027\n",
      "Iteration 567, loss = 0.00480567\n",
      "Iteration 568, loss = 0.00479594\n",
      "Iteration 569, loss = 0.00478361\n",
      "Iteration 570, loss = 0.00478417\n",
      "Iteration 571, loss = 0.00476750\n",
      "Iteration 572, loss = 0.00475706\n",
      "Iteration 573, loss = 0.00475704\n",
      "Iteration 574, loss = 0.00473631\n",
      "Iteration 575, loss = 0.00473963\n",
      "Iteration 576, loss = 0.00472678\n",
      "Iteration 577, loss = 0.00471653\n",
      "Iteration 578, loss = 0.00470484\n",
      "Iteration 579, loss = 0.00469263\n",
      "Iteration 580, loss = 0.00468685\n",
      "Iteration 581, loss = 0.00467971\n",
      "Iteration 582, loss = 0.00467108\n",
      "Iteration 583, loss = 0.00465716\n",
      "Iteration 584, loss = 0.00464678\n",
      "Iteration 585, loss = 0.00464317\n",
      "Iteration 586, loss = 0.00463448\n",
      "Iteration 587, loss = 0.00462713\n",
      "Iteration 588, loss = 0.00462023\n",
      "Iteration 589, loss = 0.00460462\n",
      "Iteration 590, loss = 0.00459281\n",
      "Iteration 591, loss = 0.00458996\n",
      "Iteration 592, loss = 0.00457942\n",
      "Iteration 593, loss = 0.00458370\n",
      "Iteration 594, loss = 0.00456212\n",
      "Iteration 595, loss = 0.00455665\n",
      "Iteration 596, loss = 0.00454627\n",
      "Iteration 597, loss = 0.00453969\n",
      "Iteration 598, loss = 0.00452926\n",
      "Iteration 599, loss = 0.00452085\n",
      "Iteration 600, loss = 0.00450677\n",
      "Iteration 601, loss = 0.00450424\n",
      "Iteration 602, loss = 0.00449301\n",
      "Iteration 603, loss = 0.00448473\n",
      "Iteration 604, loss = 0.00448281\n",
      "Iteration 605, loss = 0.00447543\n",
      "Iteration 606, loss = 0.00446308\n",
      "Iteration 607, loss = 0.00445235\n",
      "Iteration 608, loss = 0.00444403\n",
      "Iteration 609, loss = 0.00443684\n",
      "Iteration 610, loss = 0.00443185\n",
      "Iteration 611, loss = 0.00442214\n",
      "Iteration 612, loss = 0.00441459\n",
      "Iteration 613, loss = 0.00441006\n",
      "Iteration 614, loss = 0.00440049\n",
      "Iteration 615, loss = 0.00439296\n",
      "Iteration 616, loss = 0.00439661\n",
      "Iteration 617, loss = 0.00437661\n",
      "Iteration 618, loss = 0.00437156\n",
      "Iteration 619, loss = 0.00436489\n",
      "Iteration 620, loss = 0.00436056\n",
      "Iteration 621, loss = 0.00435294\n",
      "Iteration 622, loss = 0.00434939\n",
      "Iteration 623, loss = 0.00433678\n",
      "Iteration 624, loss = 0.00433012\n",
      "Iteration 625, loss = 0.00432049\n",
      "Iteration 626, loss = 0.00431452\n",
      "Iteration 627, loss = 0.00430838\n",
      "Iteration 628, loss = 0.00429989\n",
      "Iteration 629, loss = 0.00429355\n",
      "Iteration 630, loss = 0.00428802\n",
      "Iteration 631, loss = 0.00428116\n",
      "Iteration 632, loss = 0.00427478\n",
      "Iteration 633, loss = 0.00426615\n",
      "Iteration 634, loss = 0.00426181\n",
      "Iteration 635, loss = 0.00426510\n",
      "Iteration 636, loss = 0.00425097\n",
      "Iteration 637, loss = 0.00424045\n",
      "Iteration 638, loss = 0.00423727\n",
      "Iteration 639, loss = 0.00423069\n",
      "Iteration 640, loss = 0.00422330\n",
      "Iteration 641, loss = 0.00421434\n",
      "Iteration 642, loss = 0.00420908\n",
      "Iteration 643, loss = 0.00420385\n",
      "Iteration 644, loss = 0.00419615\n",
      "Iteration 645, loss = 0.00419130\n",
      "Iteration 646, loss = 0.00418647\n",
      "Iteration 647, loss = 0.00417711\n",
      "Iteration 648, loss = 0.00417733\n",
      "Iteration 649, loss = 0.00417463\n",
      "Iteration 650, loss = 0.00416334\n",
      "Iteration 651, loss = 0.00415577\n",
      "Iteration 652, loss = 0.00414748\n",
      "Iteration 653, loss = 0.00414352\n",
      "Iteration 654, loss = 0.00413917\n",
      "Iteration 655, loss = 0.00413185\n",
      "Iteration 656, loss = 0.00412723\n",
      "Iteration 657, loss = 0.00412196\n",
      "Iteration 658, loss = 0.00411946\n",
      "Iteration 659, loss = 0.00410976\n",
      "Iteration 660, loss = 0.00410300\n",
      "Iteration 661, loss = 0.00409895\n",
      "Iteration 662, loss = 0.00409418\n",
      "Iteration 663, loss = 0.00408725\n",
      "Iteration 664, loss = 0.00408219\n",
      "Iteration 665, loss = 0.00407611\n",
      "Iteration 666, loss = 0.00407056\n",
      "Iteration 667, loss = 0.00406676\n",
      "Iteration 668, loss = 0.00405919\n",
      "Iteration 669, loss = 0.00405458\n",
      "Iteration 670, loss = 0.00404987\n",
      "Iteration 671, loss = 0.00404294\n",
      "Iteration 672, loss = 0.00403639\n",
      "Iteration 673, loss = 0.00403079\n",
      "Iteration 674, loss = 0.00402648\n",
      "Iteration 675, loss = 0.00401953\n",
      "Iteration 676, loss = 0.00401485\n",
      "Iteration 677, loss = 0.00400996\n",
      "Iteration 678, loss = 0.00400520\n",
      "Iteration 679, loss = 0.00400660\n",
      "Iteration 680, loss = 0.00400192\n",
      "Iteration 681, loss = 0.00399095\n",
      "Iteration 682, loss = 0.00398902\n",
      "Iteration 683, loss = 0.00399106\n",
      "Iteration 684, loss = 0.00397529\n",
      "Iteration 685, loss = 0.00397148\n",
      "Iteration 686, loss = 0.00396660\n",
      "Iteration 687, loss = 0.00396079\n",
      "Iteration 688, loss = 0.00395819\n",
      "Iteration 689, loss = 0.00395659\n",
      "Iteration 690, loss = 0.00394756\n",
      "Iteration 691, loss = 0.00394052\n",
      "Iteration 692, loss = 0.00393627\n",
      "Iteration 693, loss = 0.00393334\n",
      "Iteration 694, loss = 0.00392861\n",
      "Iteration 695, loss = 0.00392361\n",
      "Iteration 696, loss = 0.00391720\n",
      "Iteration 697, loss = 0.00391365\n",
      "Iteration 698, loss = 0.00390910\n",
      "Iteration 699, loss = 0.00390485\n",
      "Iteration 700, loss = 0.00389917\n",
      "Iteration 701, loss = 0.00389401\n",
      "Iteration 702, loss = 0.00389082\n",
      "Iteration 703, loss = 0.00388637\n",
      "Iteration 704, loss = 0.00388316\n",
      "Iteration 705, loss = 0.00387617\n",
      "Iteration 706, loss = 0.00387337\n",
      "Iteration 707, loss = 0.00386807\n",
      "Iteration 708, loss = 0.00386502\n",
      "Iteration 709, loss = 0.00385870\n",
      "Iteration 710, loss = 0.00385543\n",
      "Iteration 711, loss = 0.00385086\n",
      "Iteration 712, loss = 0.00384557\n",
      "Iteration 713, loss = 0.00384451\n",
      "Iteration 714, loss = 0.00383811\n",
      "Iteration 715, loss = 0.00383492\n",
      "Iteration 716, loss = 0.00382896\n",
      "Iteration 717, loss = 0.00382604\n",
      "Iteration 718, loss = 0.00382124\n",
      "Iteration 719, loss = 0.00381598\n",
      "Iteration 720, loss = 0.00381412\n",
      "Iteration 721, loss = 0.00381042\n",
      "Iteration 722, loss = 0.00380460\n",
      "Iteration 723, loss = 0.00380000\n",
      "Iteration 724, loss = 0.00380037\n",
      "Iteration 725, loss = 0.00379317\n",
      "Iteration 726, loss = 0.00379134\n",
      "Iteration 727, loss = 0.00378691\n",
      "Iteration 728, loss = 0.00378103\n",
      "Iteration 729, loss = 0.00377765\n",
      "Iteration 730, loss = 0.00377199\n",
      "Iteration 731, loss = 0.00377154\n",
      "Iteration 732, loss = 0.00376428\n",
      "Iteration 733, loss = 0.00376248\n",
      "Iteration 734, loss = 0.00375779\n",
      "Iteration 735, loss = 0.00375284\n",
      "Iteration 736, loss = 0.00375019\n",
      "Iteration 737, loss = 0.00374569\n",
      "Iteration 738, loss = 0.00374344\n",
      "Iteration 739, loss = 0.00373951\n",
      "Iteration 740, loss = 0.00373433\n",
      "Iteration 741, loss = 0.00373178\n",
      "Iteration 742, loss = 0.00372874\n",
      "Iteration 743, loss = 0.00372428\n",
      "Iteration 744, loss = 0.00371928\n",
      "Iteration 745, loss = 0.00371638\n",
      "Iteration 746, loss = 0.00371226\n",
      "Iteration 747, loss = 0.00370968\n",
      "Iteration 748, loss = 0.00370549\n",
      "Iteration 749, loss = 0.00370247\n",
      "Iteration 750, loss = 0.00369783\n",
      "Iteration 751, loss = 0.00369522\n",
      "Iteration 752, loss = 0.00369110\n",
      "Iteration 753, loss = 0.00368777\n",
      "Iteration 754, loss = 0.00368500\n",
      "Iteration 755, loss = 0.00368281\n",
      "Iteration 756, loss = 0.00367940\n",
      "Iteration 757, loss = 0.00367368\n",
      "Iteration 758, loss = 0.00367045\n",
      "Iteration 759, loss = 0.00366856\n",
      "Iteration 760, loss = 0.00366464\n",
      "Iteration 761, loss = 0.00366590\n",
      "Iteration 762, loss = 0.00365698\n",
      "Iteration 763, loss = 0.00365337\n",
      "Iteration 764, loss = 0.00364999\n",
      "Iteration 765, loss = 0.00364693\n",
      "Iteration 766, loss = 0.00364501\n",
      "Iteration 767, loss = 0.00364137\n",
      "Iteration 768, loss = 0.00363712\n",
      "Iteration 769, loss = 0.00363447\n",
      "Iteration 770, loss = 0.00363353\n",
      "Iteration 771, loss = 0.00362738\n",
      "Iteration 772, loss = 0.00362546\n",
      "Iteration 773, loss = 0.00362054\n",
      "Iteration 774, loss = 0.00361715\n",
      "Iteration 775, loss = 0.00361403\n",
      "Iteration 776, loss = 0.00361421\n",
      "Iteration 777, loss = 0.00360864\n",
      "Iteration 778, loss = 0.00360532\n",
      "Iteration 779, loss = 0.00360178\n",
      "Iteration 780, loss = 0.00359916\n",
      "Iteration 781, loss = 0.00359592\n",
      "Iteration 782, loss = 0.00359370\n",
      "Iteration 783, loss = 0.00358994\n",
      "Iteration 784, loss = 0.00358690\n",
      "Iteration 785, loss = 0.00358896\n",
      "Iteration 786, loss = 0.00358558\n",
      "Iteration 787, loss = 0.00357893\n",
      "Iteration 788, loss = 0.00357666\n",
      "Iteration 789, loss = 0.00357194\n",
      "Iteration 790, loss = 0.00356876\n",
      "Iteration 791, loss = 0.00356659\n",
      "Iteration 792, loss = 0.00356144\n",
      "Iteration 793, loss = 0.00356121\n",
      "Iteration 794, loss = 0.00355731\n",
      "Iteration 795, loss = 0.00355616\n",
      "Iteration 796, loss = 0.00355365\n",
      "Iteration 797, loss = 0.00354879\n",
      "Iteration 798, loss = 0.00354827\n",
      "Iteration 799, loss = 0.00354432\n",
      "Iteration 800, loss = 0.00354075\n",
      "Iteration 801, loss = 0.00354027\n",
      "Iteration 802, loss = 0.00353520\n",
      "Iteration 803, loss = 0.00353333\n",
      "Iteration 804, loss = 0.00352791\n",
      "Iteration 805, loss = 0.00352497\n",
      "Iteration 806, loss = 0.00352182\n",
      "Iteration 807, loss = 0.00351865\n",
      "Iteration 808, loss = 0.00351677\n",
      "Iteration 809, loss = 0.00351510\n",
      "Iteration 810, loss = 0.00351073\n",
      "Iteration 811, loss = 0.00350850\n",
      "Iteration 812, loss = 0.00350636\n",
      "Iteration 813, loss = 0.00350328\n",
      "Iteration 814, loss = 0.00350174\n",
      "Iteration 815, loss = 0.00349803\n",
      "Iteration 816, loss = 0.00349755\n",
      "Iteration 817, loss = 0.00349384\n",
      "Iteration 818, loss = 0.00349018\n",
      "Iteration 819, loss = 0.00348716\n",
      "Iteration 820, loss = 0.00348458\n",
      "Iteration 821, loss = 0.00348100\n",
      "Iteration 822, loss = 0.00347802\n",
      "Iteration 823, loss = 0.00347627\n",
      "Iteration 824, loss = 0.00347350\n",
      "Iteration 825, loss = 0.00347302\n",
      "Iteration 826, loss = 0.00346939\n",
      "Iteration 827, loss = 0.00346725\n",
      "Iteration 828, loss = 0.00346289\n",
      "Iteration 829, loss = 0.00346251\n",
      "Iteration 830, loss = 0.00345787\n",
      "Iteration 831, loss = 0.00345569\n",
      "Iteration 832, loss = 0.00345250\n",
      "Iteration 833, loss = 0.00345235\n",
      "Iteration 834, loss = 0.00344763\n",
      "Iteration 835, loss = 0.00344633\n",
      "Iteration 836, loss = 0.00344261\n",
      "Iteration 837, loss = 0.00344173\n",
      "Iteration 838, loss = 0.00343894\n",
      "Iteration 839, loss = 0.00343507\n",
      "Iteration 840, loss = 0.00343194\n",
      "Iteration 841, loss = 0.00342930\n",
      "Iteration 842, loss = 0.00342659\n",
      "Iteration 843, loss = 0.00342727\n",
      "Iteration 844, loss = 0.00342454\n",
      "Iteration 845, loss = 0.00341880\n",
      "Iteration 846, loss = 0.00341677\n",
      "Iteration 847, loss = 0.00341633\n",
      "Iteration 848, loss = 0.00341348\n",
      "Iteration 849, loss = 0.00340925\n",
      "Iteration 850, loss = 0.00340772\n",
      "Iteration 851, loss = 0.00340474\n",
      "Iteration 852, loss = 0.00340278\n",
      "Iteration 853, loss = 0.00340109\n",
      "Iteration 854, loss = 0.00339784\n",
      "Iteration 855, loss = 0.00339602\n",
      "Iteration 856, loss = 0.00339438\n",
      "Iteration 857, loss = 0.00339253\n",
      "Iteration 858, loss = 0.00338928\n",
      "Iteration 859, loss = 0.00338702\n",
      "Iteration 860, loss = 0.00338468\n",
      "Iteration 861, loss = 0.00338192\n",
      "Iteration 862, loss = 0.00337847\n",
      "Iteration 863, loss = 0.00337744\n",
      "Iteration 864, loss = 0.00337447\n",
      "Iteration 865, loss = 0.00337164\n",
      "Iteration 866, loss = 0.00337072\n",
      "Iteration 867, loss = 0.00337039\n",
      "Iteration 868, loss = 0.00336615\n",
      "Iteration 869, loss = 0.00336382\n",
      "Iteration 870, loss = 0.00336175\n",
      "Iteration 871, loss = 0.00335907\n",
      "Iteration 872, loss = 0.00335624\n",
      "Iteration 873, loss = 0.00335391\n",
      "Iteration 874, loss = 0.00335281\n",
      "Iteration 875, loss = 0.00335054\n",
      "Iteration 876, loss = 0.00334684\n",
      "Iteration 877, loss = 0.00334495\n",
      "Iteration 878, loss = 0.00334282\n",
      "Iteration 879, loss = 0.00334103\n",
      "Iteration 880, loss = 0.00333833\n",
      "Iteration 881, loss = 0.00333755\n",
      "Iteration 882, loss = 0.00333520\n",
      "Iteration 883, loss = 0.00333421\n",
      "Iteration 884, loss = 0.00333061\n",
      "Iteration 885, loss = 0.00332713\n",
      "Iteration 886, loss = 0.00332551\n",
      "Iteration 887, loss = 0.00332365\n",
      "Iteration 888, loss = 0.00332140\n",
      "Iteration 889, loss = 0.00331990\n",
      "Iteration 890, loss = 0.00331660\n",
      "Iteration 891, loss = 0.00331494\n",
      "Iteration 892, loss = 0.00331345\n",
      "Iteration 893, loss = 0.00331049\n",
      "Iteration 894, loss = 0.00330859\n",
      "Iteration 895, loss = 0.00330657\n",
      "Iteration 896, loss = 0.00330382\n",
      "Iteration 897, loss = 0.00330231\n",
      "Iteration 898, loss = 0.00329992\n",
      "Iteration 899, loss = 0.00329968\n",
      "Iteration 900, loss = 0.00329657\n",
      "Iteration 901, loss = 0.00329523\n",
      "Iteration 902, loss = 0.00329275\n",
      "Iteration 903, loss = 0.00328939\n",
      "Iteration 904, loss = 0.00328981\n",
      "Iteration 905, loss = 0.00329047\n",
      "Iteration 906, loss = 0.00328303\n",
      "Iteration 907, loss = 0.00328194\n",
      "Iteration 908, loss = 0.00328064\n",
      "Iteration 909, loss = 0.00327819\n",
      "Iteration 910, loss = 0.00327626\n",
      "Iteration 911, loss = 0.00327541\n",
      "Iteration 912, loss = 0.00327226\n",
      "Iteration 913, loss = 0.00327067\n",
      "Iteration 914, loss = 0.00326811\n",
      "Iteration 915, loss = 0.00326813\n",
      "Iteration 916, loss = 0.00326354\n",
      "Iteration 917, loss = 0.00326137\n",
      "Iteration 918, loss = 0.00326056\n",
      "Iteration 919, loss = 0.00325867\n",
      "Iteration 920, loss = 0.00325665\n",
      "Iteration 921, loss = 0.00325434\n",
      "Iteration 922, loss = 0.00325266\n",
      "Iteration 923, loss = 0.00325007\n",
      "Iteration 924, loss = 0.00324883\n",
      "Iteration 925, loss = 0.00324619\n",
      "Iteration 926, loss = 0.00324378\n",
      "Iteration 927, loss = 0.00324206\n",
      "Iteration 928, loss = 0.00323985\n",
      "Iteration 929, loss = 0.00323857\n",
      "Iteration 930, loss = 0.00323616\n",
      "Iteration 931, loss = 0.00323449\n",
      "Iteration 932, loss = 0.00323249\n",
      "Iteration 933, loss = 0.00323052\n",
      "Iteration 934, loss = 0.00322914\n",
      "Iteration 935, loss = 0.00322631\n",
      "Iteration 936, loss = 0.00322500\n",
      "Iteration 937, loss = 0.00322388\n",
      "Iteration 938, loss = 0.00322120\n",
      "Iteration 939, loss = 0.00321965\n",
      "Iteration 940, loss = 0.00321743\n",
      "Iteration 941, loss = 0.00321487\n",
      "Iteration 942, loss = 0.00321479\n",
      "Iteration 943, loss = 0.00321215\n",
      "Iteration 944, loss = 0.00321039\n",
      "Iteration 945, loss = 0.00320806\n",
      "Iteration 946, loss = 0.00320728\n",
      "Iteration 947, loss = 0.00320400\n",
      "Iteration 948, loss = 0.00320406\n",
      "Iteration 949, loss = 0.00320200\n",
      "Iteration 950, loss = 0.00319986\n",
      "Iteration 951, loss = 0.00319669\n",
      "Iteration 952, loss = 0.00319571\n",
      "Iteration 953, loss = 0.00319451\n",
      "Iteration 954, loss = 0.00319335\n",
      "Iteration 955, loss = 0.00319073\n",
      "Iteration 956, loss = 0.00318810\n",
      "Iteration 957, loss = 0.00318581\n",
      "Iteration 958, loss = 0.00318488\n",
      "Iteration 959, loss = 0.00318258\n",
      "Iteration 960, loss = 0.00318008\n",
      "Iteration 961, loss = 0.00317897\n",
      "Iteration 962, loss = 0.00317711\n",
      "Iteration 963, loss = 0.00317536\n",
      "Iteration 964, loss = 0.00317445\n",
      "Iteration 965, loss = 0.00317204\n",
      "Iteration 966, loss = 0.00317039\n",
      "Iteration 967, loss = 0.00316898\n",
      "Iteration 968, loss = 0.00316666\n",
      "Iteration 969, loss = 0.00316494\n",
      "Iteration 970, loss = 0.00316338\n",
      "Iteration 971, loss = 0.00316117\n",
      "Iteration 972, loss = 0.00316418\n",
      "Iteration 973, loss = 0.00315858\n",
      "Iteration 974, loss = 0.00315627\n",
      "Iteration 975, loss = 0.00315524\n",
      "Iteration 976, loss = 0.00315322\n",
      "Iteration 977, loss = 0.00315163\n",
      "Iteration 978, loss = 0.00315019\n",
      "Iteration 979, loss = 0.00314846\n",
      "Iteration 980, loss = 0.00314588\n",
      "Iteration 981, loss = 0.00314509\n",
      "Iteration 982, loss = 0.00314304\n",
      "Iteration 983, loss = 0.00314217\n",
      "Iteration 984, loss = 0.00313916\n",
      "Iteration 985, loss = 0.00313772\n",
      "Iteration 986, loss = 0.00313767\n",
      "Iteration 987, loss = 0.00313634\n",
      "Iteration 988, loss = 0.00313327\n",
      "Iteration 989, loss = 0.00313067\n",
      "Iteration 990, loss = 0.00313013\n",
      "Iteration 991, loss = 0.00312769\n",
      "Iteration 992, loss = 0.00312590\n",
      "Iteration 993, loss = 0.00312561\n",
      "Iteration 994, loss = 0.00312292\n",
      "Iteration 995, loss = 0.00312094\n",
      "Iteration 996, loss = 0.00311950\n",
      "Iteration 997, loss = 0.00311745\n",
      "Iteration 998, loss = 0.00311577\n",
      "Iteration 999, loss = 0.00311442\n",
      "Iteration 1000, loss = 0.00311421\n",
      "Iteration 1001, loss = 0.00311139\n",
      "Iteration 1002, loss = 0.00310931\n",
      "Iteration 1003, loss = 0.00310791\n",
      "Iteration 1004, loss = 0.00310689\n",
      "Iteration 1005, loss = 0.00310456\n",
      "Iteration 1006, loss = 0.00310345\n",
      "Iteration 1007, loss = 0.00310176\n",
      "Iteration 1008, loss = 0.00310103\n",
      "Iteration 1009, loss = 0.00309813\n",
      "Iteration 1010, loss = 0.00309719\n",
      "Iteration 1011, loss = 0.00309512\n",
      "Iteration 1012, loss = 0.00309356\n",
      "Iteration 1013, loss = 0.00309278\n",
      "Iteration 1014, loss = 0.00309101\n",
      "Iteration 1015, loss = 0.00308922\n",
      "Iteration 1016, loss = 0.00308702\n",
      "Iteration 1017, loss = 0.00308549\n",
      "Iteration 1018, loss = 0.00308393\n",
      "Iteration 1019, loss = 0.00308270\n",
      "Iteration 1020, loss = 0.00308144\n",
      "Iteration 1021, loss = 0.00307969\n",
      "Iteration 1022, loss = 0.00307795\n",
      "Iteration 1023, loss = 0.00307571\n",
      "Iteration 1024, loss = 0.00307497\n",
      "Iteration 1025, loss = 0.00307413\n",
      "Iteration 1026, loss = 0.00307184\n",
      "Iteration 1027, loss = 0.00306997\n",
      "Iteration 1028, loss = 0.00306911\n",
      "Iteration 1029, loss = 0.00306767\n",
      "Iteration 1030, loss = 0.00306586\n",
      "Iteration 1031, loss = 0.00306416\n",
      "Iteration 1032, loss = 0.00306302\n",
      "Iteration 1033, loss = 0.00306131\n",
      "Iteration 1034, loss = 0.00305895\n",
      "Iteration 1035, loss = 0.00305743\n",
      "Iteration 1036, loss = 0.00305670\n",
      "Iteration 1037, loss = 0.00305516\n",
      "Iteration 1038, loss = 0.00305434\n",
      "Iteration 1039, loss = 0.00305315\n",
      "Iteration 1040, loss = 0.00305032\n",
      "Iteration 1041, loss = 0.00304959\n",
      "Iteration 1042, loss = 0.00304697\n",
      "Iteration 1043, loss = 0.00304543\n",
      "Iteration 1044, loss = 0.00304487\n",
      "Iteration 1045, loss = 0.00304326\n",
      "Iteration 1046, loss = 0.00304100\n",
      "Iteration 1047, loss = 0.00303970\n",
      "Iteration 1048, loss = 0.00303787\n",
      "Iteration 1049, loss = 0.00303796\n",
      "Iteration 1050, loss = 0.00303550\n",
      "Iteration 1051, loss = 0.00303362\n",
      "Iteration 1052, loss = 0.00303280\n",
      "Iteration 1053, loss = 0.00303101\n",
      "Iteration 1054, loss = 0.00302981\n",
      "Iteration 1055, loss = 0.00302899\n",
      "Iteration 1056, loss = 0.00302769\n",
      "Iteration 1057, loss = 0.00302620\n",
      "Iteration 1058, loss = 0.00302385\n",
      "Iteration 1059, loss = 0.00302221\n",
      "Iteration 1060, loss = 0.00302089\n",
      "Iteration 1061, loss = 0.00301940\n",
      "Iteration 1062, loss = 0.00301903\n",
      "Iteration 1063, loss = 0.00301596\n",
      "Iteration 1064, loss = 0.00301521\n",
      "Iteration 1065, loss = 0.00301431\n",
      "Iteration 1066, loss = 0.00301205\n",
      "Iteration 1067, loss = 0.00301054\n",
      "Iteration 1068, loss = 0.00300975\n",
      "Iteration 1069, loss = 0.00300805\n",
      "Iteration 1070, loss = 0.00300708\n",
      "Iteration 1071, loss = 0.00300535\n",
      "Iteration 1072, loss = 0.00300440\n",
      "Iteration 1073, loss = 0.00300258\n",
      "Iteration 1074, loss = 0.00300066\n",
      "Iteration 1075, loss = 0.00299905\n",
      "Iteration 1076, loss = 0.00299764\n",
      "Iteration 1077, loss = 0.00299712\n",
      "Iteration 1078, loss = 0.00299515\n",
      "Iteration 1079, loss = 0.00299365\n",
      "Iteration 1080, loss = 0.00299183\n",
      "Iteration 1081, loss = 0.00299052\n",
      "Iteration 1082, loss = 0.00298969\n",
      "Iteration 1083, loss = 0.00298798\n",
      "Iteration 1084, loss = 0.00298612\n",
      "Iteration 1085, loss = 0.00298694\n",
      "Iteration 1086, loss = 0.00298462\n",
      "Iteration 1087, loss = 0.00298286\n",
      "Iteration 1088, loss = 0.00298100\n",
      "Iteration 1089, loss = 0.00297996\n",
      "Iteration 1090, loss = 0.00297899\n",
      "Iteration 1091, loss = 0.00297734\n",
      "Iteration 1092, loss = 0.00297621\n",
      "Iteration 1093, loss = 0.00297487\n",
      "Iteration 1094, loss = 0.00297342\n",
      "Iteration 1095, loss = 0.00297161\n",
      "Iteration 1096, loss = 0.00297074\n",
      "Iteration 1097, loss = 0.00296837\n",
      "Iteration 1098, loss = 0.00296730\n",
      "Iteration 1099, loss = 0.00296580\n",
      "Iteration 1100, loss = 0.00296491\n",
      "Iteration 1101, loss = 0.00296303\n",
      "Iteration 1102, loss = 0.00296227\n",
      "Iteration 1103, loss = 0.00296302\n",
      "Iteration 1104, loss = 0.00295941\n",
      "Iteration 1105, loss = 0.00295778\n",
      "Iteration 1106, loss = 0.00295991\n",
      "Iteration 1107, loss = 0.00295571\n",
      "Iteration 1108, loss = 0.00295361\n",
      "Iteration 1109, loss = 0.00295526\n",
      "Iteration 1110, loss = 0.00295242\n",
      "Iteration 1111, loss = 0.00295005\n",
      "Iteration 1112, loss = 0.00294879\n",
      "Iteration 1113, loss = 0.00294884\n",
      "Iteration 1114, loss = 0.00294621\n",
      "Iteration 1115, loss = 0.00294488\n",
      "Iteration 1116, loss = 0.00294399\n",
      "Iteration 1117, loss = 0.00294332\n",
      "Iteration 1118, loss = 0.00294079\n",
      "Iteration 1119, loss = 0.00294028\n",
      "Iteration 1120, loss = 0.00293809\n",
      "Iteration 1121, loss = 0.00293772\n",
      "Iteration 1122, loss = 0.00293575\n",
      "Iteration 1123, loss = 0.00293534\n",
      "Iteration 1124, loss = 0.00293352\n",
      "Iteration 1125, loss = 0.00293203\n",
      "Iteration 1126, loss = 0.00293140\n",
      "Iteration 1127, loss = 0.00292883\n",
      "Iteration 1128, loss = 0.00292772\n",
      "Iteration 1129, loss = 0.00292673\n",
      "Iteration 1130, loss = 0.00292505\n",
      "Iteration 1131, loss = 0.00292444\n",
      "Iteration 1132, loss = 0.00292287\n",
      "Iteration 1133, loss = 0.00292149\n",
      "Iteration 1134, loss = 0.00291957\n",
      "Iteration 1135, loss = 0.00291826\n",
      "Iteration 1136, loss = 0.00291755\n",
      "Iteration 1137, loss = 0.00291650\n",
      "Iteration 1138, loss = 0.00291508\n",
      "Iteration 1139, loss = 0.00291340\n",
      "Iteration 1140, loss = 0.00291255\n",
      "Iteration 1141, loss = 0.00291139\n",
      "Iteration 1142, loss = 0.00291085\n",
      "Iteration 1143, loss = 0.00290859\n",
      "Iteration 1144, loss = 0.00290718\n",
      "Iteration 1145, loss = 0.00290584\n",
      "Iteration 1146, loss = 0.00290463\n",
      "Iteration 1147, loss = 0.00290370\n",
      "Iteration 1148, loss = 0.00290228\n",
      "Iteration 1149, loss = 0.00290071\n",
      "Iteration 1150, loss = 0.00290083\n",
      "Iteration 1151, loss = 0.00289888\n",
      "Iteration 1152, loss = 0.00289805\n",
      "Iteration 1153, loss = 0.00289581\n",
      "Iteration 1154, loss = 0.00289465\n",
      "Iteration 1155, loss = 0.00289308\n",
      "Iteration 1156, loss = 0.00289193\n",
      "Iteration 1157, loss = 0.00289093\n",
      "Iteration 1158, loss = 0.00288962\n",
      "Iteration 1159, loss = 0.00288820\n",
      "Iteration 1160, loss = 0.00288725\n",
      "Iteration 1161, loss = 0.00288586\n",
      "Iteration 1162, loss = 0.00288566\n",
      "Iteration 1163, loss = 0.00288444\n",
      "Iteration 1164, loss = 0.00288269\n",
      "Iteration 1165, loss = 0.00288090\n",
      "Iteration 1166, loss = 0.00287957\n",
      "Iteration 1167, loss = 0.00287831\n",
      "Iteration 1168, loss = 0.00287723\n",
      "Iteration 1169, loss = 0.00287576\n",
      "Iteration 1170, loss = 0.00287604\n",
      "Iteration 1171, loss = 0.00287380\n",
      "Iteration 1172, loss = 0.00287246\n",
      "Iteration 1173, loss = 0.00287145\n",
      "Iteration 1174, loss = 0.00287162\n",
      "Iteration 1175, loss = 0.00286930\n",
      "Iteration 1176, loss = 0.00286776\n",
      "Iteration 1177, loss = 0.00286778\n",
      "Iteration 1178, loss = 0.00286619\n",
      "Iteration 1179, loss = 0.00286387\n",
      "Iteration 1180, loss = 0.00286297\n",
      "Iteration 1181, loss = 0.00286260\n",
      "Iteration 1182, loss = 0.00286038\n",
      "Iteration 1183, loss = 0.00285985\n",
      "Iteration 1184, loss = 0.00285789\n",
      "Iteration 1185, loss = 0.00285773\n",
      "Iteration 1186, loss = 0.00285549\n",
      "Iteration 1187, loss = 0.00285402\n",
      "Iteration 1188, loss = 0.00285286\n",
      "Iteration 1189, loss = 0.00285189\n",
      "Iteration 1190, loss = 0.00285073\n",
      "Iteration 1191, loss = 0.00284933\n",
      "Iteration 1192, loss = 0.00284899\n",
      "Iteration 1193, loss = 0.00284896\n",
      "Iteration 1194, loss = 0.00284598\n",
      "Iteration 1195, loss = 0.00284509\n",
      "Iteration 1196, loss = 0.00284453\n",
      "Iteration 1197, loss = 0.00284310\n",
      "Iteration 1198, loss = 0.00284107\n",
      "Iteration 1199, loss = 0.00283989\n",
      "Iteration 1200, loss = 0.00283933\n",
      "Iteration 1201, loss = 0.00283817\n",
      "Iteration 1202, loss = 0.00283605\n",
      "Iteration 1203, loss = 0.00283527\n",
      "Iteration 1204, loss = 0.00283384\n",
      "Iteration 1205, loss = 0.00283330\n",
      "Iteration 1206, loss = 0.00283163\n",
      "Iteration 1207, loss = 0.00283036\n",
      "Iteration 1208, loss = 0.00282940\n",
      "Iteration 1209, loss = 0.00282862\n",
      "Iteration 1210, loss = 0.00282820\n",
      "Iteration 1211, loss = 0.00282605\n",
      "Iteration 1212, loss = 0.00282470\n",
      "Iteration 1213, loss = 0.00282394\n",
      "Iteration 1214, loss = 0.00282293\n",
      "Iteration 1215, loss = 0.00282134\n",
      "Iteration 1216, loss = 0.00282071\n",
      "Iteration 1217, loss = 0.00281904\n",
      "Iteration 1218, loss = 0.00281800\n",
      "Iteration 1219, loss = 0.00281626\n",
      "Iteration 1220, loss = 0.00281524\n",
      "Iteration 1221, loss = 0.00281509\n",
      "Iteration 1222, loss = 0.00281430\n",
      "Iteration 1223, loss = 0.00281339\n",
      "Iteration 1224, loss = 0.00281102\n",
      "Iteration 1225, loss = 0.00280994\n",
      "Iteration 1226, loss = 0.00281000\n",
      "Iteration 1227, loss = 0.00280757\n",
      "Iteration 1228, loss = 0.00280642\n",
      "Iteration 1229, loss = 0.00280493\n",
      "Iteration 1230, loss = 0.00280374\n",
      "Iteration 1231, loss = 0.00280373\n",
      "Iteration 1232, loss = 0.00280188\n",
      "Iteration 1233, loss = 0.00280056\n",
      "Iteration 1234, loss = 0.00279958\n",
      "Iteration 1235, loss = 0.00279839\n",
      "Iteration 1236, loss = 0.00279728\n",
      "Iteration 1237, loss = 0.00279616\n",
      "Iteration 1238, loss = 0.00279548\n",
      "Iteration 1239, loss = 0.00279443\n",
      "Iteration 1240, loss = 0.00279280\n",
      "Iteration 1241, loss = 0.00279257\n",
      "Iteration 1242, loss = 0.00279063\n",
      "Iteration 1243, loss = 0.00278990\n",
      "Iteration 1244, loss = 0.00278919\n",
      "Iteration 1245, loss = 0.00278765\n",
      "Iteration 1246, loss = 0.00278603\n",
      "Iteration 1247, loss = 0.00278570\n",
      "Iteration 1248, loss = 0.00278439\n",
      "Iteration 1249, loss = 0.00278334\n",
      "Iteration 1250, loss = 0.00278152\n",
      "Iteration 1251, loss = 0.00278137\n",
      "Iteration 1252, loss = 0.00277965\n",
      "Iteration 1253, loss = 0.00277838\n",
      "Iteration 1254, loss = 0.00277713\n",
      "Iteration 1255, loss = 0.00277593\n",
      "Iteration 1256, loss = 0.00277535\n",
      "Iteration 1257, loss = 0.00277454\n",
      "Iteration 1258, loss = 0.00277272\n",
      "Iteration 1259, loss = 0.00277149\n",
      "Iteration 1260, loss = 0.00277165\n",
      "Iteration 1261, loss = 0.00276992\n",
      "Iteration 1262, loss = 0.00276825\n",
      "Iteration 1263, loss = 0.00276756\n",
      "Iteration 1264, loss = 0.00276692\n",
      "Iteration 1265, loss = 0.00276545\n",
      "Iteration 1266, loss = 0.00276399\n",
      "Iteration 1267, loss = 0.00276374\n",
      "Iteration 1268, loss = 0.00276153\n",
      "Iteration 1269, loss = 0.00276135\n",
      "Iteration 1270, loss = 0.00276040\n",
      "Iteration 1271, loss = 0.00275884\n",
      "Iteration 1272, loss = 0.00275732\n",
      "Iteration 1273, loss = 0.00275646\n",
      "Iteration 1274, loss = 0.00275518\n",
      "Iteration 1275, loss = 0.00275475\n",
      "Iteration 1276, loss = 0.00275308\n",
      "Iteration 1277, loss = 0.00275214\n",
      "Iteration 1278, loss = 0.00275113\n",
      "Iteration 1279, loss = 0.00274980\n",
      "Iteration 1280, loss = 0.00274888\n",
      "Iteration 1281, loss = 0.00274801\n",
      "Iteration 1282, loss = 0.00274746\n",
      "Iteration 1283, loss = 0.00274623\n",
      "Iteration 1284, loss = 0.00274481\n",
      "Iteration 1285, loss = 0.00274415\n",
      "Iteration 1286, loss = 0.00274241\n",
      "Iteration 1287, loss = 0.00274138\n",
      "Iteration 1288, loss = 0.00274027\n",
      "Iteration 1289, loss = 0.00274008\n",
      "Iteration 1290, loss = 0.00273800\n",
      "Iteration 1291, loss = 0.00273759\n",
      "Iteration 1292, loss = 0.00273581\n",
      "Iteration 1293, loss = 0.00273462\n",
      "Iteration 1294, loss = 0.00273411\n",
      "Iteration 1295, loss = 0.00273313\n",
      "Iteration 1296, loss = 0.00273177\n",
      "Iteration 1297, loss = 0.00273044\n",
      "Iteration 1298, loss = 0.00272976\n",
      "Iteration 1299, loss = 0.00272879\n",
      "Iteration 1300, loss = 0.00272725\n",
      "Iteration 1301, loss = 0.00272620\n",
      "Iteration 1302, loss = 0.00272536\n",
      "Iteration 1303, loss = 0.00272413\n",
      "Iteration 1304, loss = 0.00272326\n",
      "Iteration 1305, loss = 0.00272197\n",
      "Iteration 1306, loss = 0.00272172\n",
      "Iteration 1307, loss = 0.00272058\n",
      "Iteration 1308, loss = 0.00271905\n",
      "Iteration 1309, loss = 0.00271782\n",
      "Iteration 1310, loss = 0.00271666\n",
      "Iteration 1311, loss = 0.00271582\n",
      "Iteration 1312, loss = 0.00271503\n",
      "Iteration 1313, loss = 0.00271380\n",
      "Iteration 1314, loss = 0.00271275\n",
      "Iteration 1315, loss = 0.00271241\n",
      "Iteration 1316, loss = 0.00271070\n",
      "Iteration 1317, loss = 0.00271014\n",
      "Iteration 1318, loss = 0.00270885\n",
      "Iteration 1319, loss = 0.00270807\n",
      "Iteration 1320, loss = 0.00270645\n",
      "Iteration 1321, loss = 0.00270532\n",
      "Iteration 1322, loss = 0.00270421\n",
      "Iteration 1323, loss = 0.00270328\n",
      "Iteration 1324, loss = 0.00270280\n",
      "Iteration 1325, loss = 0.00270153\n",
      "Iteration 1326, loss = 0.00270006\n",
      "Iteration 1327, loss = 0.00269979\n",
      "Iteration 1328, loss = 0.00269841\n",
      "Iteration 1329, loss = 0.00269732\n",
      "Iteration 1330, loss = 0.00269627\n",
      "Iteration 1331, loss = 0.00269516\n",
      "Iteration 1332, loss = 0.00269390\n",
      "Iteration 1333, loss = 0.00269335\n",
      "Iteration 1334, loss = 0.00269265\n",
      "Iteration 1335, loss = 0.00269109\n",
      "Iteration 1336, loss = 0.00269042\n",
      "Iteration 1337, loss = 0.00268922\n",
      "Iteration 1338, loss = 0.00268798\n",
      "Iteration 1339, loss = 0.00268685\n",
      "Iteration 1340, loss = 0.00268617\n",
      "Iteration 1341, loss = 0.00268520\n",
      "Iteration 1342, loss = 0.00268404\n",
      "Iteration 1343, loss = 0.00268294\n",
      "Iteration 1344, loss = 0.00268184\n",
      "Iteration 1345, loss = 0.00268063\n",
      "Iteration 1346, loss = 0.00268008\n",
      "Iteration 1347, loss = 0.00268060\n",
      "Iteration 1348, loss = 0.00267760\n",
      "Iteration 1349, loss = 0.00267691\n",
      "Iteration 1350, loss = 0.00267649\n",
      "Iteration 1351, loss = 0.00267515\n",
      "Iteration 1352, loss = 0.00267373\n",
      "Iteration 1353, loss = 0.00267299\n",
      "Iteration 1354, loss = 0.00267185\n",
      "Iteration 1355, loss = 0.00267092\n",
      "Iteration 1356, loss = 0.00267004\n",
      "Iteration 1357, loss = 0.00266883\n",
      "Iteration 1358, loss = 0.00266764\n",
      "Iteration 1359, loss = 0.00266675\n",
      "Iteration 1360, loss = 0.00266578\n",
      "Iteration 1361, loss = 0.00266448\n",
      "Iteration 1362, loss = 0.00266351\n",
      "Iteration 1363, loss = 0.00266245\n",
      "Iteration 1364, loss = 0.00266174\n",
      "Iteration 1365, loss = 0.00266069\n",
      "Iteration 1366, loss = 0.00265965\n",
      "Iteration 1367, loss = 0.00265875\n",
      "Iteration 1368, loss = 0.00265749\n",
      "Iteration 1369, loss = 0.00265656\n",
      "Iteration 1370, loss = 0.00265582\n",
      "Iteration 1371, loss = 0.00265450\n",
      "Iteration 1372, loss = 0.00265370\n",
      "Iteration 1373, loss = 0.00265306\n",
      "Iteration 1374, loss = 0.00265159\n",
      "Iteration 1375, loss = 0.00265052\n",
      "Iteration 1376, loss = 0.00265052\n",
      "Iteration 1377, loss = 0.00264881\n",
      "Iteration 1378, loss = 0.00264855\n",
      "Iteration 1379, loss = 0.00264785\n",
      "Iteration 1380, loss = 0.00264580\n",
      "Iteration 1381, loss = 0.00264499\n",
      "Iteration 1382, loss = 0.00264372\n",
      "Iteration 1383, loss = 0.00264298\n",
      "Iteration 1384, loss = 0.00264174\n",
      "Iteration 1385, loss = 0.00264114\n",
      "Iteration 1386, loss = 0.00264083\n",
      "Iteration 1387, loss = 0.00263914\n",
      "Iteration 1388, loss = 0.00263842\n",
      "Iteration 1389, loss = 0.00263715\n",
      "Iteration 1390, loss = 0.00263606\n",
      "Iteration 1391, loss = 0.00263487\n",
      "Iteration 1392, loss = 0.00263494\n",
      "Iteration 1393, loss = 0.00263381\n",
      "Iteration 1394, loss = 0.00263235\n",
      "Iteration 1395, loss = 0.00263193\n",
      "Iteration 1396, loss = 0.00262998\n",
      "Iteration 1397, loss = 0.00262927\n",
      "Iteration 1398, loss = 0.00262860\n",
      "Iteration 1399, loss = 0.00262722\n",
      "Iteration 1400, loss = 0.00262617\n",
      "Iteration 1401, loss = 0.00262522\n",
      "Iteration 1402, loss = 0.00262429\n",
      "Iteration 1403, loss = 0.00262329\n",
      "Iteration 1404, loss = 0.00262210\n",
      "Iteration 1405, loss = 0.00262139\n",
      "Iteration 1406, loss = 0.00262076\n",
      "Iteration 1407, loss = 0.00261948\n",
      "Iteration 1408, loss = 0.00261866\n",
      "Iteration 1409, loss = 0.00261724\n",
      "Iteration 1410, loss = 0.00261655\n",
      "Iteration 1411, loss = 0.00261556\n",
      "Iteration 1412, loss = 0.00261522\n",
      "Iteration 1413, loss = 0.00261455\n",
      "Iteration 1414, loss = 0.00261257\n",
      "Iteration 1415, loss = 0.00261229\n",
      "Iteration 1416, loss = 0.00261090\n",
      "Iteration 1417, loss = 0.00261011\n",
      "Iteration 1418, loss = 0.00260916\n",
      "Iteration 1419, loss = 0.00260806\n",
      "Iteration 1420, loss = 0.00260703\n",
      "Iteration 1421, loss = 0.00260615\n",
      "Iteration 1422, loss = 0.00260499\n",
      "Iteration 1423, loss = 0.00260422\n",
      "Iteration 1424, loss = 0.00260302\n",
      "Iteration 1425, loss = 0.00260305\n",
      "Iteration 1426, loss = 0.00260102\n",
      "Iteration 1427, loss = 0.00260035\n",
      "Iteration 1428, loss = 0.00260033\n",
      "Iteration 1429, loss = 0.00259821\n",
      "Iteration 1430, loss = 0.00259763\n",
      "Iteration 1431, loss = 0.00259653\n",
      "Iteration 1432, loss = 0.00259697\n",
      "Iteration 1433, loss = 0.00259488\n",
      "Iteration 1434, loss = 0.00259337\n",
      "Iteration 1435, loss = 0.00259238\n",
      "Iteration 1436, loss = 0.00259147\n",
      "Iteration 1437, loss = 0.00259084\n",
      "Iteration 1438, loss = 0.00258970\n",
      "Iteration 1439, loss = 0.00258868\n",
      "Iteration 1440, loss = 0.00258811\n",
      "Iteration 1441, loss = 0.00258688\n",
      "Iteration 1442, loss = 0.00258664\n",
      "Iteration 1443, loss = 0.00258559\n",
      "Iteration 1444, loss = 0.00258375\n",
      "Iteration 1445, loss = 0.00258309\n",
      "Iteration 1446, loss = 0.00258214\n",
      "Iteration 1447, loss = 0.00258118\n",
      "Iteration 1448, loss = 0.00258009\n",
      "Iteration 1449, loss = 0.00257930\n",
      "Iteration 1450, loss = 0.00257833\n",
      "Iteration 1451, loss = 0.00257759\n",
      "Iteration 1452, loss = 0.00257669\n",
      "Iteration 1453, loss = 0.00257563\n",
      "Iteration 1454, loss = 0.00257448\n",
      "Iteration 1455, loss = 0.00257390\n",
      "Iteration 1456, loss = 0.00257337\n",
      "Iteration 1457, loss = 0.00257174\n",
      "Iteration 1458, loss = 0.00257093\n",
      "Iteration 1459, loss = 0.00256973\n",
      "Iteration 1460, loss = 0.00256897\n",
      "Iteration 1461, loss = 0.00256811\n",
      "Iteration 1462, loss = 0.00256759\n",
      "Iteration 1463, loss = 0.00256647\n",
      "Iteration 1464, loss = 0.00256628\n",
      "Iteration 1465, loss = 0.00256458\n",
      "Iteration 1466, loss = 0.00256367\n",
      "Iteration 1467, loss = 0.00256277\n",
      "Iteration 1468, loss = 0.00256199\n",
      "Iteration 1469, loss = 0.00256056\n",
      "Iteration 1470, loss = 0.00255984\n",
      "Iteration 1471, loss = 0.00255878\n",
      "Iteration 1472, loss = 0.00255812\n",
      "Iteration 1473, loss = 0.00255713\n",
      "Iteration 1474, loss = 0.00255595\n",
      "Iteration 1475, loss = 0.00255594\n",
      "Iteration 1476, loss = 0.00255500\n",
      "Iteration 1477, loss = 0.00255314\n",
      "Iteration 1478, loss = 0.00255255\n",
      "Iteration 1479, loss = 0.00255165\n",
      "Iteration 1480, loss = 0.00255072\n",
      "Iteration 1481, loss = 0.00254961\n",
      "Iteration 1482, loss = 0.00254876\n",
      "Iteration 1483, loss = 0.00254781\n",
      "Iteration 1484, loss = 0.00254709\n",
      "Iteration 1485, loss = 0.00254600\n",
      "Iteration 1486, loss = 0.00254492\n",
      "Iteration 1487, loss = 0.00254463\n",
      "Iteration 1488, loss = 0.00254302\n",
      "Iteration 1489, loss = 0.00254195\n",
      "Iteration 1490, loss = 0.00254110\n",
      "Iteration 1491, loss = 0.00254150\n",
      "Iteration 1492, loss = 0.00253970\n",
      "Iteration 1493, loss = 0.00253809\n",
      "Iteration 1494, loss = 0.00253743\n",
      "Iteration 1495, loss = 0.00253665\n",
      "Iteration 1496, loss = 0.00253588\n",
      "Iteration 1497, loss = 0.00253510\n",
      "Iteration 1498, loss = 0.00253438\n",
      "Iteration 1499, loss = 0.00253280\n",
      "Iteration 1500, loss = 0.00253203\n",
      "Iteration 1501, loss = 0.00253100\n",
      "Iteration 1502, loss = 0.00253018\n",
      "Iteration 1503, loss = 0.00252931\n",
      "Iteration 1504, loss = 0.00252817\n",
      "Iteration 1505, loss = 0.00252716\n",
      "Iteration 1506, loss = 0.00252727\n",
      "Iteration 1507, loss = 0.00252553\n",
      "Iteration 1508, loss = 0.00252474\n",
      "Iteration 1509, loss = 0.00252416\n",
      "Iteration 1510, loss = 0.00252299\n",
      "Iteration 1511, loss = 0.00252231\n",
      "Iteration 1512, loss = 0.00252189\n",
      "Iteration 1513, loss = 0.00252041\n",
      "Iteration 1514, loss = 0.00251909\n",
      "Iteration 1515, loss = 0.00251910\n",
      "Iteration 1516, loss = 0.00251802\n",
      "Iteration 1517, loss = 0.00251678\n",
      "Iteration 1518, loss = 0.00251551\n",
      "Iteration 1519, loss = 0.00251473\n",
      "Iteration 1520, loss = 0.00251425\n",
      "Iteration 1521, loss = 0.00251302\n",
      "Iteration 1522, loss = 0.00251237\n",
      "Iteration 1523, loss = 0.00251118\n",
      "Iteration 1524, loss = 0.00251005\n",
      "Iteration 1525, loss = 0.00250899\n",
      "Iteration 1526, loss = 0.00250846\n",
      "Iteration 1527, loss = 0.00250765\n",
      "Iteration 1528, loss = 0.00250675\n",
      "Iteration 1529, loss = 0.00250570\n",
      "Iteration 1530, loss = 0.00250496\n",
      "Iteration 1531, loss = 0.00250391\n",
      "Iteration 1532, loss = 0.00250325\n",
      "Iteration 1533, loss = 0.00250326\n",
      "Iteration 1534, loss = 0.00250125\n",
      "Iteration 1535, loss = 0.00250037\n",
      "Iteration 1536, loss = 0.00249893\n",
      "Iteration 1537, loss = 0.00249883\n",
      "Iteration 1538, loss = 0.00249773\n",
      "Iteration 1539, loss = 0.00249656\n",
      "Iteration 1540, loss = 0.00249594\n",
      "Iteration 1541, loss = 0.00249576\n",
      "Iteration 1542, loss = 0.00249360\n",
      "Iteration 1543, loss = 0.00249322\n",
      "Iteration 1544, loss = 0.00249206\n",
      "Iteration 1545, loss = 0.00249167\n",
      "Iteration 1546, loss = 0.00249053\n",
      "Iteration 1547, loss = 0.00248944\n",
      "Iteration 1548, loss = 0.00248838\n",
      "Iteration 1549, loss = 0.00248747\n",
      "Iteration 1550, loss = 0.00248665\n",
      "Iteration 1551, loss = 0.00248597\n",
      "Iteration 1552, loss = 0.00248452\n",
      "Iteration 1553, loss = 0.00248368\n",
      "Iteration 1554, loss = 0.00248272\n",
      "Iteration 1555, loss = 0.00248219\n",
      "Iteration 1556, loss = 0.00248100\n",
      "Iteration 1557, loss = 0.00248001\n",
      "Iteration 1558, loss = 0.00247972\n",
      "Iteration 1559, loss = 0.00247811\n",
      "Iteration 1560, loss = 0.00247719\n",
      "Iteration 1561, loss = 0.00247711\n",
      "Iteration 1562, loss = 0.00247591\n",
      "Iteration 1563, loss = 0.00247463\n",
      "Iteration 1564, loss = 0.00247520\n",
      "Iteration 1565, loss = 0.00247285\n",
      "Iteration 1566, loss = 0.00247222\n",
      "Iteration 1567, loss = 0.00247059\n",
      "Iteration 1568, loss = 0.00246972\n",
      "Iteration 1569, loss = 0.00246954\n",
      "Iteration 1570, loss = 0.00246796\n",
      "Iteration 1571, loss = 0.00246902\n",
      "Iteration 1572, loss = 0.00246720\n",
      "Iteration 1573, loss = 0.00246551\n",
      "Iteration 1574, loss = 0.00246698\n",
      "Iteration 1575, loss = 0.00246375\n",
      "Iteration 1576, loss = 0.00246430\n",
      "Iteration 1577, loss = 0.00246309\n",
      "Iteration 1578, loss = 0.00246096\n",
      "Iteration 1579, loss = 0.00246074\n",
      "Iteration 1580, loss = 0.00245961\n",
      "Iteration 1581, loss = 0.00245759\n",
      "Iteration 1582, loss = 0.00245798\n",
      "Iteration 1583, loss = 0.00245680\n",
      "Iteration 1584, loss = 0.00245541\n",
      "Iteration 1585, loss = 0.00245460\n",
      "Iteration 1586, loss = 0.00245431\n",
      "Iteration 1587, loss = 0.00245294\n",
      "Iteration 1588, loss = 0.00245238\n",
      "Iteration 1589, loss = 0.00245121\n",
      "Iteration 1590, loss = 0.00245006\n",
      "Iteration 1591, loss = 0.00244916\n",
      "Iteration 1592, loss = 0.00244806\n",
      "Iteration 1593, loss = 0.00244691\n",
      "Iteration 1594, loss = 0.00244627\n",
      "Iteration 1595, loss = 0.00244535\n",
      "Iteration 1596, loss = 0.00244479\n",
      "Iteration 1597, loss = 0.00244340\n",
      "Iteration 1598, loss = 0.00244257\n",
      "Iteration 1599, loss = 0.00244191\n",
      "Iteration 1600, loss = 0.00244065\n",
      "Iteration 1601, loss = 0.00243996\n",
      "Iteration 1602, loss = 0.00243897\n",
      "Iteration 1603, loss = 0.00243818\n",
      "Iteration 1604, loss = 0.00243794\n",
      "Iteration 1605, loss = 0.00243625\n",
      "Iteration 1606, loss = 0.00243518\n",
      "Iteration 1607, loss = 0.00243481\n",
      "Iteration 1608, loss = 0.00243385\n",
      "Iteration 1609, loss = 0.00243405\n",
      "Iteration 1610, loss = 0.00243193\n",
      "Iteration 1611, loss = 0.00243106\n",
      "Iteration 1612, loss = 0.00243037\n",
      "Iteration 1613, loss = 0.00242947\n",
      "Iteration 1614, loss = 0.00242830\n",
      "Iteration 1615, loss = 0.00242887\n",
      "Iteration 1616, loss = 0.00242628\n",
      "Iteration 1617, loss = 0.00242539\n",
      "Iteration 1618, loss = 0.00242462\n",
      "Iteration 1619, loss = 0.00242480\n",
      "Iteration 1620, loss = 0.00242264\n",
      "Iteration 1621, loss = 0.00242195\n",
      "Iteration 1622, loss = 0.00242137\n",
      "Iteration 1623, loss = 0.00242185\n",
      "Iteration 1624, loss = 0.00242012\n",
      "Iteration 1625, loss = 0.00241816\n",
      "Iteration 1626, loss = 0.00241784\n",
      "Iteration 1627, loss = 0.00241649\n",
      "Iteration 1628, loss = 0.00241645\n",
      "Iteration 1629, loss = 0.00241488\n",
      "Iteration 1630, loss = 0.00241423\n",
      "Iteration 1631, loss = 0.00241308\n",
      "Iteration 1632, loss = 0.00241234\n",
      "Iteration 1633, loss = 0.00241114\n",
      "Iteration 1634, loss = 0.00241047\n",
      "Iteration 1635, loss = 0.00240985\n",
      "Iteration 1636, loss = 0.00240838\n",
      "Iteration 1637, loss = 0.00240759\n",
      "Iteration 1638, loss = 0.00240665\n",
      "Iteration 1639, loss = 0.00240699\n",
      "Iteration 1640, loss = 0.00240531\n",
      "Iteration 1641, loss = 0.00240426\n",
      "Iteration 1642, loss = 0.00240308\n",
      "Iteration 1643, loss = 0.00240273\n",
      "Iteration 1644, loss = 0.00240107\n",
      "Iteration 1645, loss = 0.00240051\n",
      "Iteration 1646, loss = 0.00240110\n",
      "Iteration 1647, loss = 0.00239874\n",
      "Iteration 1648, loss = 0.00239820\n",
      "Iteration 1649, loss = 0.00239746\n",
      "Iteration 1650, loss = 0.00239688\n",
      "Iteration 1651, loss = 0.00239640\n",
      "Iteration 1652, loss = 0.00239424\n",
      "Iteration 1653, loss = 0.00239345\n",
      "Iteration 1654, loss = 0.00239257\n",
      "Iteration 1655, loss = 0.00239219\n",
      "Iteration 1656, loss = 0.00239121\n",
      "Iteration 1657, loss = 0.00239029\n",
      "Iteration 1658, loss = 0.00238915\n",
      "Iteration 1659, loss = 0.00238815\n",
      "Iteration 1660, loss = 0.00238720\n",
      "Iteration 1661, loss = 0.00238672\n",
      "Iteration 1662, loss = 0.00238553\n",
      "Iteration 1663, loss = 0.00238459\n",
      "Iteration 1664, loss = 0.00238440\n",
      "Iteration 1665, loss = 0.00238319\n",
      "Iteration 1666, loss = 0.00238217\n",
      "Iteration 1667, loss = 0.00238307\n",
      "Iteration 1668, loss = 0.00238062\n",
      "Iteration 1669, loss = 0.00238042\n",
      "Iteration 1670, loss = 0.00237890\n",
      "Iteration 1671, loss = 0.00237861\n",
      "Iteration 1672, loss = 0.00237788\n",
      "Iteration 1673, loss = 0.00237628\n",
      "Iteration 1674, loss = 0.00237572\n",
      "Iteration 1675, loss = 0.00237430\n",
      "Iteration 1676, loss = 0.00237362\n",
      "Iteration 1677, loss = 0.00237323\n",
      "Iteration 1678, loss = 0.00237192\n",
      "Iteration 1679, loss = 0.00237097\n",
      "Iteration 1680, loss = 0.00237036\n",
      "Iteration 1681, loss = 0.00236883\n",
      "Iteration 1682, loss = 0.00236931\n",
      "Iteration 1683, loss = 0.00236795\n",
      "Iteration 1684, loss = 0.00236702\n",
      "Iteration 1685, loss = 0.00236567\n",
      "Iteration 1686, loss = 0.00236460\n",
      "Iteration 1687, loss = 0.00236387\n",
      "Iteration 1688, loss = 0.00236302\n",
      "Iteration 1689, loss = 0.00236216\n",
      "Iteration 1690, loss = 0.00236125\n",
      "Iteration 1691, loss = 0.00236158\n",
      "Iteration 1692, loss = 0.00236022\n",
      "Iteration 1693, loss = 0.00235948\n",
      "Iteration 1694, loss = 0.00235838\n",
      "Iteration 1695, loss = 0.00235775\n",
      "Iteration 1696, loss = 0.00235646\n",
      "Iteration 1697, loss = 0.00235771\n",
      "Iteration 1698, loss = 0.00235479\n",
      "Iteration 1699, loss = 0.00235369\n",
      "Iteration 1700, loss = 0.00235364\n",
      "Iteration 1701, loss = 0.00235198\n",
      "Iteration 1702, loss = 0.00235229\n",
      "Iteration 1703, loss = 0.00235026\n",
      "Iteration 1704, loss = 0.00235049\n",
      "Iteration 1705, loss = 0.00234980\n",
      "Iteration 1706, loss = 0.00234795\n",
      "Iteration 1707, loss = 0.00234746\n",
      "Iteration 1708, loss = 0.00234670\n",
      "Iteration 1709, loss = 0.00234573\n",
      "Iteration 1710, loss = 0.00234484\n",
      "Iteration 1711, loss = 0.00234422\n",
      "Iteration 1712, loss = 0.00234339\n",
      "Iteration 1713, loss = 0.00234206\n",
      "Iteration 1714, loss = 0.00234133\n",
      "Iteration 1715, loss = 0.00234115\n",
      "Iteration 1716, loss = 0.00233989\n",
      "Iteration 1717, loss = 0.00233916\n",
      "Iteration 1718, loss = 0.00233789\n",
      "Iteration 1719, loss = 0.00233784\n",
      "Iteration 1720, loss = 0.00233640\n",
      "Iteration 1721, loss = 0.00233546\n",
      "Iteration 1722, loss = 0.00233457\n",
      "Iteration 1723, loss = 0.00233438\n",
      "Iteration 1724, loss = 0.00233256\n",
      "Iteration 1725, loss = 0.00233208\n",
      "Iteration 1726, loss = 0.00233145\n",
      "Iteration 1727, loss = 0.00233038\n",
      "Iteration 1728, loss = 0.00232972\n",
      "Iteration 1729, loss = 0.00232854\n",
      "Iteration 1730, loss = 0.00232870\n",
      "Iteration 1731, loss = 0.00232799\n",
      "Iteration 1732, loss = 0.00232631\n",
      "Iteration 1733, loss = 0.00232538\n",
      "Iteration 1734, loss = 0.00232425\n",
      "Iteration 1735, loss = 0.00232365\n",
      "Iteration 1736, loss = 0.00232239\n",
      "Iteration 1737, loss = 0.00232207\n",
      "Iteration 1738, loss = 0.00232145\n",
      "Iteration 1739, loss = 0.00232006\n",
      "Iteration 1740, loss = 0.00231923\n",
      "Iteration 1741, loss = 0.00231867\n",
      "Iteration 1742, loss = 0.00231814\n",
      "Iteration 1743, loss = 0.00231687\n",
      "Iteration 1744, loss = 0.00231651\n",
      "Iteration 1745, loss = 0.00231549\n",
      "Iteration 1746, loss = 0.00231483\n",
      "Iteration 1747, loss = 0.00231360\n",
      "Iteration 1748, loss = 0.00231307\n",
      "Iteration 1749, loss = 0.00231173\n",
      "Iteration 1750, loss = 0.00231107\n",
      "Iteration 1751, loss = 0.00231023\n",
      "Iteration 1752, loss = 0.00230925\n",
      "Iteration 1753, loss = 0.00230852\n",
      "Iteration 1754, loss = 0.00230790\n",
      "Iteration 1755, loss = 0.00230717\n",
      "Iteration 1756, loss = 0.00230582\n",
      "Iteration 1757, loss = 0.00230508\n",
      "Iteration 1758, loss = 0.00230413\n",
      "Iteration 1759, loss = 0.00230492\n",
      "Iteration 1760, loss = 0.00230259\n",
      "Iteration 1761, loss = 0.00230240\n",
      "Iteration 1762, loss = 0.00230188\n",
      "Iteration 1763, loss = 0.00230074\n",
      "Iteration 1764, loss = 0.00230002\n",
      "Iteration 1765, loss = 0.00229854\n",
      "Iteration 1766, loss = 0.00229828\n",
      "Iteration 1767, loss = 0.00229751\n",
      "Iteration 1768, loss = 0.00229716\n",
      "Iteration 1769, loss = 0.00229615\n",
      "Iteration 1770, loss = 0.00229428\n",
      "Iteration 1771, loss = 0.00229399\n",
      "Iteration 1772, loss = 0.00229299\n",
      "Iteration 1773, loss = 0.00229221\n",
      "Iteration 1774, loss = 0.00229137\n",
      "Iteration 1775, loss = 0.00229026\n",
      "Iteration 1776, loss = 0.00228948\n",
      "Iteration 1777, loss = 0.00228852\n",
      "Iteration 1778, loss = 0.00228820\n",
      "Iteration 1779, loss = 0.00228761\n",
      "Iteration 1780, loss = 0.00228681\n",
      "Iteration 1781, loss = 0.00228552\n",
      "Iteration 1782, loss = 0.00228491\n",
      "Iteration 1783, loss = 0.00228418\n",
      "Iteration 1784, loss = 0.00228308\n",
      "Iteration 1785, loss = 0.00228185\n",
      "Iteration 1786, loss = 0.00228102\n",
      "Iteration 1787, loss = 0.00228065\n",
      "Iteration 1788, loss = 0.00227973\n",
      "Iteration 1789, loss = 0.00227888\n",
      "Iteration 1790, loss = 0.00227853\n",
      "Iteration 1791, loss = 0.00227704\n",
      "Iteration 1792, loss = 0.00227697\n",
      "Iteration 1793, loss = 0.00227551\n",
      "Iteration 1794, loss = 0.00227418\n",
      "Iteration 1795, loss = 0.00227425\n",
      "Iteration 1796, loss = 0.00227329\n",
      "Iteration 1797, loss = 0.00227205\n",
      "Iteration 1798, loss = 0.00227209\n",
      "Iteration 1799, loss = 0.00227049\n",
      "Iteration 1800, loss = 0.00226954\n",
      "Iteration 1801, loss = 0.00226910\n",
      "Iteration 1802, loss = 0.00226842\n",
      "Iteration 1803, loss = 0.00226723\n",
      "Iteration 1804, loss = 0.00226696\n",
      "Iteration 1805, loss = 0.00226583\n",
      "Iteration 1806, loss = 0.00226488\n",
      "Iteration 1807, loss = 0.00226376\n",
      "Iteration 1808, loss = 0.00226296\n",
      "Iteration 1809, loss = 0.00226221\n",
      "Iteration 1810, loss = 0.00226151\n",
      "Iteration 1811, loss = 0.00226057\n",
      "Iteration 1812, loss = 0.00226089\n",
      "Iteration 1813, loss = 0.00225909\n",
      "Iteration 1814, loss = 0.00225815\n",
      "Iteration 1815, loss = 0.00225780\n",
      "Iteration 1816, loss = 0.00225658\n",
      "Iteration 1817, loss = 0.00225568\n",
      "Iteration 1818, loss = 0.00225501\n",
      "Iteration 1819, loss = 0.00225554\n",
      "Iteration 1820, loss = 0.00225392\n",
      "Iteration 1821, loss = 0.00225281\n",
      "Iteration 1822, loss = 0.00225218\n",
      "Iteration 1823, loss = 0.00225146\n",
      "Iteration 1824, loss = 0.00225042\n",
      "Iteration 1825, loss = 0.00224886\n",
      "Iteration 1826, loss = 0.00224832\n",
      "Iteration 1827, loss = 0.00224784\n",
      "Iteration 1828, loss = 0.00224679\n",
      "Iteration 1829, loss = 0.00224576\n",
      "Iteration 1830, loss = 0.00224525\n",
      "Iteration 1831, loss = 0.00224451\n",
      "Iteration 1832, loss = 0.00224382\n",
      "Iteration 1833, loss = 0.00224413\n",
      "Iteration 1834, loss = 0.00224180\n",
      "Iteration 1835, loss = 0.00224127\n",
      "Iteration 1836, loss = 0.00224148\n",
      "Iteration 1837, loss = 0.00223922\n",
      "Iteration 1838, loss = 0.00223971\n",
      "Iteration 1839, loss = 0.00223804\n",
      "Iteration 1840, loss = 0.00223781\n",
      "Iteration 1841, loss = 0.00223707\n",
      "Iteration 1842, loss = 0.00223560\n",
      "Iteration 1843, loss = 0.00223569\n",
      "Iteration 1844, loss = 0.00223353\n",
      "Iteration 1845, loss = 0.00223331\n",
      "Iteration 1846, loss = 0.00223260\n",
      "Iteration 1847, loss = 0.00223165\n",
      "Iteration 1848, loss = 0.00223070\n",
      "Iteration 1849, loss = 0.00222954\n",
      "Iteration 1850, loss = 0.00222922\n",
      "Iteration 1851, loss = 0.00222792\n",
      "Iteration 1852, loss = 0.00222736\n",
      "Iteration 1853, loss = 0.00222664\n",
      "Iteration 1854, loss = 0.00222548\n",
      "Iteration 1855, loss = 0.00222614\n",
      "Iteration 1856, loss = 0.00222516\n",
      "Iteration 1857, loss = 0.00222292\n",
      "Iteration 1858, loss = 0.00222387\n",
      "Iteration 1859, loss = 0.00222135\n",
      "Iteration 1860, loss = 0.00222288\n",
      "Iteration 1861, loss = 0.00221981\n",
      "Iteration 1862, loss = 0.00221991\n",
      "Iteration 1863, loss = 0.00221910\n",
      "Iteration 1864, loss = 0.00221766\n",
      "Iteration 1865, loss = 0.00221766\n",
      "Iteration 1866, loss = 0.00221621\n",
      "Iteration 1867, loss = 0.00221549\n",
      "Iteration 1868, loss = 0.00221614\n",
      "Iteration 1869, loss = 0.00221364\n",
      "Iteration 1870, loss = 0.00221290\n",
      "Iteration 1871, loss = 0.00221138\n",
      "Iteration 1872, loss = 0.00221214\n",
      "Iteration 1873, loss = 0.00221094\n",
      "Iteration 1874, loss = 0.00221103\n",
      "Iteration 1875, loss = 0.00220960\n",
      "Iteration 1876, loss = 0.00220802\n",
      "Iteration 1877, loss = 0.00220789\n",
      "Iteration 1878, loss = 0.00220636\n",
      "Iteration 1879, loss = 0.00220583\n",
      "Iteration 1880, loss = 0.00220464\n",
      "Iteration 1881, loss = 0.00220458\n",
      "Iteration 1882, loss = 0.00220352\n",
      "Iteration 1883, loss = 0.00220249\n",
      "Iteration 1884, loss = 0.00220238\n",
      "Iteration 1885, loss = 0.00220082\n",
      "Iteration 1886, loss = 0.00220026\n",
      "Iteration 1887, loss = 0.00219906\n",
      "Iteration 1888, loss = 0.00219887\n",
      "Iteration 1889, loss = 0.00219795\n",
      "Iteration 1890, loss = 0.00219830\n",
      "Iteration 1891, loss = 0.00219559\n",
      "Iteration 1892, loss = 0.00219632\n",
      "Iteration 1893, loss = 0.00219500\n",
      "Iteration 1894, loss = 0.00219496\n",
      "Iteration 1895, loss = 0.00219421\n",
      "Iteration 1896, loss = 0.00219382\n",
      "Iteration 1897, loss = 0.00219266\n",
      "Iteration 1898, loss = 0.00219080\n",
      "Iteration 1899, loss = 0.00219092\n",
      "Iteration 1900, loss = 0.00218926\n",
      "Iteration 1901, loss = 0.00218833\n",
      "Iteration 1902, loss = 0.00218807\n",
      "Iteration 1903, loss = 0.00218668\n",
      "Iteration 1904, loss = 0.00218629\n",
      "Iteration 1905, loss = 0.00218518\n",
      "Iteration 1906, loss = 0.00218496\n",
      "Iteration 1907, loss = 0.00218310\n",
      "Iteration 1908, loss = 0.00218254\n",
      "Iteration 1909, loss = 0.00218191\n",
      "Iteration 1910, loss = 0.00218184\n",
      "Iteration 1911, loss = 0.00218071\n",
      "Iteration 1912, loss = 0.00217992\n",
      "Iteration 1913, loss = 0.00217982\n",
      "Iteration 1914, loss = 0.00217766\n",
      "Iteration 1915, loss = 0.00217720\n",
      "Iteration 1916, loss = 0.00217664\n",
      "Iteration 1917, loss = 0.00217578\n",
      "Iteration 1918, loss = 0.00217472\n",
      "Iteration 1919, loss = 0.00217417\n",
      "Iteration 1920, loss = 0.00217349\n",
      "Iteration 1921, loss = 0.00217226\n",
      "Iteration 1922, loss = 0.00217194\n",
      "Iteration 1923, loss = 0.00217091\n",
      "Iteration 1924, loss = 0.00217048\n",
      "Iteration 1925, loss = 0.00216950\n",
      "Iteration 1926, loss = 0.00216822\n",
      "Iteration 1927, loss = 0.00216795\n",
      "Iteration 1928, loss = 0.00216791\n",
      "Iteration 1929, loss = 0.00216697\n",
      "Iteration 1930, loss = 0.00216529\n",
      "Iteration 1931, loss = 0.00216448\n",
      "Iteration 1932, loss = 0.00216449\n",
      "Iteration 1933, loss = 0.00216343\n",
      "Iteration 1934, loss = 0.00216236\n",
      "Iteration 1935, loss = 0.00216138\n",
      "Iteration 1936, loss = 0.00216143\n",
      "Iteration 1937, loss = 0.00215982\n",
      "Iteration 1938, loss = 0.00215985\n",
      "Iteration 1939, loss = 0.00215830\n",
      "Iteration 1940, loss = 0.00215749\n",
      "Iteration 1941, loss = 0.00215675\n",
      "Iteration 1942, loss = 0.00215630\n",
      "Iteration 1943, loss = 0.00215596\n",
      "Iteration 1944, loss = 0.00215469\n",
      "Iteration 1945, loss = 0.00215433\n",
      "Iteration 1946, loss = 0.00215267\n",
      "Iteration 1947, loss = 0.00215288\n",
      "Iteration 1948, loss = 0.00215202\n",
      "Iteration 1949, loss = 0.00215043\n",
      "Iteration 1950, loss = 0.00215017\n",
      "Iteration 1951, loss = 0.00214944\n",
      "Iteration 1952, loss = 0.00214824\n",
      "Iteration 1953, loss = 0.00214769\n",
      "Iteration 1954, loss = 0.00214742\n",
      "Iteration 1955, loss = 0.00214620\n",
      "Iteration 1956, loss = 0.00214532\n",
      "Iteration 1957, loss = 0.00214549\n",
      "Iteration 1958, loss = 0.00214382\n",
      "Iteration 1959, loss = 0.00214498\n",
      "Iteration 1960, loss = 0.00214271\n",
      "Iteration 1961, loss = 0.00214126\n",
      "Iteration 1962, loss = 0.00214136\n",
      "Iteration 1963, loss = 0.00214074\n",
      "Iteration 1964, loss = 0.00214017\n",
      "Iteration 1965, loss = 0.00213893\n",
      "Iteration 1966, loss = 0.00213768\n",
      "Iteration 1967, loss = 0.00213800\n",
      "Iteration 1968, loss = 0.00213629\n",
      "Iteration 1969, loss = 0.00213557\n",
      "Iteration 1970, loss = 0.00213601\n",
      "Iteration 1971, loss = 0.00213389\n",
      "Iteration 1972, loss = 0.00213302\n",
      "Iteration 1973, loss = 0.00213283\n",
      "Iteration 1974, loss = 0.00213185\n",
      "Iteration 1975, loss = 0.00213100\n",
      "Iteration 1976, loss = 0.00213037\n",
      "Iteration 1977, loss = 0.00212973\n",
      "Iteration 1978, loss = 0.00212864\n",
      "Iteration 1979, loss = 0.00212826\n",
      "Iteration 1980, loss = 0.00212711\n",
      "Iteration 1981, loss = 0.00212663\n",
      "Iteration 1982, loss = 0.00212565\n",
      "Iteration 1983, loss = 0.00212510\n",
      "Iteration 1984, loss = 0.00212421\n",
      "Iteration 1985, loss = 0.00212341\n",
      "Iteration 1986, loss = 0.00212278\n",
      "Iteration 1987, loss = 0.00212267\n",
      "Iteration 1988, loss = 0.00212125\n",
      "Iteration 1989, loss = 0.00212018\n",
      "Iteration 1990, loss = 0.00211971\n",
      "Iteration 1991, loss = 0.00211864\n",
      "Iteration 1992, loss = 0.00211815\n",
      "Iteration 1993, loss = 0.00211827\n",
      "Iteration 1994, loss = 0.00211654\n",
      "Iteration 1995, loss = 0.00211618\n",
      "Iteration 1996, loss = 0.00211528\n",
      "Iteration 1997, loss = 0.00211436\n",
      "Iteration 1998, loss = 0.00211379\n",
      "Iteration 1999, loss = 0.00211312\n",
      "Iteration 2000, loss = 0.00211210\n",
      "Iteration 2001, loss = 0.00211194\n",
      "Iteration 2002, loss = 0.00211031\n",
      "Iteration 2003, loss = 0.00211001\n",
      "Iteration 2004, loss = 0.00210926\n",
      "Iteration 2005, loss = 0.00210855\n",
      "Iteration 2006, loss = 0.00210769\n",
      "Iteration 2007, loss = 0.00210666\n",
      "Iteration 2008, loss = 0.00210599\n",
      "Iteration 2009, loss = 0.00210588\n",
      "Iteration 2010, loss = 0.00210467\n",
      "Iteration 2011, loss = 0.00210385\n",
      "Iteration 2012, loss = 0.00210294\n",
      "Iteration 2013, loss = 0.00210234\n",
      "Iteration 2014, loss = 0.00210154\n",
      "Iteration 2015, loss = 0.00210107\n",
      "Iteration 2016, loss = 0.00210022\n",
      "Iteration 2017, loss = 0.00209976\n",
      "Iteration 2018, loss = 0.00209887\n",
      "Iteration 2019, loss = 0.00209810\n",
      "Iteration 2020, loss = 0.00209714\n",
      "Iteration 2021, loss = 0.00209631\n",
      "Iteration 2022, loss = 0.00209574\n",
      "Iteration 2023, loss = 0.00209563\n",
      "Iteration 2024, loss = 0.00209410\n",
      "Iteration 2025, loss = 0.00209383\n",
      "Iteration 2026, loss = 0.00209282\n",
      "Iteration 2027, loss = 0.00209199\n",
      "Iteration 2028, loss = 0.00209117\n",
      "Iteration 2029, loss = 0.00209046\n",
      "Iteration 2030, loss = 0.00208971\n",
      "Iteration 2031, loss = 0.00208880\n",
      "Iteration 2032, loss = 0.00208836\n",
      "Iteration 2033, loss = 0.00208748\n",
      "Iteration 2034, loss = 0.00208746\n",
      "Iteration 2035, loss = 0.00208640\n",
      "Iteration 2036, loss = 0.00208583\n",
      "Iteration 2037, loss = 0.00208482\n",
      "Iteration 2038, loss = 0.00208520\n",
      "Iteration 2039, loss = 0.00208354\n",
      "Iteration 2040, loss = 0.00208284\n",
      "Iteration 2041, loss = 0.00208167\n",
      "Iteration 2042, loss = 0.00208091\n",
      "Iteration 2043, loss = 0.00208060\n",
      "Iteration 2044, loss = 0.00207934\n",
      "Iteration 2045, loss = 0.00207917\n",
      "Iteration 2046, loss = 0.00207835\n",
      "Iteration 2047, loss = 0.00207755\n",
      "Iteration 2048, loss = 0.00207671\n",
      "Iteration 2049, loss = 0.00207559\n",
      "Iteration 2050, loss = 0.00207498\n",
      "Iteration 2051, loss = 0.00207398\n",
      "Iteration 2052, loss = 0.00207394\n",
      "Iteration 2053, loss = 0.00207318\n",
      "Iteration 2054, loss = 0.00207331\n",
      "Iteration 2055, loss = 0.00207208\n",
      "Iteration 2056, loss = 0.00207062\n",
      "Iteration 2057, loss = 0.00207128\n",
      "Iteration 2058, loss = 0.00207000\n",
      "Iteration 2059, loss = 0.00206866\n",
      "Iteration 2060, loss = 0.00206773\n",
      "Iteration 2061, loss = 0.00206695\n",
      "Iteration 2062, loss = 0.00206659\n",
      "Iteration 2063, loss = 0.00206585\n",
      "Iteration 2064, loss = 0.00206503\n",
      "Iteration 2065, loss = 0.00206405\n",
      "Iteration 2066, loss = 0.00206376\n",
      "Iteration 2067, loss = 0.00206262\n",
      "Iteration 2068, loss = 0.00206196\n",
      "Iteration 2069, loss = 0.00206151\n",
      "Iteration 2070, loss = 0.00206081\n",
      "Iteration 2071, loss = 0.00205974\n",
      "Iteration 2072, loss = 0.00205975\n",
      "Iteration 2073, loss = 0.00205921\n",
      "Iteration 2074, loss = 0.00205710\n",
      "Iteration 2075, loss = 0.00205685\n",
      "Iteration 2076, loss = 0.00205654\n",
      "Iteration 2077, loss = 0.00205511\n",
      "Iteration 2078, loss = 0.00205464\n",
      "Iteration 2079, loss = 0.00205385\n",
      "Iteration 2080, loss = 0.00205362\n",
      "Iteration 2081, loss = 0.00205245\n",
      "Iteration 2082, loss = 0.00205141\n",
      "Iteration 2083, loss = 0.00205146\n",
      "Iteration 2084, loss = 0.00205009\n",
      "Iteration 2085, loss = 0.00204914\n",
      "Iteration 2086, loss = 0.00204929\n",
      "Iteration 2087, loss = 0.00204865\n",
      "Iteration 2088, loss = 0.00204745\n",
      "Iteration 2089, loss = 0.00204714\n",
      "Iteration 2090, loss = 0.00204566\n",
      "Iteration 2091, loss = 0.00204568\n",
      "Iteration 2092, loss = 0.00204449\n",
      "Iteration 2093, loss = 0.00204474\n",
      "Iteration 2094, loss = 0.00204292\n",
      "Iteration 2095, loss = 0.00204221\n",
      "Iteration 2096, loss = 0.00204197\n",
      "Iteration 2097, loss = 0.00204138\n",
      "Iteration 2098, loss = 0.00204003\n",
      "Iteration 2099, loss = 0.00203928\n",
      "Iteration 2100, loss = 0.00203891\n",
      "Iteration 2101, loss = 0.00203779\n",
      "Iteration 2102, loss = 0.00203725\n",
      "Iteration 2103, loss = 0.00203682\n",
      "Iteration 2104, loss = 0.00203549\n",
      "Iteration 2105, loss = 0.00203514\n",
      "Iteration 2106, loss = 0.00203601\n",
      "Iteration 2107, loss = 0.00203400\n",
      "Iteration 2108, loss = 0.00203270\n",
      "Iteration 2109, loss = 0.00203256\n",
      "Iteration 2110, loss = 0.00203211\n",
      "Iteration 2111, loss = 0.00203086\n",
      "Iteration 2112, loss = 0.00203118\n",
      "Iteration 2113, loss = 0.00202947\n",
      "Iteration 2114, loss = 0.00202925\n",
      "Iteration 2115, loss = 0.00202762\n",
      "Iteration 2116, loss = 0.00202742\n",
      "Iteration 2117, loss = 0.00202637\n",
      "Iteration 2118, loss = 0.00202604\n",
      "Iteration 2119, loss = 0.00202520\n",
      "Iteration 2120, loss = 0.00202485\n",
      "Iteration 2121, loss = 0.00202387\n",
      "Iteration 2122, loss = 0.00202262\n",
      "Iteration 2123, loss = 0.00202234\n",
      "Iteration 2124, loss = 0.00202112\n",
      "Iteration 2125, loss = 0.00202038\n",
      "Iteration 2126, loss = 0.00201977\n",
      "Iteration 2127, loss = 0.00201879\n",
      "Iteration 2128, loss = 0.00201940\n",
      "Iteration 2129, loss = 0.00201800\n",
      "Iteration 2130, loss = 0.00201672\n",
      "Iteration 2131, loss = 0.00201741\n",
      "Iteration 2132, loss = 0.00201646\n",
      "Iteration 2133, loss = 0.00201499\n",
      "Iteration 2134, loss = 0.00201499\n",
      "Iteration 2135, loss = 0.00201288\n",
      "Iteration 2136, loss = 0.00201342\n",
      "Iteration 2137, loss = 0.00201291\n",
      "Iteration 2138, loss = 0.00201213\n",
      "Iteration 2139, loss = 0.00201094\n",
      "Iteration 2140, loss = 0.00201001\n",
      "Iteration 2141, loss = 0.00200885\n",
      "Iteration 2142, loss = 0.00200835\n",
      "Iteration 2143, loss = 0.00200785\n",
      "Iteration 2144, loss = 0.00200684\n",
      "Iteration 2145, loss = 0.00200636\n",
      "Iteration 2146, loss = 0.00200595\n",
      "Iteration 2147, loss = 0.00200460\n",
      "Iteration 2148, loss = 0.00200409\n",
      "Iteration 2149, loss = 0.00200328\n",
      "Iteration 2150, loss = 0.00200302\n",
      "Iteration 2151, loss = 0.00200224\n",
      "Iteration 2152, loss = 0.00200269\n",
      "Iteration 2153, loss = 0.00200075\n",
      "Iteration 2154, loss = 0.00199994\n",
      "Iteration 2155, loss = 0.00199906\n",
      "Iteration 2156, loss = 0.00199822\n",
      "Iteration 2157, loss = 0.00199878\n",
      "Iteration 2158, loss = 0.00199687\n",
      "Iteration 2159, loss = 0.00199586\n",
      "Iteration 2160, loss = 0.00199518\n",
      "Iteration 2161, loss = 0.00199507\n",
      "Iteration 2162, loss = 0.00199429\n",
      "Iteration 2163, loss = 0.00199307\n",
      "Iteration 2164, loss = 0.00199303\n",
      "Iteration 2165, loss = 0.00199263\n",
      "Iteration 2166, loss = 0.00199156\n",
      "Iteration 2167, loss = 0.00199045\n",
      "Iteration 2168, loss = 0.00199043\n",
      "Iteration 2169, loss = 0.00198917\n",
      "Iteration 2170, loss = 0.00198857\n",
      "Iteration 2171, loss = 0.00198786\n",
      "Iteration 2172, loss = 0.00198704\n",
      "Iteration 2173, loss = 0.00198668\n",
      "Iteration 2174, loss = 0.00198532\n",
      "Iteration 2175, loss = 0.00198534\n",
      "Iteration 2176, loss = 0.00198443\n",
      "Iteration 2177, loss = 0.00198358\n",
      "Iteration 2178, loss = 0.00198394\n",
      "Iteration 2179, loss = 0.00198245\n",
      "Iteration 2180, loss = 0.00198432\n",
      "Iteration 2181, loss = 0.00198100\n",
      "Iteration 2182, loss = 0.00198164\n",
      "Iteration 2183, loss = 0.00198033\n",
      "Iteration 2184, loss = 0.00197890\n",
      "Iteration 2185, loss = 0.00197843\n",
      "Iteration 2186, loss = 0.00197803\n",
      "Iteration 2187, loss = 0.00197727\n",
      "Iteration 2188, loss = 0.00197542\n",
      "Iteration 2189, loss = 0.00197509\n",
      "Iteration 2190, loss = 0.00197363\n",
      "Iteration 2191, loss = 0.00197367\n",
      "Iteration 2192, loss = 0.00197275\n",
      "Iteration 2193, loss = 0.00197164\n",
      "Iteration 2194, loss = 0.00197117\n",
      "Iteration 2195, loss = 0.00197094\n",
      "Iteration 2196, loss = 0.00197020\n",
      "Iteration 2197, loss = 0.00196893\n",
      "Iteration 2198, loss = 0.00196824\n",
      "Iteration 2199, loss = 0.00196807\n",
      "Iteration 2200, loss = 0.00196672\n",
      "Iteration 2201, loss = 0.00196679\n",
      "Iteration 2202, loss = 0.00196624\n",
      "Iteration 2203, loss = 0.00196473\n",
      "Iteration 2204, loss = 0.00196445\n",
      "Iteration 2205, loss = 0.00196404\n",
      "Iteration 2206, loss = 0.00196283\n",
      "Iteration 2207, loss = 0.00196293\n",
      "Iteration 2208, loss = 0.00196102\n",
      "Iteration 2209, loss = 0.00196090\n",
      "Iteration 2210, loss = 0.00196040\n",
      "Iteration 2211, loss = 0.00195941\n",
      "Iteration 2212, loss = 0.00195862\n",
      "Iteration 2213, loss = 0.00195778\n",
      "Iteration 2214, loss = 0.00195683\n",
      "Iteration 2215, loss = 0.00195651\n",
      "Iteration 2216, loss = 0.00195547\n",
      "Iteration 2217, loss = 0.00195587\n",
      "Iteration 2218, loss = 0.00195425\n",
      "Iteration 2219, loss = 0.00195338\n",
      "Iteration 2220, loss = 0.00195353\n",
      "Iteration 2221, loss = 0.00195311\n",
      "Iteration 2222, loss = 0.00195216\n",
      "Iteration 2223, loss = 0.00195091\n",
      "Iteration 2224, loss = 0.00194988\n",
      "Iteration 2225, loss = 0.00194968\n",
      "Iteration 2226, loss = 0.00194931\n",
      "Iteration 2227, loss = 0.00194974\n",
      "Iteration 2228, loss = 0.00194813\n",
      "Iteration 2229, loss = 0.00194625\n",
      "Iteration 2230, loss = 0.00194755\n",
      "Iteration 2231, loss = 0.00194564\n",
      "Iteration 2232, loss = 0.00194505\n",
      "Iteration 2233, loss = 0.00194531\n",
      "Iteration 2234, loss = 0.00194356\n",
      "Iteration 2235, loss = 0.00194435\n",
      "Iteration 2236, loss = 0.00194249\n",
      "Iteration 2237, loss = 0.00194207\n",
      "Iteration 2238, loss = 0.00194118\n",
      "Iteration 2239, loss = 0.00193983\n",
      "Iteration 2240, loss = 0.00193984\n",
      "Iteration 2241, loss = 0.00193867\n",
      "Iteration 2242, loss = 0.00193830\n",
      "Iteration 2243, loss = 0.00193777\n",
      "Iteration 2244, loss = 0.00193604\n",
      "Iteration 2245, loss = 0.00193721\n",
      "Iteration 2246, loss = 0.00193546\n",
      "Iteration 2247, loss = 0.00193453\n",
      "Iteration 2248, loss = 0.00193357\n",
      "Iteration 2249, loss = 0.00193278\n",
      "Iteration 2250, loss = 0.00193308\n",
      "Iteration 2251, loss = 0.00193149\n",
      "Iteration 2252, loss = 0.00193127\n",
      "Iteration 2253, loss = 0.00193001\n",
      "Iteration 2254, loss = 0.00193055\n",
      "Iteration 2255, loss = 0.00192865\n",
      "Iteration 2256, loss = 0.00192778\n",
      "Iteration 2257, loss = 0.00192732\n",
      "Iteration 2258, loss = 0.00192673\n",
      "Iteration 2259, loss = 0.00192650\n",
      "Iteration 2260, loss = 0.00192576\n",
      "Iteration 2261, loss = 0.00192503\n",
      "Iteration 2262, loss = 0.00192414\n",
      "Iteration 2263, loss = 0.00192338\n",
      "Iteration 2264, loss = 0.00192234\n",
      "Iteration 2265, loss = 0.00192170\n",
      "Iteration 2266, loss = 0.00192173\n",
      "Iteration 2267, loss = 0.00192027\n",
      "Iteration 2268, loss = 0.00192004\n",
      "Iteration 2269, loss = 0.00191907\n",
      "Iteration 2270, loss = 0.00191831\n",
      "Iteration 2271, loss = 0.00191803\n",
      "Iteration 2272, loss = 0.00191692\n",
      "Iteration 2273, loss = 0.00191769\n",
      "Iteration 2274, loss = 0.00191573\n",
      "Iteration 2275, loss = 0.00191482\n",
      "Iteration 2276, loss = 0.00191426\n",
      "Iteration 2277, loss = 0.00191427\n",
      "Iteration 2278, loss = 0.00191244\n",
      "Iteration 2279, loss = 0.00191183\n",
      "Iteration 2280, loss = 0.00191182\n",
      "Iteration 2281, loss = 0.00191068\n",
      "Iteration 2282, loss = 0.00190999\n",
      "Iteration 2283, loss = 0.00190934\n",
      "Iteration 2284, loss = 0.00190973\n",
      "Iteration 2285, loss = 0.00190770\n",
      "Iteration 2286, loss = 0.00190699\n",
      "Iteration 2287, loss = 0.00190702\n",
      "Iteration 2288, loss = 0.00190655\n",
      "Iteration 2289, loss = 0.00190514\n",
      "Iteration 2290, loss = 0.00190504\n",
      "Iteration 2291, loss = 0.00190404\n",
      "Iteration 2292, loss = 0.00190300\n",
      "Iteration 2293, loss = 0.00190281\n",
      "Iteration 2294, loss = 0.00190214\n",
      "Iteration 2295, loss = 0.00190208\n",
      "Iteration 2296, loss = 0.00190105\n",
      "Iteration 2297, loss = 0.00190022\n",
      "Iteration 2298, loss = 0.00189913\n",
      "Iteration 2299, loss = 0.00189918\n",
      "Iteration 2300, loss = 0.00189760\n",
      "Iteration 2301, loss = 0.00189741\n",
      "Iteration 2302, loss = 0.00189610\n",
      "Iteration 2303, loss = 0.00189783\n",
      "Iteration 2304, loss = 0.00189566\n",
      "Iteration 2305, loss = 0.00189410\n",
      "Iteration 2306, loss = 0.00189418\n",
      "Iteration 2307, loss = 0.00189301\n",
      "Iteration 2308, loss = 0.00189243\n",
      "Iteration 2309, loss = 0.00189163\n",
      "Iteration 2310, loss = 0.00189099\n",
      "Iteration 2311, loss = 0.00188989\n",
      "Iteration 2312, loss = 0.00188941\n",
      "Iteration 2313, loss = 0.00188879\n",
      "Iteration 2314, loss = 0.00188788\n",
      "Iteration 2315, loss = 0.00188711\n",
      "Iteration 2316, loss = 0.00188656\n",
      "Iteration 2317, loss = 0.00188620\n",
      "Iteration 2318, loss = 0.00188545\n",
      "Iteration 2319, loss = 0.00188495\n",
      "Iteration 2320, loss = 0.00188368\n",
      "Iteration 2321, loss = 0.00188348\n",
      "Iteration 2322, loss = 0.00188285\n",
      "Iteration 2323, loss = 0.00188171\n",
      "Iteration 2324, loss = 0.00188165\n",
      "Iteration 2325, loss = 0.00188059\n",
      "Iteration 2326, loss = 0.00188043\n",
      "Iteration 2327, loss = 0.00187969\n",
      "Iteration 2328, loss = 0.00187835\n",
      "Iteration 2329, loss = 0.00187825\n",
      "Iteration 2330, loss = 0.00187741\n",
      "Iteration 2331, loss = 0.00187629\n",
      "Iteration 2332, loss = 0.00187622\n",
      "Iteration 2333, loss = 0.00187502\n",
      "Iteration 2334, loss = 0.00187505\n",
      "Iteration 2335, loss = 0.00187387\n",
      "Iteration 2336, loss = 0.00187332\n",
      "Iteration 2337, loss = 0.00187324\n",
      "Iteration 2338, loss = 0.00187202\n",
      "Iteration 2339, loss = 0.00187146\n",
      "Iteration 2340, loss = 0.00187046\n",
      "Iteration 2341, loss = 0.00187023\n",
      "Iteration 2342, loss = 0.00186904\n",
      "Iteration 2343, loss = 0.00186820\n",
      "Iteration 2344, loss = 0.00186746\n",
      "Iteration 2345, loss = 0.00186719\n",
      "Iteration 2346, loss = 0.00186694\n",
      "Iteration 2347, loss = 0.00186580\n",
      "Iteration 2348, loss = 0.00186521\n",
      "Iteration 2349, loss = 0.00186405\n",
      "Iteration 2350, loss = 0.00186357\n",
      "Iteration 2351, loss = 0.00186274\n",
      "Iteration 2352, loss = 0.00186257\n",
      "Iteration 2353, loss = 0.00186156\n",
      "Iteration 2354, loss = 0.00186127\n",
      "Iteration 2355, loss = 0.00186019\n",
      "Iteration 2356, loss = 0.00185949\n",
      "Iteration 2357, loss = 0.00185904\n",
      "Iteration 2358, loss = 0.00185872\n",
      "Iteration 2359, loss = 0.00185802\n",
      "Iteration 2360, loss = 0.00185700\n",
      "Iteration 2361, loss = 0.00185697\n",
      "Iteration 2362, loss = 0.00185562\n",
      "Iteration 2363, loss = 0.00185615\n",
      "Iteration 2364, loss = 0.00185508\n",
      "Iteration 2365, loss = 0.00185366\n",
      "Iteration 2366, loss = 0.00185372\n",
      "Iteration 2367, loss = 0.00185313\n",
      "Iteration 2368, loss = 0.00185201\n",
      "Iteration 2369, loss = 0.00185118\n",
      "Iteration 2370, loss = 0.00185160\n",
      "Iteration 2371, loss = 0.00184994\n",
      "Iteration 2372, loss = 0.00184898\n",
      "Iteration 2373, loss = 0.00184874\n",
      "Iteration 2374, loss = 0.00184789\n",
      "Iteration 2375, loss = 0.00184703\n",
      "Iteration 2376, loss = 0.00184649\n",
      "Iteration 2377, loss = 0.00184557\n",
      "Iteration 2378, loss = 0.00184515\n",
      "Iteration 2379, loss = 0.00184493\n",
      "Iteration 2380, loss = 0.00184385\n",
      "Iteration 2381, loss = 0.00184308\n",
      "Iteration 2382, loss = 0.00184229\n",
      "Iteration 2383, loss = 0.00184181\n",
      "Iteration 2384, loss = 0.00184127\n",
      "Iteration 2385, loss = 0.00184074\n",
      "Iteration 2386, loss = 0.00183993\n",
      "Iteration 2387, loss = 0.00183973\n",
      "Iteration 2388, loss = 0.00183823\n",
      "Iteration 2389, loss = 0.00183904\n",
      "Iteration 2390, loss = 0.00183739\n",
      "Iteration 2391, loss = 0.00183709\n",
      "Iteration 2392, loss = 0.00183650\n",
      "Iteration 2393, loss = 0.00183484\n",
      "Iteration 2394, loss = 0.00183491\n",
      "Iteration 2395, loss = 0.00183397\n",
      "Iteration 2396, loss = 0.00183300\n",
      "Iteration 2397, loss = 0.00183447\n",
      "Iteration 2398, loss = 0.00183173\n",
      "Iteration 2399, loss = 0.00183196\n",
      "Iteration 2400, loss = 0.00183185\n",
      "Iteration 2401, loss = 0.00182978\n",
      "Iteration 2402, loss = 0.00182966\n",
      "Iteration 2403, loss = 0.00182828\n",
      "Iteration 2404, loss = 0.00182830\n",
      "Iteration 2405, loss = 0.00182719\n",
      "Iteration 2406, loss = 0.00182678\n",
      "Iteration 2407, loss = 0.00182577\n",
      "Iteration 2408, loss = 0.00182540\n",
      "Iteration 2409, loss = 0.00182455\n",
      "Iteration 2410, loss = 0.00182367\n",
      "Iteration 2411, loss = 0.00182304\n",
      "Iteration 2412, loss = 0.00182215\n",
      "Iteration 2413, loss = 0.00182170\n",
      "Iteration 2414, loss = 0.00182160\n",
      "Iteration 2415, loss = 0.00182113\n",
      "Iteration 2416, loss = 0.00181988\n",
      "Iteration 2417, loss = 0.00181909\n",
      "Iteration 2418, loss = 0.00181839\n",
      "Iteration 2419, loss = 0.00181828\n",
      "Iteration 2420, loss = 0.00181704\n",
      "Iteration 2421, loss = 0.00181729\n",
      "Iteration 2422, loss = 0.00181603\n",
      "Iteration 2423, loss = 0.00181527\n",
      "Iteration 2424, loss = 0.00181500\n",
      "Iteration 2425, loss = 0.00181439\n",
      "Iteration 2426, loss = 0.00181319\n",
      "Iteration 2427, loss = 0.00181319\n",
      "Iteration 2428, loss = 0.00181182\n",
      "Iteration 2429, loss = 0.00181135\n",
      "Iteration 2430, loss = 0.00181109\n",
      "Iteration 2431, loss = 0.00181028\n",
      "Iteration 2432, loss = 0.00180953\n",
      "Iteration 2433, loss = 0.00181031\n",
      "Iteration 2434, loss = 0.00180809\n",
      "Iteration 2435, loss = 0.00180878\n",
      "Iteration 2436, loss = 0.00180738\n",
      "Iteration 2437, loss = 0.00180662\n",
      "Iteration 2438, loss = 0.00180534\n",
      "Iteration 2439, loss = 0.00180468\n",
      "Iteration 2440, loss = 0.00180526\n",
      "Iteration 2441, loss = 0.00180367\n",
      "Iteration 2442, loss = 0.00180460\n",
      "Iteration 2443, loss = 0.00180254\n",
      "Iteration 2444, loss = 0.00180194\n",
      "Iteration 2445, loss = 0.00180154\n",
      "Iteration 2446, loss = 0.00180173\n",
      "Iteration 2447, loss = 0.00180021\n",
      "Iteration 2448, loss = 0.00179923\n",
      "Iteration 2449, loss = 0.00179974\n",
      "Iteration 2450, loss = 0.00179821\n",
      "Iteration 2451, loss = 0.00179753\n",
      "Iteration 2452, loss = 0.00179684\n",
      "Iteration 2453, loss = 0.00179627\n",
      "Iteration 2454, loss = 0.00179555\n",
      "Iteration 2455, loss = 0.00179493\n",
      "Iteration 2456, loss = 0.00179420\n",
      "Iteration 2457, loss = 0.00179335\n",
      "Iteration 2458, loss = 0.00179274\n",
      "Iteration 2459, loss = 0.00179259\n",
      "Iteration 2460, loss = 0.00179191\n",
      "Iteration 2461, loss = 0.00179145\n",
      "Iteration 2462, loss = 0.00179002\n",
      "Iteration 2463, loss = 0.00179121\n",
      "Iteration 2464, loss = 0.00178944\n",
      "Iteration 2465, loss = 0.00178832\n",
      "Iteration 2466, loss = 0.00178779\n",
      "Iteration 2467, loss = 0.00178702\n",
      "Iteration 2468, loss = 0.00178641\n",
      "Iteration 2469, loss = 0.00178576\n",
      "Iteration 2470, loss = 0.00178600\n",
      "Iteration 2471, loss = 0.00178577\n",
      "Iteration 2472, loss = 0.00178432\n",
      "Iteration 2473, loss = 0.00178340\n",
      "Iteration 2474, loss = 0.00178332\n",
      "Iteration 2475, loss = 0.00178153\n",
      "Iteration 2476, loss = 0.00178301\n",
      "Iteration 2477, loss = 0.00178192\n",
      "Iteration 2478, loss = 0.00178016\n",
      "Iteration 2479, loss = 0.00178032\n",
      "Iteration 2480, loss = 0.00177896\n",
      "Iteration 2481, loss = 0.00177763\n",
      "Iteration 2482, loss = 0.00177737\n",
      "Iteration 2483, loss = 0.00177688\n",
      "Iteration 2484, loss = 0.00177557\n",
      "Iteration 2485, loss = 0.00177536\n",
      "Iteration 2486, loss = 0.00177439\n",
      "Iteration 2487, loss = 0.00177462\n",
      "Iteration 2488, loss = 0.00177395\n",
      "Iteration 2489, loss = 0.00177354\n",
      "Iteration 2490, loss = 0.00177204\n",
      "Iteration 2491, loss = 0.00177197\n",
      "Iteration 2492, loss = 0.00177067\n",
      "Iteration 2493, loss = 0.00177065\n",
      "Iteration 2494, loss = 0.00177005\n",
      "Iteration 2495, loss = 0.00177030\n",
      "Iteration 2496, loss = 0.00176815\n",
      "Iteration 2497, loss = 0.00176854\n",
      "Iteration 2498, loss = 0.00176791\n",
      "Iteration 2499, loss = 0.00176658\n",
      "Iteration 2500, loss = 0.00176589\n",
      "Iteration 2501, loss = 0.00176552\n",
      "Iteration 2502, loss = 0.00176608\n",
      "Iteration 2503, loss = 0.00176388\n",
      "Iteration 2504, loss = 0.00176349\n",
      "Iteration 2505, loss = 0.00176252\n",
      "Iteration 2506, loss = 0.00176174\n",
      "Iteration 2507, loss = 0.00176198\n",
      "Iteration 2508, loss = 0.00176103\n",
      "Iteration 2509, loss = 0.00176029\n",
      "Iteration 2510, loss = 0.00175965\n",
      "Iteration 2511, loss = 0.00175941\n",
      "Iteration 2512, loss = 0.00175841\n",
      "Iteration 2513, loss = 0.00175844\n",
      "Iteration 2514, loss = 0.00175709\n",
      "Iteration 2515, loss = 0.00175692\n",
      "Iteration 2516, loss = 0.00175597\n",
      "Iteration 2517, loss = 0.00175520\n",
      "Iteration 2518, loss = 0.00175415\n",
      "Iteration 2519, loss = 0.00175372\n",
      "Iteration 2520, loss = 0.00175282\n",
      "Iteration 2521, loss = 0.00175220\n",
      "Iteration 2522, loss = 0.00175261\n",
      "Iteration 2523, loss = 0.00175167\n",
      "Iteration 2524, loss = 0.00175101\n",
      "Iteration 2525, loss = 0.00174974\n",
      "Iteration 2526, loss = 0.00175098\n",
      "Iteration 2527, loss = 0.00174911\n",
      "Iteration 2528, loss = 0.00174904\n",
      "Iteration 2529, loss = 0.00174749\n",
      "Iteration 2530, loss = 0.00174883\n",
      "Iteration 2531, loss = 0.00174786\n",
      "Iteration 2532, loss = 0.00174539\n",
      "Iteration 2533, loss = 0.00174745\n",
      "Iteration 2534, loss = 0.00174495\n",
      "Iteration 2535, loss = 0.00174472\n",
      "Iteration 2536, loss = 0.00174337\n",
      "Iteration 2537, loss = 0.00174341\n",
      "Iteration 2538, loss = 0.00174215\n",
      "Iteration 2539, loss = 0.00174306\n",
      "Iteration 2540, loss = 0.00174046\n",
      "Iteration 2541, loss = 0.00174014\n",
      "Iteration 2542, loss = 0.00174072\n",
      "Iteration 2543, loss = 0.00173918\n",
      "Iteration 2544, loss = 0.00173892\n",
      "Iteration 2545, loss = 0.00173733\n",
      "Iteration 2546, loss = 0.00173853\n",
      "Iteration 2547, loss = 0.00173684\n",
      "Iteration 2548, loss = 0.00173577\n",
      "Iteration 2549, loss = 0.00173521\n",
      "Iteration 2550, loss = 0.00173490\n",
      "Iteration 2551, loss = 0.00173473\n",
      "Iteration 2552, loss = 0.00173341\n",
      "Iteration 2553, loss = 0.00173208\n",
      "Iteration 2554, loss = 0.00173284\n",
      "Iteration 2555, loss = 0.00173226\n",
      "Iteration 2556, loss = 0.00173233\n",
      "Iteration 2557, loss = 0.00173233\n",
      "Iteration 2558, loss = 0.00173041\n",
      "Iteration 2559, loss = 0.00173167\n",
      "Iteration 2560, loss = 0.00172984\n",
      "Iteration 2561, loss = 0.00172913\n",
      "Iteration 2562, loss = 0.00172740\n",
      "Iteration 2563, loss = 0.00172684\n",
      "Iteration 2564, loss = 0.00172722\n",
      "Iteration 2565, loss = 0.00172576\n",
      "Iteration 2566, loss = 0.00172642\n",
      "Iteration 2567, loss = 0.00172377\n",
      "Iteration 2568, loss = 0.00172371\n",
      "Iteration 2569, loss = 0.00172309\n",
      "Iteration 2570, loss = 0.00172166\n",
      "Iteration 2571, loss = 0.00172246\n",
      "Iteration 2572, loss = 0.00172146\n",
      "Iteration 2573, loss = 0.00172105\n",
      "Iteration 2574, loss = 0.00172003\n",
      "Iteration 2575, loss = 0.00171877\n",
      "Iteration 2576, loss = 0.00171894\n",
      "Iteration 2577, loss = 0.00171773\n",
      "Iteration 2578, loss = 0.00171747\n",
      "Iteration 2579, loss = 0.00171621\n",
      "Iteration 2580, loss = 0.00171670\n",
      "Iteration 2581, loss = 0.00171612\n",
      "Iteration 2582, loss = 0.00171412\n",
      "Iteration 2583, loss = 0.00171367\n",
      "Iteration 2584, loss = 0.00171435\n",
      "Iteration 2585, loss = 0.00171450\n",
      "Iteration 2586, loss = 0.00171251\n",
      "Iteration 2587, loss = 0.00171204\n",
      "Iteration 2588, loss = 0.00171181\n",
      "Iteration 2589, loss = 0.00171072\n",
      "Iteration 2590, loss = 0.00170931\n",
      "Iteration 2591, loss = 0.00170865\n",
      "Iteration 2592, loss = 0.00170878\n",
      "Iteration 2593, loss = 0.00170843\n",
      "Iteration 2594, loss = 0.00170850\n",
      "Iteration 2595, loss = 0.00170687\n",
      "Iteration 2596, loss = 0.00170538\n",
      "Iteration 2597, loss = 0.00170646\n",
      "Iteration 2598, loss = 0.00170497\n",
      "Iteration 2599, loss = 0.00170485\n",
      "Iteration 2600, loss = 0.00170336\n",
      "Iteration 2601, loss = 0.00170228\n",
      "Iteration 2602, loss = 0.00170232\n",
      "Iteration 2603, loss = 0.00170090\n",
      "Iteration 2604, loss = 0.00170080\n",
      "Iteration 2605, loss = 0.00170017\n",
      "Iteration 2606, loss = 0.00169954\n",
      "Iteration 2607, loss = 0.00169879\n",
      "Iteration 2608, loss = 0.00169917\n",
      "Iteration 2609, loss = 0.00169718\n",
      "Iteration 2610, loss = 0.00169707\n",
      "Iteration 2611, loss = 0.00169629\n",
      "Iteration 2612, loss = 0.00169582\n",
      "Iteration 2613, loss = 0.00169473\n",
      "Iteration 2614, loss = 0.00169417\n",
      "Iteration 2615, loss = 0.00169377\n",
      "Iteration 2616, loss = 0.00169334\n",
      "Iteration 2617, loss = 0.00169242\n",
      "Iteration 2618, loss = 0.00169185\n",
      "Iteration 2619, loss = 0.00169151\n",
      "Iteration 2620, loss = 0.00169128\n",
      "Iteration 2621, loss = 0.00168968\n",
      "Iteration 2622, loss = 0.00169015\n",
      "Iteration 2623, loss = 0.00168898\n",
      "Iteration 2624, loss = 0.00168870\n",
      "Iteration 2625, loss = 0.00168770\n",
      "Iteration 2626, loss = 0.00168836\n",
      "Iteration 2627, loss = 0.00168737\n",
      "Iteration 2628, loss = 0.00168669\n",
      "Iteration 2629, loss = 0.00168543\n",
      "Iteration 2630, loss = 0.00168493\n",
      "Iteration 2631, loss = 0.00168382\n",
      "Iteration 2632, loss = 0.00168389\n",
      "Iteration 2633, loss = 0.00168298\n",
      "Iteration 2634, loss = 0.00168175\n",
      "Iteration 2635, loss = 0.00168205\n",
      "Iteration 2636, loss = 0.00168100\n",
      "Iteration 2637, loss = 0.00168039\n",
      "Iteration 2638, loss = 0.00168153\n",
      "Iteration 2639, loss = 0.00167929\n",
      "Iteration 2640, loss = 0.00167972\n",
      "Iteration 2641, loss = 0.00167866\n",
      "Iteration 2642, loss = 0.00167738\n",
      "Iteration 2643, loss = 0.00167680\n",
      "Iteration 2644, loss = 0.00167597\n",
      "Iteration 2645, loss = 0.00167699\n",
      "Iteration 2646, loss = 0.00167681\n",
      "Iteration 2647, loss = 0.00167434\n",
      "Iteration 2648, loss = 0.00167395\n",
      "Iteration 2649, loss = 0.00167367\n",
      "Iteration 2650, loss = 0.00167294\n",
      "Iteration 2651, loss = 0.00167232\n",
      "Iteration 2652, loss = 0.00167079\n",
      "Iteration 2653, loss = 0.00167058\n",
      "Iteration 2654, loss = 0.00167067\n",
      "Iteration 2655, loss = 0.00166984\n",
      "Iteration 2656, loss = 0.00166905\n",
      "Iteration 2657, loss = 0.00166809\n",
      "Iteration 2658, loss = 0.00166823\n",
      "Iteration 2659, loss = 0.00166715\n",
      "Iteration 2660, loss = 0.00166602\n",
      "Iteration 2661, loss = 0.00166621\n",
      "Iteration 2662, loss = 0.00166470\n",
      "Iteration 2663, loss = 0.00166449\n",
      "Iteration 2664, loss = 0.00166345\n",
      "Iteration 2665, loss = 0.00166338\n",
      "Iteration 2666, loss = 0.00166239\n",
      "Iteration 2667, loss = 0.00166250\n",
      "Iteration 2668, loss = 0.00166114\n",
      "Iteration 2669, loss = 0.00166141\n",
      "Iteration 2670, loss = 0.00166034\n",
      "Iteration 2671, loss = 0.00165933\n",
      "Iteration 2672, loss = 0.00166020\n",
      "Iteration 2673, loss = 0.00165810\n",
      "Iteration 2674, loss = 0.00165861\n",
      "Iteration 2675, loss = 0.00165731\n",
      "Iteration 2676, loss = 0.00165619\n",
      "Iteration 2677, loss = 0.00165681\n",
      "Iteration 2678, loss = 0.00165616\n",
      "Iteration 2679, loss = 0.00165484\n",
      "Iteration 2680, loss = 0.00165616\n",
      "Iteration 2681, loss = 0.00165421\n",
      "Iteration 2682, loss = 0.00165327\n",
      "Iteration 2683, loss = 0.00165193\n",
      "Iteration 2684, loss = 0.00165213\n",
      "Iteration 2685, loss = 0.00165215\n",
      "Iteration 2686, loss = 0.00165044\n",
      "Iteration 2687, loss = 0.00165119\n",
      "Iteration 2688, loss = 0.00165152\n",
      "Iteration 2689, loss = 0.00164913\n",
      "Iteration 2690, loss = 0.00164825\n",
      "Iteration 2691, loss = 0.00164780\n",
      "Iteration 2692, loss = 0.00164643\n",
      "Iteration 2693, loss = 0.00164608\n",
      "Iteration 2694, loss = 0.00164672\n",
      "Iteration 2695, loss = 0.00164545\n",
      "Iteration 2696, loss = 0.00164686\n",
      "Iteration 2697, loss = 0.00164412\n",
      "Iteration 2698, loss = 0.00164332\n",
      "Iteration 2699, loss = 0.00164501\n",
      "Iteration 2700, loss = 0.00164527\n",
      "Iteration 2701, loss = 0.00164159\n",
      "Iteration 2702, loss = 0.00164037\n",
      "Iteration 2703, loss = 0.00164122\n",
      "Iteration 2704, loss = 0.00164000\n",
      "Iteration 2705, loss = 0.00163859\n",
      "Iteration 2706, loss = 0.00163831\n",
      "Iteration 2707, loss = 0.00163829\n",
      "Iteration 2708, loss = 0.00163764\n",
      "Iteration 2709, loss = 0.00163677\n",
      "Iteration 2710, loss = 0.00163611\n",
      "Iteration 2711, loss = 0.00163573\n",
      "Iteration 2712, loss = 0.00163478\n",
      "Iteration 2713, loss = 0.00163442\n",
      "Iteration 2714, loss = 0.00163346\n",
      "Iteration 2715, loss = 0.00163351\n",
      "Iteration 2716, loss = 0.00163190\n",
      "Iteration 2717, loss = 0.00163234\n",
      "Iteration 2718, loss = 0.00163151\n",
      "Iteration 2719, loss = 0.00163042\n",
      "Iteration 2720, loss = 0.00163099\n",
      "Iteration 2721, loss = 0.00162942\n",
      "Iteration 2722, loss = 0.00162897\n",
      "Iteration 2723, loss = 0.00162809\n",
      "Iteration 2724, loss = 0.00162877\n",
      "Iteration 2725, loss = 0.00162693\n",
      "Iteration 2726, loss = 0.00162650\n",
      "Iteration 2727, loss = 0.00162561\n",
      "Iteration 2728, loss = 0.00162526\n",
      "Iteration 2729, loss = 0.00162604\n",
      "Iteration 2730, loss = 0.00162545\n",
      "Iteration 2731, loss = 0.00162429\n",
      "Iteration 2732, loss = 0.00162430\n",
      "Iteration 2733, loss = 0.00162284\n",
      "Iteration 2734, loss = 0.00162205\n",
      "Iteration 2735, loss = 0.00162357\n",
      "Iteration 2736, loss = 0.00162090\n",
      "Iteration 2737, loss = 0.00162025\n",
      "Iteration 2738, loss = 0.00161921\n",
      "Iteration 2739, loss = 0.00161916\n",
      "Iteration 2740, loss = 0.00161760\n",
      "Iteration 2741, loss = 0.00161756\n",
      "Iteration 2742, loss = 0.00161737\n",
      "Iteration 2743, loss = 0.00161618\n",
      "Iteration 2744, loss = 0.00161935\n",
      "Iteration 2745, loss = 0.00161530\n",
      "Iteration 2746, loss = 0.00161601\n",
      "Iteration 2747, loss = 0.00161387\n",
      "Iteration 2748, loss = 0.00161593\n",
      "Iteration 2749, loss = 0.00161253\n",
      "Iteration 2750, loss = 0.00161455\n",
      "Iteration 2751, loss = 0.00161261\n",
      "Iteration 2752, loss = 0.00161267\n",
      "Iteration 2753, loss = 0.00161085\n",
      "Iteration 2754, loss = 0.00161039\n",
      "Iteration 2755, loss = 0.00161066\n",
      "Iteration 2756, loss = 0.00160900\n",
      "Iteration 2757, loss = 0.00160872\n",
      "Iteration 2758, loss = 0.00160711\n",
      "Iteration 2759, loss = 0.00160772\n",
      "Iteration 2760, loss = 0.00160737\n",
      "Iteration 2761, loss = 0.00160643\n",
      "Iteration 2762, loss = 0.00160550\n",
      "Iteration 2763, loss = 0.00160436\n",
      "Iteration 2764, loss = 0.00160401\n",
      "Iteration 2765, loss = 0.00160366\n",
      "Iteration 2766, loss = 0.00160292\n",
      "Iteration 2767, loss = 0.00160201\n",
      "Iteration 2768, loss = 0.00160120\n",
      "Iteration 2769, loss = 0.00160117\n",
      "Iteration 2770, loss = 0.00160091\n",
      "Iteration 2771, loss = 0.00159960\n",
      "Iteration 2772, loss = 0.00159890\n",
      "Iteration 2773, loss = 0.00159819\n",
      "Iteration 2774, loss = 0.00159809\n",
      "Iteration 2775, loss = 0.00159814\n",
      "Iteration 2776, loss = 0.00159832\n",
      "Iteration 2777, loss = 0.00159641\n",
      "Iteration 2778, loss = 0.00159644\n",
      "Iteration 2779, loss = 0.00159487\n",
      "Iteration 2780, loss = 0.00159551\n",
      "Iteration 2781, loss = 0.00159395\n",
      "Iteration 2782, loss = 0.00159320\n",
      "Iteration 2783, loss = 0.00159399\n",
      "Iteration 2784, loss = 0.00159274\n",
      "Iteration 2785, loss = 0.00159220\n",
      "Iteration 2786, loss = 0.00159091\n",
      "Iteration 2787, loss = 0.00159105\n",
      "Iteration 2788, loss = 0.00159102\n",
      "Iteration 2789, loss = 0.00158932\n",
      "Iteration 2790, loss = 0.00158990\n",
      "Iteration 2791, loss = 0.00159043\n",
      "Iteration 2792, loss = 0.00158802\n",
      "Iteration 2793, loss = 0.00158731\n",
      "Iteration 2794, loss = 0.00158723\n",
      "Iteration 2795, loss = 0.00158596\n",
      "Iteration 2796, loss = 0.00158509\n",
      "Iteration 2797, loss = 0.00158675\n",
      "Iteration 2798, loss = 0.00158642\n",
      "Iteration 2799, loss = 0.00158490\n",
      "Iteration 2800, loss = 0.00158585\n",
      "Iteration 2801, loss = 0.00158316\n",
      "Iteration 2802, loss = 0.00158255\n",
      "Iteration 2803, loss = 0.00158288\n",
      "Iteration 2804, loss = 0.00158247\n",
      "Iteration 2805, loss = 0.00158164\n",
      "Iteration 2806, loss = 0.00158087\n",
      "Iteration 2807, loss = 0.00157930\n",
      "Iteration 2808, loss = 0.00157984\n",
      "Iteration 2809, loss = 0.00157726\n",
      "Iteration 2810, loss = 0.00157909\n",
      "Iteration 2811, loss = 0.00157789\n",
      "Iteration 2812, loss = 0.00157775\n",
      "Iteration 2813, loss = 0.00157539\n",
      "Iteration 2814, loss = 0.00157565\n",
      "Iteration 2815, loss = 0.00157539\n",
      "Iteration 2816, loss = 0.00157413\n",
      "Iteration 2817, loss = 0.00157374\n",
      "Iteration 2818, loss = 0.00157233\n",
      "Iteration 2819, loss = 0.00157302\n",
      "Iteration 2820, loss = 0.00157120\n",
      "Iteration 2821, loss = 0.00157132\n",
      "Iteration 2822, loss = 0.00157079\n",
      "Iteration 2823, loss = 0.00156999\n",
      "Iteration 2824, loss = 0.00156892\n",
      "Iteration 2825, loss = 0.00156887\n",
      "Iteration 2826, loss = 0.00156831\n",
      "Iteration 2827, loss = 0.00156853\n",
      "Iteration 2828, loss = 0.00156760\n",
      "Iteration 2829, loss = 0.00156699\n",
      "Iteration 2830, loss = 0.00156825\n",
      "Iteration 2831, loss = 0.00156557\n",
      "Iteration 2832, loss = 0.00156480\n",
      "Iteration 2833, loss = 0.00156495\n",
      "Iteration 2834, loss = 0.00156605\n",
      "Iteration 2835, loss = 0.00156516\n",
      "Iteration 2836, loss = 0.00156487\n",
      "Iteration 2837, loss = 0.00156248\n",
      "Iteration 2838, loss = 0.00156198\n",
      "Iteration 2839, loss = 0.00156243\n",
      "Iteration 2840, loss = 0.00156071\n",
      "Iteration 2841, loss = 0.00156067\n",
      "Iteration 2842, loss = 0.00155913\n",
      "Iteration 2843, loss = 0.00155864\n",
      "Iteration 2844, loss = 0.00155823\n",
      "Iteration 2845, loss = 0.00155815\n",
      "Iteration 2846, loss = 0.00155687\n",
      "Iteration 2847, loss = 0.00155605\n",
      "Iteration 2848, loss = 0.00155625\n",
      "Iteration 2849, loss = 0.00155542\n",
      "Iteration 2850, loss = 0.00155469\n",
      "Iteration 2851, loss = 0.00155509\n",
      "Iteration 2852, loss = 0.00155339\n",
      "Iteration 2853, loss = 0.00155333\n",
      "Iteration 2854, loss = 0.00155270\n",
      "Iteration 2855, loss = 0.00155299\n",
      "Iteration 2856, loss = 0.00155095\n",
      "Iteration 2857, loss = 0.00155106\n",
      "Iteration 2858, loss = 0.00155232\n",
      "Iteration 2859, loss = 0.00154981\n",
      "Iteration 2860, loss = 0.00154963\n",
      "Iteration 2861, loss = 0.00154915\n",
      "Iteration 2862, loss = 0.00154816\n",
      "Iteration 2863, loss = 0.00154733\n",
      "Iteration 2864, loss = 0.00154730\n",
      "Iteration 2865, loss = 0.00154638\n",
      "Iteration 2866, loss = 0.00154645\n",
      "Iteration 2867, loss = 0.00154549\n",
      "Iteration 2868, loss = 0.00154632\n",
      "Iteration 2869, loss = 0.00154430\n",
      "Iteration 2870, loss = 0.00154511\n",
      "Iteration 2871, loss = 0.00154332\n",
      "Iteration 2872, loss = 0.00154375\n",
      "Iteration 2873, loss = 0.00154206\n",
      "Iteration 2874, loss = 0.00154249\n",
      "Iteration 2875, loss = 0.00154131\n",
      "Iteration 2876, loss = 0.00154115\n",
      "Iteration 2877, loss = 0.00153930\n",
      "Iteration 2878, loss = 0.00153915\n",
      "Iteration 2879, loss = 0.00153810\n",
      "Iteration 2880, loss = 0.00153845\n",
      "Iteration 2881, loss = 0.00153739\n",
      "Iteration 2882, loss = 0.00153683\n",
      "Iteration 2883, loss = 0.00153656\n",
      "Iteration 2884, loss = 0.00153632\n",
      "Iteration 2885, loss = 0.00153542\n",
      "Iteration 2886, loss = 0.00153421\n",
      "Iteration 2887, loss = 0.00153409\n",
      "Iteration 2888, loss = 0.00153396\n",
      "Iteration 2889, loss = 0.00153293\n",
      "Iteration 2890, loss = 0.00153205\n",
      "Iteration 2891, loss = 0.00153194\n",
      "Iteration 2892, loss = 0.00153044\n",
      "Iteration 2893, loss = 0.00153190\n",
      "Iteration 2894, loss = 0.00153146\n",
      "Iteration 2895, loss = 0.00153164\n",
      "Iteration 2896, loss = 0.00153089\n",
      "Iteration 2897, loss = 0.00152914\n",
      "Iteration 2898, loss = 0.00152899\n",
      "Iteration 2899, loss = 0.00152794\n",
      "Iteration 2900, loss = 0.00152797\n",
      "Iteration 2901, loss = 0.00152666\n",
      "Iteration 2902, loss = 0.00152720\n",
      "Iteration 2903, loss = 0.00152670\n",
      "Iteration 2904, loss = 0.00152645\n",
      "Iteration 2905, loss = 0.00152434\n",
      "Iteration 2906, loss = 0.00152456\n",
      "Iteration 2907, loss = 0.00152344\n",
      "Iteration 2908, loss = 0.00152254\n",
      "Iteration 2909, loss = 0.00152242\n",
      "Iteration 2910, loss = 0.00152270\n",
      "Iteration 2911, loss = 0.00152177\n",
      "Iteration 2912, loss = 0.00152044\n",
      "Iteration 2913, loss = 0.00151964\n",
      "Iteration 2914, loss = 0.00152070\n",
      "Iteration 2915, loss = 0.00151832\n",
      "Iteration 2916, loss = 0.00151892\n",
      "Iteration 2917, loss = 0.00151774\n",
      "Iteration 2918, loss = 0.00151693\n",
      "Iteration 2919, loss = 0.00151666\n",
      "Iteration 2920, loss = 0.00151604\n",
      "Iteration 2921, loss = 0.00151544\n",
      "Iteration 2922, loss = 0.00151423\n",
      "Iteration 2923, loss = 0.00151540\n",
      "Iteration 2924, loss = 0.00151382\n",
      "Iteration 2925, loss = 0.00151434\n",
      "Iteration 2926, loss = 0.00151230\n",
      "Iteration 2927, loss = 0.00151292\n",
      "Iteration 2928, loss = 0.00151178\n",
      "Iteration 2929, loss = 0.00151266\n",
      "Iteration 2930, loss = 0.00151059\n",
      "Iteration 2931, loss = 0.00151164\n",
      "Iteration 2932, loss = 0.00150862\n",
      "Iteration 2933, loss = 0.00151012\n",
      "Iteration 2934, loss = 0.00150995\n",
      "Iteration 2935, loss = 0.00150830\n",
      "Iteration 2936, loss = 0.00150861\n",
      "Iteration 2937, loss = 0.00150715\n",
      "Iteration 2938, loss = 0.00150681\n",
      "Iteration 2939, loss = 0.00150658\n",
      "Iteration 2940, loss = 0.00150487\n",
      "Iteration 2941, loss = 0.00150498\n",
      "Iteration 2942, loss = 0.00150399\n",
      "Iteration 2943, loss = 0.00150565\n",
      "Iteration 2944, loss = 0.00150215\n",
      "Iteration 2945, loss = 0.00150393\n",
      "Iteration 2946, loss = 0.00150200\n",
      "Iteration 2947, loss = 0.00150369\n",
      "Iteration 2948, loss = 0.00150071\n",
      "Iteration 2949, loss = 0.00150211\n",
      "Iteration 2950, loss = 0.00149961\n",
      "Iteration 2951, loss = 0.00149901\n",
      "Iteration 2952, loss = 0.00150052\n",
      "Iteration 2953, loss = 0.00149854\n",
      "Iteration 2954, loss = 0.00149855\n",
      "Iteration 2955, loss = 0.00149760\n",
      "Iteration 2956, loss = 0.00149659\n",
      "Iteration 2957, loss = 0.00149755\n",
      "Iteration 2958, loss = 0.00149557\n",
      "Iteration 2959, loss = 0.00149583\n",
      "Iteration 2960, loss = 0.00149607\n",
      "Iteration 2961, loss = 0.00149506\n",
      "Iteration 2962, loss = 0.00149372\n",
      "Iteration 2963, loss = 0.00149259\n",
      "Iteration 2964, loss = 0.00149276\n",
      "Iteration 2965, loss = 0.00149188\n",
      "Iteration 2966, loss = 0.00149265\n",
      "Iteration 2967, loss = 0.00149003\n",
      "Iteration 2968, loss = 0.00149119\n",
      "Iteration 2969, loss = 0.00149017\n",
      "Iteration 2970, loss = 0.00148917\n",
      "Iteration 2971, loss = 0.00148948\n",
      "Iteration 2972, loss = 0.00148802\n",
      "Iteration 2973, loss = 0.00148836\n",
      "Iteration 2974, loss = 0.00148996\n",
      "Iteration 2975, loss = 0.00148760\n",
      "Iteration 2976, loss = 0.00148878\n",
      "Iteration 2977, loss = 0.00148473\n",
      "Iteration 2978, loss = 0.00148881\n",
      "Iteration 2979, loss = 0.00148506\n",
      "Iteration 2980, loss = 0.00148677\n",
      "Iteration 2981, loss = 0.00148374\n",
      "Iteration 2982, loss = 0.00148514\n",
      "Iteration 2983, loss = 0.00148311\n",
      "Iteration 2984, loss = 0.00148288\n",
      "Iteration 2985, loss = 0.00148242\n",
      "Iteration 2986, loss = 0.00148127\n",
      "Iteration 2987, loss = 0.00148182\n",
      "Iteration 2988, loss = 0.00148033\n",
      "Iteration 2989, loss = 0.00148144\n",
      "Iteration 2990, loss = 0.00147942\n",
      "Iteration 2991, loss = 0.00147885\n",
      "Iteration 2992, loss = 0.00147724\n",
      "Iteration 2993, loss = 0.00147797\n",
      "Iteration 2994, loss = 0.00147619\n",
      "Iteration 2995, loss = 0.00147559\n",
      "Iteration 2996, loss = 0.00147561\n",
      "Iteration 2997, loss = 0.00147439\n",
      "Iteration 2998, loss = 0.00147446\n",
      "Iteration 2999, loss = 0.00147380\n",
      "Iteration 3000, loss = 0.00147503\n",
      "Iteration 3001, loss = 0.00147374\n",
      "Iteration 3002, loss = 0.00147282\n",
      "Iteration 3003, loss = 0.00147227\n",
      "Iteration 3004, loss = 0.00147065\n",
      "Iteration 3005, loss = 0.00147153\n",
      "Iteration 3006, loss = 0.00147053\n",
      "Iteration 3007, loss = 0.00146925\n",
      "Iteration 3008, loss = 0.00147042\n",
      "Iteration 3009, loss = 0.00146824\n",
      "Iteration 3010, loss = 0.00147014\n",
      "Iteration 3011, loss = 0.00146822\n",
      "Iteration 3012, loss = 0.00146689\n",
      "Iteration 3013, loss = 0.00146694\n",
      "Iteration 3014, loss = 0.00146747\n",
      "Iteration 3015, loss = 0.00146671\n",
      "Iteration 3016, loss = 0.00146566\n",
      "Iteration 3017, loss = 0.00146456\n",
      "Iteration 3018, loss = 0.00146407\n",
      "Iteration 3019, loss = 0.00146344\n",
      "Iteration 3020, loss = 0.00146412\n",
      "Iteration 3021, loss = 0.00146213\n",
      "Iteration 3022, loss = 0.00146224\n",
      "Iteration 3023, loss = 0.00146144\n",
      "Iteration 3024, loss = 0.00146086\n",
      "Iteration 3025, loss = 0.00145990\n",
      "Iteration 3026, loss = 0.00145921\n",
      "Iteration 3027, loss = 0.00145893\n",
      "Iteration 3028, loss = 0.00145826\n",
      "Iteration 3029, loss = 0.00145768\n",
      "Iteration 3030, loss = 0.00145701\n",
      "Iteration 3031, loss = 0.00145693\n",
      "Iteration 3032, loss = 0.00145681\n",
      "Iteration 3033, loss = 0.00145638\n",
      "Iteration 3034, loss = 0.00145677\n",
      "Iteration 3035, loss = 0.00145603\n",
      "Iteration 3036, loss = 0.00145474\n",
      "Iteration 3037, loss = 0.00145485\n",
      "Iteration 3038, loss = 0.00145336\n",
      "Iteration 3039, loss = 0.00145315\n",
      "Iteration 3040, loss = 0.00145234\n",
      "Iteration 3041, loss = 0.00145304\n",
      "Iteration 3042, loss = 0.00145156\n",
      "Iteration 3043, loss = 0.00145161\n",
      "Iteration 3044, loss = 0.00144973\n",
      "Iteration 3045, loss = 0.00145098\n",
      "Iteration 3046, loss = 0.00145008\n",
      "Iteration 3047, loss = 0.00144912\n",
      "Iteration 3048, loss = 0.00144897\n",
      "Iteration 3049, loss = 0.00144828\n",
      "Iteration 3050, loss = 0.00144891\n",
      "Iteration 3051, loss = 0.00144719\n",
      "Iteration 3052, loss = 0.00144655\n",
      "Iteration 3053, loss = 0.00144723\n",
      "Iteration 3054, loss = 0.00144463\n",
      "Iteration 3055, loss = 0.00144664\n",
      "Iteration 3056, loss = 0.00144392\n",
      "Iteration 3057, loss = 0.00144573\n",
      "Iteration 3058, loss = 0.00144546\n",
      "Iteration 3059, loss = 0.00144394\n",
      "Iteration 3060, loss = 0.00144294\n",
      "Iteration 3061, loss = 0.00144414\n",
      "Iteration 3062, loss = 0.00144291\n",
      "Iteration 3063, loss = 0.00144105\n",
      "Iteration 3064, loss = 0.00144113\n",
      "Iteration 3065, loss = 0.00144136\n",
      "Iteration 3066, loss = 0.00143882\n",
      "Iteration 3067, loss = 0.00143934\n",
      "Iteration 3068, loss = 0.00143810\n",
      "Iteration 3069, loss = 0.00143740\n",
      "Iteration 3070, loss = 0.00143706\n",
      "Iteration 3071, loss = 0.00143687\n",
      "Iteration 3072, loss = 0.00143635\n",
      "Iteration 3073, loss = 0.00143587\n",
      "Iteration 3074, loss = 0.00143476\n",
      "Iteration 3075, loss = 0.00143491\n",
      "Iteration 3076, loss = 0.00143401\n",
      "Iteration 3077, loss = 0.00143331\n",
      "Iteration 3078, loss = 0.00143319\n",
      "Iteration 3079, loss = 0.00143320\n",
      "Iteration 3080, loss = 0.00143284\n",
      "Iteration 3081, loss = 0.00143195\n",
      "Iteration 3082, loss = 0.00143073\n",
      "Iteration 3083, loss = 0.00143073\n",
      "Iteration 3084, loss = 0.00142978\n",
      "Iteration 3085, loss = 0.00142932\n",
      "Iteration 3086, loss = 0.00142869\n",
      "Iteration 3087, loss = 0.00142854\n",
      "Iteration 3088, loss = 0.00142913\n",
      "Iteration 3089, loss = 0.00142773\n",
      "Iteration 3090, loss = 0.00142706\n",
      "Iteration 3091, loss = 0.00142736\n",
      "Iteration 3092, loss = 0.00142646\n",
      "Iteration 3093, loss = 0.00142780\n",
      "Iteration 3094, loss = 0.00142640\n",
      "Iteration 3095, loss = 0.00142798\n",
      "Iteration 3096, loss = 0.00142473\n",
      "Iteration 3097, loss = 0.00142531\n",
      "Iteration 3098, loss = 0.00142311\n",
      "Iteration 3099, loss = 0.00142335\n",
      "Iteration 3100, loss = 0.00142377\n",
      "Iteration 3101, loss = 0.00142210\n",
      "Iteration 3102, loss = 0.00142168\n",
      "Iteration 3103, loss = 0.00142120\n",
      "Iteration 3104, loss = 0.00142031\n",
      "Iteration 3105, loss = 0.00142116\n",
      "Iteration 3106, loss = 0.00141914\n",
      "Iteration 3107, loss = 0.00142104\n",
      "Iteration 3108, loss = 0.00141812\n",
      "Iteration 3109, loss = 0.00141990\n",
      "Iteration 3110, loss = 0.00141684\n",
      "Iteration 3111, loss = 0.00141818\n",
      "Iteration 3112, loss = 0.00141575\n",
      "Iteration 3113, loss = 0.00141637\n",
      "Iteration 3114, loss = 0.00141559\n",
      "Iteration 3115, loss = 0.00141684\n",
      "Iteration 3116, loss = 0.00141528\n",
      "Iteration 3117, loss = 0.00141338\n",
      "Iteration 3118, loss = 0.00141405\n",
      "Iteration 3119, loss = 0.00141257\n",
      "Iteration 3120, loss = 0.00141269\n",
      "Iteration 3121, loss = 0.00141122\n",
      "Iteration 3122, loss = 0.00141145\n",
      "Iteration 3123, loss = 0.00141175\n",
      "Iteration 3124, loss = 0.00141104\n",
      "Iteration 3125, loss = 0.00141094\n",
      "Iteration 3126, loss = 0.00140890\n",
      "Iteration 3127, loss = 0.00141026\n",
      "Iteration 3128, loss = 0.00140793\n",
      "Iteration 3129, loss = 0.00140980\n",
      "Iteration 3130, loss = 0.00140846\n",
      "Iteration 3131, loss = 0.00140765\n",
      "Iteration 3132, loss = 0.00140721\n",
      "Iteration 3133, loss = 0.00140677\n",
      "Iteration 3134, loss = 0.00140683\n",
      "Iteration 3135, loss = 0.00140514\n",
      "Iteration 3136, loss = 0.00140509\n",
      "Iteration 3137, loss = 0.00140455\n",
      "Iteration 3138, loss = 0.00140340\n",
      "Iteration 3139, loss = 0.00140312\n",
      "Iteration 3140, loss = 0.00140291\n",
      "Iteration 3141, loss = 0.00140224\n",
      "Iteration 3142, loss = 0.00140167\n",
      "Iteration 3143, loss = 0.00140162\n",
      "Iteration 3144, loss = 0.00140075\n",
      "Iteration 3145, loss = 0.00139963\n",
      "Iteration 3146, loss = 0.00139942\n",
      "Iteration 3147, loss = 0.00140003\n",
      "Iteration 3148, loss = 0.00139832\n",
      "Iteration 3149, loss = 0.00139804\n",
      "Iteration 3150, loss = 0.00139822\n",
      "Iteration 3151, loss = 0.00139722\n",
      "Iteration 3152, loss = 0.00139600\n",
      "Iteration 3153, loss = 0.00139562\n",
      "Iteration 3154, loss = 0.00139623\n",
      "Iteration 3155, loss = 0.00139439\n",
      "Iteration 3156, loss = 0.00139482\n",
      "Iteration 3157, loss = 0.00139361\n",
      "Iteration 3158, loss = 0.00139326\n",
      "Iteration 3159, loss = 0.00139385\n",
      "Iteration 3160, loss = 0.00139461\n",
      "Iteration 3161, loss = 0.00139217\n",
      "Iteration 3162, loss = 0.00139249\n",
      "Iteration 3163, loss = 0.00139093\n",
      "Iteration 3164, loss = 0.00139144\n",
      "Iteration 3165, loss = 0.00139056\n",
      "Iteration 3166, loss = 0.00139069\n",
      "Iteration 3167, loss = 0.00138954\n",
      "Iteration 3168, loss = 0.00138938\n",
      "Iteration 3169, loss = 0.00138841\n",
      "Iteration 3170, loss = 0.00138802\n",
      "Iteration 3171, loss = 0.00138893\n",
      "Iteration 3172, loss = 0.00138680\n",
      "Iteration 3173, loss = 0.00138727\n",
      "Iteration 3174, loss = 0.00138614\n",
      "Iteration 3175, loss = 0.00138522\n",
      "Iteration 3176, loss = 0.00138513\n",
      "Iteration 3177, loss = 0.00138524\n",
      "Iteration 3178, loss = 0.00138419\n",
      "Iteration 3179, loss = 0.00138460\n",
      "Iteration 3180, loss = 0.00138320\n",
      "Iteration 3181, loss = 0.00138243\n",
      "Iteration 3182, loss = 0.00138228\n",
      "Iteration 3183, loss = 0.00138133\n",
      "Iteration 3184, loss = 0.00138162\n",
      "Iteration 3185, loss = 0.00138079\n",
      "Iteration 3186, loss = 0.00138043\n",
      "Iteration 3187, loss = 0.00137997\n",
      "Iteration 3188, loss = 0.00137965\n",
      "Iteration 3189, loss = 0.00137863\n",
      "Iteration 3190, loss = 0.00137907\n",
      "Iteration 3191, loss = 0.00137865\n",
      "Iteration 3192, loss = 0.00137856\n",
      "Iteration 3193, loss = 0.00137783\n",
      "Iteration 3194, loss = 0.00137632\n",
      "Iteration 3195, loss = 0.00137536\n",
      "Iteration 3196, loss = 0.00137615\n",
      "Iteration 3197, loss = 0.00137465\n",
      "Iteration 3198, loss = 0.00137535\n",
      "Iteration 3199, loss = 0.00137331\n",
      "Iteration 3200, loss = 0.00137431\n",
      "Iteration 3201, loss = 0.00137244\n",
      "Iteration 3202, loss = 0.00137421\n",
      "Iteration 3203, loss = 0.00137113\n",
      "Iteration 3204, loss = 0.00137301\n",
      "Iteration 3205, loss = 0.00137191\n",
      "Iteration 3206, loss = 0.00137135\n",
      "Iteration 3207, loss = 0.00137244\n",
      "Iteration 3208, loss = 0.00137246\n",
      "Iteration 3209, loss = 0.00136982\n",
      "Iteration 3210, loss = 0.00136947\n",
      "Iteration 3211, loss = 0.00136876\n",
      "Iteration 3212, loss = 0.00136838\n",
      "Iteration 3213, loss = 0.00136789\n",
      "Iteration 3214, loss = 0.00136734\n",
      "Iteration 3215, loss = 0.00136680\n",
      "Iteration 3216, loss = 0.00136534\n",
      "Iteration 3217, loss = 0.00136580\n",
      "Iteration 3218, loss = 0.00136661\n",
      "Iteration 3219, loss = 0.00136635\n",
      "Iteration 3220, loss = 0.00136443\n",
      "Iteration 3221, loss = 0.00136419\n",
      "Iteration 3222, loss = 0.00136352\n",
      "Iteration 3223, loss = 0.00136289\n",
      "Iteration 3224, loss = 0.00136251\n",
      "Iteration 3225, loss = 0.00136159\n",
      "Iteration 3226, loss = 0.00136140\n",
      "Iteration 3227, loss = 0.00136019\n",
      "Iteration 3228, loss = 0.00136037\n",
      "Iteration 3229, loss = 0.00135904\n",
      "Iteration 3230, loss = 0.00135980\n",
      "Iteration 3231, loss = 0.00135858\n",
      "Iteration 3232, loss = 0.00135810\n",
      "Iteration 3233, loss = 0.00135801\n",
      "Iteration 3234, loss = 0.00135855\n",
      "Iteration 3235, loss = 0.00135716\n",
      "Iteration 3236, loss = 0.00135684\n",
      "Iteration 3237, loss = 0.00135597\n",
      "Iteration 3238, loss = 0.00135663\n",
      "Iteration 3239, loss = 0.00135611\n",
      "Iteration 3240, loss = 0.00135481\n",
      "Iteration 3241, loss = 0.00135460\n",
      "Iteration 3242, loss = 0.00135474\n",
      "Iteration 3243, loss = 0.00135504\n",
      "Iteration 3244, loss = 0.00135279\n",
      "Iteration 3245, loss = 0.00135251\n",
      "Iteration 3246, loss = 0.00135158\n",
      "Iteration 3247, loss = 0.00135117\n",
      "Iteration 3248, loss = 0.00135206\n",
      "Iteration 3249, loss = 0.00135012\n",
      "Iteration 3250, loss = 0.00135071\n",
      "Iteration 3251, loss = 0.00134987\n",
      "Iteration 3252, loss = 0.00134976\n",
      "Iteration 3253, loss = 0.00134912\n",
      "Iteration 3254, loss = 0.00134839\n",
      "Iteration 3255, loss = 0.00134791\n",
      "Iteration 3256, loss = 0.00134849\n",
      "Iteration 3257, loss = 0.00134724\n",
      "Iteration 3258, loss = 0.00134605\n",
      "Iteration 3259, loss = 0.00134580\n",
      "Iteration 3260, loss = 0.00134585\n",
      "Iteration 3261, loss = 0.00134502\n",
      "Iteration 3262, loss = 0.00134438\n",
      "Iteration 3263, loss = 0.00134541\n",
      "Iteration 3264, loss = 0.00134416\n",
      "Iteration 3265, loss = 0.00134488\n",
      "Iteration 3266, loss = 0.00134245\n",
      "Iteration 3267, loss = 0.00134341\n",
      "Iteration 3268, loss = 0.00134222\n",
      "Iteration 3269, loss = 0.00134206\n",
      "Iteration 3270, loss = 0.00134103\n",
      "Iteration 3271, loss = 0.00134187\n",
      "Iteration 3272, loss = 0.00133968\n",
      "Iteration 3273, loss = 0.00134227\n",
      "Iteration 3274, loss = 0.00134136\n",
      "Iteration 3275, loss = 0.00134062\n",
      "Iteration 3276, loss = 0.00133913\n",
      "Iteration 3277, loss = 0.00133919\n",
      "Iteration 3278, loss = 0.00134045\n",
      "Iteration 3279, loss = 0.00134182\n",
      "Iteration 3280, loss = 0.00133762\n",
      "Iteration 3281, loss = 0.00133747\n",
      "Iteration 3282, loss = 0.00133681\n",
      "Iteration 3283, loss = 0.00133738\n",
      "Iteration 3284, loss = 0.00133445\n",
      "Iteration 3285, loss = 0.00133547\n",
      "Iteration 3286, loss = 0.00133576\n",
      "Iteration 3287, loss = 0.00133477\n",
      "Iteration 3288, loss = 0.00133373\n",
      "Iteration 3289, loss = 0.00133281\n",
      "Iteration 3290, loss = 0.00133235\n",
      "Iteration 3291, loss = 0.00133231\n",
      "Iteration 3292, loss = 0.00133122\n",
      "Iteration 3293, loss = 0.00133076\n",
      "Iteration 3294, loss = 0.00132944\n",
      "Iteration 3295, loss = 0.00132972\n",
      "Iteration 3296, loss = 0.00132853\n",
      "Iteration 3297, loss = 0.00133080\n",
      "Iteration 3298, loss = 0.00132778\n",
      "Iteration 3299, loss = 0.00132745\n",
      "Iteration 3300, loss = 0.00132732\n",
      "Iteration 3301, loss = 0.00132640\n",
      "Iteration 3302, loss = 0.00132744\n",
      "Iteration 3303, loss = 0.00132597\n",
      "Iteration 3304, loss = 0.00132557\n",
      "Iteration 3305, loss = 0.00132702\n",
      "Iteration 3306, loss = 0.00132710\n",
      "Iteration 3307, loss = 0.00132369\n",
      "Iteration 3308, loss = 0.00132535\n",
      "Iteration 3309, loss = 0.00132505\n",
      "Iteration 3310, loss = 0.00132422\n",
      "Iteration 3311, loss = 0.00132273\n",
      "Iteration 3312, loss = 0.00132312\n",
      "Iteration 3313, loss = 0.00132242\n",
      "Iteration 3314, loss = 0.00132222\n",
      "Iteration 3315, loss = 0.00132121\n",
      "Iteration 3316, loss = 0.00131998\n",
      "Iteration 3317, loss = 0.00132144\n",
      "Iteration 3318, loss = 0.00132024\n",
      "Iteration 3319, loss = 0.00132193\n",
      "Iteration 3320, loss = 0.00131957\n",
      "Iteration 3321, loss = 0.00131799\n",
      "Iteration 3322, loss = 0.00131852\n",
      "Iteration 3323, loss = 0.00131691\n",
      "Iteration 3324, loss = 0.00131726\n",
      "Iteration 3325, loss = 0.00131595\n",
      "Iteration 3326, loss = 0.00131511\n",
      "Iteration 3327, loss = 0.00131532\n",
      "Iteration 3328, loss = 0.00131499\n",
      "Iteration 3329, loss = 0.00131549\n",
      "Iteration 3330, loss = 0.00131371\n",
      "Iteration 3331, loss = 0.00131420\n",
      "Iteration 3332, loss = 0.00131255\n",
      "Iteration 3333, loss = 0.00131268\n",
      "Iteration 3334, loss = 0.00131252\n",
      "Iteration 3335, loss = 0.00131185\n",
      "Iteration 3336, loss = 0.00131323\n",
      "Iteration 3337, loss = 0.00131278\n",
      "Iteration 3338, loss = 0.00131275\n",
      "Iteration 3339, loss = 0.00131119\n",
      "Iteration 3340, loss = 0.00131060\n",
      "Iteration 3341, loss = 0.00130882\n",
      "Iteration 3342, loss = 0.00130911\n",
      "Iteration 3343, loss = 0.00130914\n",
      "Iteration 3344, loss = 0.00130768\n",
      "Iteration 3345, loss = 0.00130852\n",
      "Iteration 3346, loss = 0.00130688\n",
      "Iteration 3347, loss = 0.00130720\n",
      "Iteration 3348, loss = 0.00130666\n",
      "Iteration 3349, loss = 0.00130561\n",
      "Iteration 3350, loss = 0.00130509\n",
      "Iteration 3351, loss = 0.00130409\n",
      "Iteration 3352, loss = 0.00130433\n",
      "Iteration 3353, loss = 0.00130543\n",
      "Iteration 3354, loss = 0.00130336\n",
      "Iteration 3355, loss = 0.00130335\n",
      "Iteration 3356, loss = 0.00130189\n",
      "Iteration 3357, loss = 0.00130246\n",
      "Iteration 3358, loss = 0.00130259\n",
      "Iteration 3359, loss = 0.00130161\n",
      "Iteration 3360, loss = 0.00130147\n",
      "Iteration 3361, loss = 0.00130160\n",
      "Iteration 3362, loss = 0.00130131\n",
      "Iteration 3363, loss = 0.00130068\n",
      "Iteration 3364, loss = 0.00130223\n",
      "Iteration 3365, loss = 0.00129952\n",
      "Iteration 3366, loss = 0.00129926\n",
      "Iteration 3367, loss = 0.00129823\n",
      "Iteration 3368, loss = 0.00129885\n",
      "Iteration 3369, loss = 0.00129670\n",
      "Iteration 3370, loss = 0.00129763\n",
      "Iteration 3371, loss = 0.00129648\n",
      "Iteration 3372, loss = 0.00129536\n",
      "Iteration 3373, loss = 0.00129604\n",
      "Iteration 3374, loss = 0.00129640\n",
      "Iteration 3375, loss = 0.00129645\n",
      "Iteration 3376, loss = 0.00129386\n",
      "Iteration 3377, loss = 0.00129383\n",
      "Iteration 3378, loss = 0.00129313\n",
      "Iteration 3379, loss = 0.00129269\n",
      "Iteration 3380, loss = 0.00129247\n",
      "Iteration 3381, loss = 0.00129192\n",
      "Iteration 3382, loss = 0.00129475\n",
      "Iteration 3383, loss = 0.00129047\n",
      "Iteration 3384, loss = 0.00129155\n",
      "Iteration 3385, loss = 0.00128954\n",
      "Iteration 3386, loss = 0.00129081\n",
      "Iteration 3387, loss = 0.00129000\n",
      "Iteration 3388, loss = 0.00128948\n",
      "Iteration 3389, loss = 0.00128779\n",
      "Iteration 3390, loss = 0.00128744\n",
      "Iteration 3391, loss = 0.00128740\n",
      "Iteration 3392, loss = 0.00128656\n",
      "Iteration 3393, loss = 0.00128766\n",
      "Iteration 3394, loss = 0.00128615\n",
      "Iteration 3395, loss = 0.00128522\n",
      "Iteration 3396, loss = 0.00128522\n",
      "Iteration 3397, loss = 0.00128695\n",
      "Iteration 3398, loss = 0.00128359\n",
      "Iteration 3399, loss = 0.00128759\n",
      "Iteration 3400, loss = 0.00128578\n",
      "Iteration 3401, loss = 0.00128448\n",
      "Iteration 3402, loss = 0.00128357\n",
      "Iteration 3403, loss = 0.00128211\n",
      "Iteration 3404, loss = 0.00128281\n",
      "Iteration 3405, loss = 0.00128120\n",
      "Iteration 3406, loss = 0.00128213\n",
      "Iteration 3407, loss = 0.00128106\n",
      "Iteration 3408, loss = 0.00128035\n",
      "Iteration 3409, loss = 0.00128100\n",
      "Iteration 3410, loss = 0.00127954\n",
      "Iteration 3411, loss = 0.00128106\n",
      "Iteration 3412, loss = 0.00127854\n",
      "Iteration 3413, loss = 0.00127919\n",
      "Iteration 3414, loss = 0.00128270\n",
      "Iteration 3415, loss = 0.00127909\n",
      "Iteration 3416, loss = 0.00127930\n",
      "Iteration 3417, loss = 0.00128047\n",
      "Iteration 3418, loss = 0.00127668\n",
      "Iteration 3419, loss = 0.00128055\n",
      "Iteration 3420, loss = 0.00127732\n",
      "Iteration 3421, loss = 0.00127766\n",
      "Iteration 3422, loss = 0.00127787\n",
      "Iteration 3423, loss = 0.00127278\n",
      "Iteration 3424, loss = 0.00127508\n",
      "Iteration 3425, loss = 0.00127422\n",
      "Iteration 3426, loss = 0.00127290\n",
      "Iteration 3427, loss = 0.00127328\n",
      "Iteration 3428, loss = 0.00127121\n",
      "Iteration 3429, loss = 0.00127095\n",
      "Iteration 3430, loss = 0.00127155\n",
      "Iteration 3431, loss = 0.00127037\n",
      "Iteration 3432, loss = 0.00126980\n",
      "Iteration 3433, loss = 0.00126946\n",
      "Iteration 3434, loss = 0.00126922\n",
      "Iteration 3435, loss = 0.00126896\n",
      "Iteration 3436, loss = 0.00126792\n",
      "Iteration 3437, loss = 0.00126817\n",
      "Iteration 3438, loss = 0.00126724\n",
      "Iteration 3439, loss = 0.00126672\n",
      "Iteration 3440, loss = 0.00126776\n",
      "Iteration 3441, loss = 0.00126573\n",
      "Iteration 3442, loss = 0.00126622\n",
      "Iteration 3443, loss = 0.00126585\n",
      "Iteration 3444, loss = 0.00126500\n",
      "Iteration 3445, loss = 0.00126411\n",
      "Iteration 3446, loss = 0.00126540\n",
      "Iteration 3447, loss = 0.00126395\n",
      "Iteration 3448, loss = 0.00126507\n",
      "Iteration 3449, loss = 0.00126515\n",
      "Iteration 3450, loss = 0.00126323\n",
      "Iteration 3451, loss = 0.00126202\n",
      "Iteration 3452, loss = 0.00126201\n",
      "Iteration 3453, loss = 0.00126104\n",
      "Iteration 3454, loss = 0.00126068\n",
      "Iteration 3455, loss = 0.00125997\n",
      "Iteration 3456, loss = 0.00126042\n",
      "Iteration 3457, loss = 0.00125941\n",
      "Iteration 3458, loss = 0.00125959\n",
      "Iteration 3459, loss = 0.00125978\n",
      "Iteration 3460, loss = 0.00125856\n",
      "Iteration 3461, loss = 0.00125884\n",
      "Iteration 3462, loss = 0.00125954\n",
      "Iteration 3463, loss = 0.00125727\n",
      "Iteration 3464, loss = 0.00125708\n",
      "Iteration 3465, loss = 0.00125689\n",
      "Iteration 3466, loss = 0.00125866\n",
      "Iteration 3467, loss = 0.00125581\n",
      "Iteration 3468, loss = 0.00125628\n",
      "Iteration 3469, loss = 0.00125520\n",
      "Iteration 3470, loss = 0.00125719\n",
      "Iteration 3471, loss = 0.00125399\n",
      "Iteration 3472, loss = 0.00125428\n",
      "Iteration 3473, loss = 0.00125313\n",
      "Iteration 3474, loss = 0.00125600\n",
      "Iteration 3475, loss = 0.00125282\n",
      "Iteration 3476, loss = 0.00125279\n",
      "Iteration 3477, loss = 0.00125272\n",
      "Iteration 3478, loss = 0.00125090\n",
      "Iteration 3479, loss = 0.00125212\n",
      "Iteration 3480, loss = 0.00125110\n",
      "Iteration 3481, loss = 0.00125016\n",
      "Iteration 3482, loss = 0.00125004\n",
      "Iteration 3483, loss = 0.00124876\n",
      "Iteration 3484, loss = 0.00124999\n",
      "Iteration 3485, loss = 0.00124788\n",
      "Iteration 3486, loss = 0.00124848\n",
      "Iteration 3487, loss = 0.00124670\n",
      "Iteration 3488, loss = 0.00125085\n",
      "Iteration 3489, loss = 0.00124581\n",
      "Iteration 3490, loss = 0.00124756\n",
      "Iteration 3491, loss = 0.00124520\n",
      "Iteration 3492, loss = 0.00124502\n",
      "Iteration 3493, loss = 0.00124588\n",
      "Iteration 3494, loss = 0.00124405\n",
      "Iteration 3495, loss = 0.00124431\n",
      "Iteration 3496, loss = 0.00124405\n",
      "Iteration 3497, loss = 0.00124340\n",
      "Iteration 3498, loss = 0.00124356\n",
      "Iteration 3499, loss = 0.00124236\n",
      "Iteration 3500, loss = 0.00124225\n",
      "Iteration 3501, loss = 0.00124245\n",
      "Iteration 3502, loss = 0.00124057\n",
      "Iteration 3503, loss = 0.00124100\n",
      "Iteration 3504, loss = 0.00124056\n",
      "Iteration 3505, loss = 0.00124029\n",
      "Iteration 3506, loss = 0.00124054\n",
      "Iteration 3507, loss = 0.00123931\n",
      "Iteration 3508, loss = 0.00123862\n",
      "Iteration 3509, loss = 0.00123933\n",
      "Iteration 3510, loss = 0.00123768\n",
      "Iteration 3511, loss = 0.00123733\n",
      "Iteration 3512, loss = 0.00123849\n",
      "Iteration 3513, loss = 0.00123687\n",
      "Iteration 3514, loss = 0.00123769\n",
      "Iteration 3515, loss = 0.00123693\n",
      "Iteration 3516, loss = 0.00123608\n",
      "Iteration 3517, loss = 0.00123536\n",
      "Iteration 3518, loss = 0.00123477\n",
      "Iteration 3519, loss = 0.00123614\n",
      "Iteration 3520, loss = 0.00123486\n",
      "Iteration 3521, loss = 0.00123378\n",
      "Iteration 3522, loss = 0.00123355\n",
      "Iteration 3523, loss = 0.00123465\n",
      "Iteration 3524, loss = 0.00123453\n",
      "Iteration 3525, loss = 0.00123325\n",
      "Iteration 3526, loss = 0.00123164\n",
      "Iteration 3527, loss = 0.00123450\n",
      "Iteration 3528, loss = 0.00123062\n",
      "Iteration 3529, loss = 0.00123264\n",
      "Iteration 3530, loss = 0.00123003\n",
      "Iteration 3531, loss = 0.00123139\n",
      "Iteration 3532, loss = 0.00123040\n",
      "Iteration 3533, loss = 0.00123047\n",
      "Iteration 3534, loss = 0.00122861\n",
      "Iteration 3535, loss = 0.00123006\n",
      "Iteration 3536, loss = 0.00122988\n",
      "Iteration 3537, loss = 0.00122880\n",
      "Iteration 3538, loss = 0.00122689\n",
      "Iteration 3539, loss = 0.00122672\n",
      "Iteration 3540, loss = 0.00122650\n",
      "Iteration 3541, loss = 0.00122770\n",
      "Iteration 3542, loss = 0.00122539\n",
      "Iteration 3543, loss = 0.00122944\n",
      "Iteration 3544, loss = 0.00122462\n",
      "Iteration 3545, loss = 0.00122771\n",
      "Iteration 3546, loss = 0.00122898\n",
      "Iteration 3547, loss = 0.00123082\n",
      "Iteration 3548, loss = 0.00122485\n",
      "Iteration 3549, loss = 0.00122773\n",
      "Iteration 3550, loss = 0.00122469\n",
      "Iteration 3551, loss = 0.00122723\n",
      "Iteration 3552, loss = 0.00122279\n",
      "Iteration 3553, loss = 0.00122558\n",
      "Iteration 3554, loss = 0.00122530\n",
      "Iteration 3555, loss = 0.00122405\n",
      "Iteration 3556, loss = 0.00122328\n",
      "Iteration 3557, loss = 0.00122686\n",
      "Iteration 3558, loss = 0.00122159\n",
      "Iteration 3559, loss = 0.00122458\n",
      "Iteration 3560, loss = 0.00122108\n",
      "Iteration 3561, loss = 0.00121934\n",
      "Iteration 3562, loss = 0.00122045\n",
      "Iteration 3563, loss = 0.00121996\n",
      "Iteration 3564, loss = 0.00121870\n",
      "Iteration 3565, loss = 0.00121795\n",
      "Iteration 3566, loss = 0.00121634\n",
      "Iteration 3567, loss = 0.00121690\n",
      "Iteration 3568, loss = 0.00121580\n",
      "Iteration 3569, loss = 0.00121535\n",
      "Iteration 3570, loss = 0.00121511\n",
      "Iteration 3571, loss = 0.00121417\n",
      "Iteration 3572, loss = 0.00121424\n",
      "Iteration 3573, loss = 0.00121497\n",
      "Iteration 3574, loss = 0.00121319\n",
      "Iteration 3575, loss = 0.00121440\n",
      "Iteration 3576, loss = 0.00121397\n",
      "Iteration 3577, loss = 0.00121455\n",
      "Iteration 3578, loss = 0.00121274\n",
      "Iteration 3579, loss = 0.00121072\n",
      "Iteration 3580, loss = 0.00121086\n",
      "Iteration 3581, loss = 0.00121051\n",
      "Iteration 3582, loss = 0.00120902\n",
      "Iteration 3583, loss = 0.00120918\n",
      "Iteration 3584, loss = 0.00120875\n",
      "Iteration 3585, loss = 0.00120806\n",
      "Iteration 3586, loss = 0.00120787\n",
      "Iteration 3587, loss = 0.00120772\n",
      "Iteration 3588, loss = 0.00120770\n",
      "Iteration 3589, loss = 0.00120677\n",
      "Iteration 3590, loss = 0.00120759\n",
      "Iteration 3591, loss = 0.00120579\n",
      "Iteration 3592, loss = 0.00120607\n",
      "Iteration 3593, loss = 0.00120645\n",
      "Iteration 3594, loss = 0.00120566\n",
      "Iteration 3595, loss = 0.00120619\n",
      "Iteration 3596, loss = 0.00120492\n",
      "Iteration 3597, loss = 0.00120454\n",
      "Iteration 3598, loss = 0.00120358\n",
      "Iteration 3599, loss = 0.00120341\n",
      "Iteration 3600, loss = 0.00120264\n",
      "Iteration 3601, loss = 0.00120227\n",
      "Iteration 3602, loss = 0.00120232\n",
      "Iteration 3603, loss = 0.00120128\n",
      "Iteration 3604, loss = 0.00120084\n",
      "Iteration 3605, loss = 0.00120038\n",
      "Iteration 3606, loss = 0.00120079\n",
      "Iteration 3607, loss = 0.00120003\n",
      "Iteration 3608, loss = 0.00119976\n",
      "Iteration 3609, loss = 0.00119993\n",
      "Iteration 3610, loss = 0.00119983\n",
      "Iteration 3611, loss = 0.00119914\n",
      "Iteration 3612, loss = 0.00119879\n",
      "Iteration 3613, loss = 0.00119826\n",
      "Iteration 3614, loss = 0.00119803\n",
      "Iteration 3615, loss = 0.00119747\n",
      "Iteration 3616, loss = 0.00119729\n",
      "Iteration 3617, loss = 0.00119692\n",
      "Iteration 3618, loss = 0.00119558\n",
      "Iteration 3619, loss = 0.00119568\n",
      "Iteration 3620, loss = 0.00119604\n",
      "Iteration 3621, loss = 0.00119447\n",
      "Iteration 3622, loss = 0.00119495\n",
      "Iteration 3623, loss = 0.00119566\n",
      "Iteration 3624, loss = 0.00119561\n",
      "Iteration 3625, loss = 0.00119386\n",
      "Iteration 3626, loss = 0.00119457\n",
      "Iteration 3627, loss = 0.00119274\n",
      "Iteration 3628, loss = 0.00119337\n",
      "Iteration 3629, loss = 0.00119118\n",
      "Iteration 3630, loss = 0.00119289\n",
      "Iteration 3631, loss = 0.00119309\n",
      "Iteration 3632, loss = 0.00119594\n",
      "Iteration 3633, loss = 0.00119485\n",
      "Iteration 3634, loss = 0.00119202\n",
      "Iteration 3635, loss = 0.00119333\n",
      "Iteration 3636, loss = 0.00119126\n",
      "Iteration 3637, loss = 0.00119063\n",
      "Iteration 3638, loss = 0.00119257\n",
      "Iteration 3639, loss = 0.00118942\n",
      "Iteration 3640, loss = 0.00119066\n",
      "Iteration 3641, loss = 0.00118868\n",
      "Iteration 3642, loss = 0.00118821\n",
      "Iteration 3643, loss = 0.00118787\n",
      "Iteration 3644, loss = 0.00118863\n",
      "Iteration 3645, loss = 0.00118693\n",
      "Iteration 3646, loss = 0.00118807\n",
      "Iteration 3647, loss = 0.00118681\n",
      "Iteration 3648, loss = 0.00118574\n",
      "Iteration 3649, loss = 0.00118579\n",
      "Iteration 3650, loss = 0.00118502\n",
      "Iteration 3651, loss = 0.00118381\n",
      "Iteration 3652, loss = 0.00118444\n",
      "Iteration 3653, loss = 0.00118411\n",
      "Iteration 3654, loss = 0.00118293\n",
      "Iteration 3655, loss = 0.00118233\n",
      "Iteration 3656, loss = 0.00118269\n",
      "Iteration 3657, loss = 0.00118073\n",
      "Iteration 3658, loss = 0.00118191\n",
      "Iteration 3659, loss = 0.00118091\n",
      "Iteration 3660, loss = 0.00118051\n",
      "Iteration 3661, loss = 0.00118065\n",
      "Iteration 3662, loss = 0.00117912\n",
      "Iteration 3663, loss = 0.00117955\n",
      "Iteration 3664, loss = 0.00117928\n",
      "Iteration 3665, loss = 0.00117837\n",
      "Iteration 3666, loss = 0.00117816\n",
      "Iteration 3667, loss = 0.00117791\n",
      "Iteration 3668, loss = 0.00117772\n",
      "Iteration 3669, loss = 0.00117811\n",
      "Iteration 3670, loss = 0.00118118\n",
      "Iteration 3671, loss = 0.00117644\n",
      "Iteration 3672, loss = 0.00117916\n",
      "Iteration 3673, loss = 0.00117600\n",
      "Iteration 3674, loss = 0.00117682\n",
      "Iteration 3675, loss = 0.00117437\n",
      "Iteration 3676, loss = 0.00117633\n",
      "Iteration 3677, loss = 0.00117462\n",
      "Iteration 3678, loss = 0.00117553\n",
      "Iteration 3679, loss = 0.00117404\n",
      "Iteration 3680, loss = 0.00117389\n",
      "Iteration 3681, loss = 0.00117326\n",
      "Iteration 3682, loss = 0.00117236\n",
      "Iteration 3683, loss = 0.00117153\n",
      "Iteration 3684, loss = 0.00117592\n",
      "Iteration 3685, loss = 0.00117376\n",
      "Iteration 3686, loss = 0.00117450\n",
      "Iteration 3687, loss = 0.00117348\n",
      "Iteration 3688, loss = 0.00117367\n",
      "Iteration 3689, loss = 0.00117137\n",
      "Iteration 3690, loss = 0.00117761\n",
      "Iteration 3691, loss = 0.00117905\n",
      "Iteration 3692, loss = 0.00117008\n",
      "Iteration 3693, loss = 0.00117730\n",
      "Iteration 3694, loss = 0.00117177\n",
      "Iteration 3695, loss = 0.00117129\n",
      "Iteration 3696, loss = 0.00117478\n",
      "Iteration 3697, loss = 0.00116878\n",
      "Iteration 3698, loss = 0.00116893\n",
      "Iteration 3699, loss = 0.00117113\n",
      "Iteration 3700, loss = 0.00116718\n",
      "Iteration 3701, loss = 0.00116943\n",
      "Iteration 3702, loss = 0.00116667\n",
      "Iteration 3703, loss = 0.00116797\n",
      "Iteration 3704, loss = 0.00116547\n",
      "Iteration 3705, loss = 0.00116715\n",
      "Iteration 3706, loss = 0.00116503\n",
      "Iteration 3707, loss = 0.00116395\n",
      "Iteration 3708, loss = 0.00116510\n",
      "Iteration 3709, loss = 0.00116360\n",
      "Iteration 3710, loss = 0.00116352\n",
      "Iteration 3711, loss = 0.00116609\n",
      "Iteration 3712, loss = 0.00116176\n",
      "Iteration 3713, loss = 0.00116422\n",
      "Iteration 3714, loss = 0.00116276\n",
      "Iteration 3715, loss = 0.00116416\n",
      "Iteration 3716, loss = 0.00116170\n",
      "Iteration 3717, loss = 0.00116114\n",
      "Iteration 3718, loss = 0.00115987\n",
      "Iteration 3719, loss = 0.00116043\n",
      "Iteration 3720, loss = 0.00115950\n",
      "Iteration 3721, loss = 0.00116209\n",
      "Iteration 3722, loss = 0.00116130\n",
      "Iteration 3723, loss = 0.00115952\n",
      "Iteration 3724, loss = 0.00116029\n",
      "Iteration 3725, loss = 0.00115791\n",
      "Iteration 3726, loss = 0.00115788\n",
      "Iteration 3727, loss = 0.00115848\n",
      "Iteration 3728, loss = 0.00115790\n",
      "Iteration 3729, loss = 0.00115802\n",
      "Iteration 3730, loss = 0.00115558\n",
      "Iteration 3731, loss = 0.00115780\n",
      "Iteration 3732, loss = 0.00115444\n",
      "Iteration 3733, loss = 0.00115646\n",
      "Iteration 3734, loss = 0.00115407\n",
      "Iteration 3735, loss = 0.00115595\n",
      "Iteration 3736, loss = 0.00115312\n",
      "Iteration 3737, loss = 0.00115454\n",
      "Iteration 3738, loss = 0.00115259\n",
      "Iteration 3739, loss = 0.00115484\n",
      "Iteration 3740, loss = 0.00115375\n",
      "Iteration 3741, loss = 0.00115326\n",
      "Iteration 3742, loss = 0.00115044\n",
      "Iteration 3743, loss = 0.00115130\n",
      "Iteration 3744, loss = 0.00115187\n",
      "Iteration 3745, loss = 0.00115073\n",
      "Iteration 3746, loss = 0.00114988\n",
      "Iteration 3747, loss = 0.00115293\n",
      "Iteration 3748, loss = 0.00115116\n",
      "Iteration 3749, loss = 0.00115154\n",
      "Iteration 3750, loss = 0.00115139\n",
      "Iteration 3751, loss = 0.00115164\n",
      "Iteration 3752, loss = 0.00114933\n",
      "Iteration 3753, loss = 0.00115005\n",
      "Iteration 3754, loss = 0.00114724\n",
      "Iteration 3755, loss = 0.00114895\n",
      "Iteration 3756, loss = 0.00114940\n",
      "Iteration 3757, loss = 0.00114869\n",
      "Iteration 3758, loss = 0.00114681\n",
      "Iteration 3759, loss = 0.00114756\n",
      "Iteration 3760, loss = 0.00114534\n",
      "Iteration 3761, loss = 0.00114513\n",
      "Iteration 3762, loss = 0.00114473\n",
      "Iteration 3763, loss = 0.00114471\n",
      "Iteration 3764, loss = 0.00114416\n",
      "Iteration 3765, loss = 0.00114397\n",
      "Iteration 3766, loss = 0.00114380\n",
      "Iteration 3767, loss = 0.00114543\n",
      "Iteration 3768, loss = 0.00114354\n",
      "Iteration 3769, loss = 0.00114304\n",
      "Iteration 3770, loss = 0.00114386\n",
      "Iteration 3771, loss = 0.00114205\n",
      "Iteration 3772, loss = 0.00114109\n",
      "Iteration 3773, loss = 0.00114248\n",
      "Iteration 3774, loss = 0.00114043\n",
      "Iteration 3775, loss = 0.00114051\n",
      "Iteration 3776, loss = 0.00114077\n",
      "Iteration 3777, loss = 0.00114012\n",
      "Iteration 3778, loss = 0.00113883\n",
      "Iteration 3779, loss = 0.00113883\n",
      "Iteration 3780, loss = 0.00113856\n",
      "Iteration 3781, loss = 0.00113920\n",
      "Iteration 3782, loss = 0.00113782\n",
      "Iteration 3783, loss = 0.00113759\n",
      "Iteration 3784, loss = 0.00113641\n",
      "Iteration 3785, loss = 0.00113705\n",
      "Iteration 3786, loss = 0.00113582\n",
      "Iteration 3787, loss = 0.00113646\n",
      "Iteration 3788, loss = 0.00113483\n",
      "Iteration 3789, loss = 0.00113631\n",
      "Iteration 3790, loss = 0.00113424\n",
      "Iteration 3791, loss = 0.00113500\n",
      "Iteration 3792, loss = 0.00113491\n",
      "Iteration 3793, loss = 0.00113478\n",
      "Iteration 3794, loss = 0.00113524\n",
      "Iteration 3795, loss = 0.00113474\n",
      "Iteration 3796, loss = 0.00113436\n",
      "Iteration 3797, loss = 0.00113341\n",
      "Iteration 3798, loss = 0.00113324\n",
      "Iteration 3799, loss = 0.00113279\n",
      "Iteration 3800, loss = 0.00113256\n",
      "Iteration 3801, loss = 0.00113462\n",
      "Iteration 3802, loss = 0.00113135\n",
      "Iteration 3803, loss = 0.00113443\n",
      "Iteration 3804, loss = 0.00112982\n",
      "Iteration 3805, loss = 0.00113245\n",
      "Iteration 3806, loss = 0.00113057\n",
      "Iteration 3807, loss = 0.00113137\n",
      "Iteration 3808, loss = 0.00112992\n",
      "Iteration 3809, loss = 0.00112980\n",
      "Iteration 3810, loss = 0.00112955\n",
      "Iteration 3811, loss = 0.00112837\n",
      "Iteration 3812, loss = 0.00112967\n",
      "Iteration 3813, loss = 0.00112774\n",
      "Iteration 3814, loss = 0.00112738\n",
      "Iteration 3815, loss = 0.00112721\n",
      "Iteration 3816, loss = 0.00112609\n",
      "Iteration 3817, loss = 0.00112650\n",
      "Iteration 3818, loss = 0.00112839\n",
      "Iteration 3819, loss = 0.00112733\n",
      "Iteration 3820, loss = 0.00112579\n",
      "Iteration 3821, loss = 0.00112908\n",
      "Iteration 3822, loss = 0.00112691\n",
      "Iteration 3823, loss = 0.00112545\n",
      "Iteration 3824, loss = 0.00112945\n",
      "Iteration 3825, loss = 0.00112343\n",
      "Iteration 3826, loss = 0.00112675\n",
      "Iteration 3827, loss = 0.00112377\n",
      "Iteration 3828, loss = 0.00112390\n",
      "Iteration 3829, loss = 0.00112555\n",
      "Iteration 3830, loss = 0.00112159\n",
      "Iteration 3831, loss = 0.00112416\n",
      "Iteration 3832, loss = 0.00112102\n",
      "Iteration 3833, loss = 0.00112246\n",
      "Iteration 3834, loss = 0.00112214\n",
      "Iteration 3835, loss = 0.00112195\n",
      "Iteration 3836, loss = 0.00112162\n",
      "Iteration 3837, loss = 0.00112198\n",
      "Iteration 3838, loss = 0.00111963\n",
      "Iteration 3839, loss = 0.00111964\n",
      "Iteration 3840, loss = 0.00112145\n",
      "Iteration 3841, loss = 0.00112125\n",
      "Iteration 3842, loss = 0.00112021\n",
      "Iteration 3843, loss = 0.00112133\n",
      "Iteration 3844, loss = 0.00111699\n",
      "Iteration 3845, loss = 0.00111812\n",
      "Iteration 3846, loss = 0.00111781\n",
      "Iteration 3847, loss = 0.00111665\n",
      "Iteration 3848, loss = 0.00111656\n",
      "Iteration 3849, loss = 0.00111697\n",
      "Iteration 3850, loss = 0.00111638\n",
      "Iteration 3851, loss = 0.00111445\n",
      "Iteration 3852, loss = 0.00111601\n",
      "Iteration 3853, loss = 0.00111370\n",
      "Iteration 3854, loss = 0.00111552\n",
      "Iteration 3855, loss = 0.00111364\n",
      "Iteration 3856, loss = 0.00111461\n",
      "Iteration 3857, loss = 0.00111365\n",
      "Iteration 3858, loss = 0.00111330\n",
      "Iteration 3859, loss = 0.00111225\n",
      "Iteration 3860, loss = 0.00111282\n",
      "Iteration 3861, loss = 0.00111542\n",
      "Iteration 3862, loss = 0.00111382\n",
      "Iteration 3863, loss = 0.00111448\n",
      "Iteration 3864, loss = 0.00111276\n",
      "Iteration 3865, loss = 0.00111453\n",
      "Iteration 3866, loss = 0.00111265\n",
      "Iteration 3867, loss = 0.00111266\n",
      "Iteration 3868, loss = 0.00111146\n",
      "Iteration 3869, loss = 0.00111000\n",
      "Iteration 3870, loss = 0.00110847\n",
      "Iteration 3871, loss = 0.00111320\n",
      "Iteration 3872, loss = 0.00110861\n",
      "Iteration 3873, loss = 0.00111005\n",
      "Iteration 3874, loss = 0.00110877\n",
      "Iteration 3875, loss = 0.00110781\n",
      "Iteration 3876, loss = 0.00110849\n",
      "Iteration 3877, loss = 0.00110666\n",
      "Iteration 3878, loss = 0.00110632\n",
      "Iteration 3879, loss = 0.00110622\n",
      "Iteration 3880, loss = 0.00110598\n",
      "Iteration 3881, loss = 0.00110532\n",
      "Iteration 3882, loss = 0.00110462\n",
      "Iteration 3883, loss = 0.00110550\n",
      "Iteration 3884, loss = 0.00110587\n",
      "Iteration 3885, loss = 0.00110639\n",
      "Iteration 3886, loss = 0.00110465\n",
      "Iteration 3887, loss = 0.00110408\n",
      "Iteration 3888, loss = 0.00110466\n",
      "Iteration 3889, loss = 0.00110435\n",
      "Iteration 3890, loss = 0.00110324\n",
      "Iteration 3891, loss = 0.00110358\n",
      "Iteration 3892, loss = 0.00110490\n",
      "Iteration 3893, loss = 0.00110079\n",
      "Iteration 3894, loss = 0.00110488\n",
      "Iteration 3895, loss = 0.00110555\n",
      "Iteration 3896, loss = 0.00110124\n",
      "Iteration 3897, loss = 0.00110383\n",
      "Iteration 3898, loss = 0.00110314\n",
      "Iteration 3899, loss = 0.00110193\n",
      "Iteration 3900, loss = 0.00110072\n",
      "Iteration 3901, loss = 0.00110108\n",
      "Iteration 3902, loss = 0.00110109\n",
      "Iteration 3903, loss = 0.00110218\n",
      "Iteration 3904, loss = 0.00109865\n",
      "Iteration 3905, loss = 0.00110177\n",
      "Iteration 3906, loss = 0.00109939\n",
      "Iteration 3907, loss = 0.00110005\n",
      "Iteration 3908, loss = 0.00109942\n",
      "Iteration 3909, loss = 0.00109788\n",
      "Iteration 3910, loss = 0.00110089\n",
      "Iteration 3911, loss = 0.00109956\n",
      "Iteration 3912, loss = 0.00109846\n",
      "Iteration 3913, loss = 0.00109857\n",
      "Iteration 3914, loss = 0.00109483\n",
      "Iteration 3915, loss = 0.00109673\n",
      "Iteration 3916, loss = 0.00109445\n",
      "Iteration 3917, loss = 0.00109604\n",
      "Iteration 3918, loss = 0.00109491\n",
      "Iteration 3919, loss = 0.00109421\n",
      "Iteration 3920, loss = 0.00109359\n",
      "Iteration 3921, loss = 0.00109322\n",
      "Iteration 3922, loss = 0.00109338\n",
      "Iteration 3923, loss = 0.00109339\n",
      "Iteration 3924, loss = 0.00109467\n",
      "Iteration 3925, loss = 0.00109152\n",
      "Iteration 3926, loss = 0.00109189\n",
      "Iteration 3927, loss = 0.00109036\n",
      "Iteration 3928, loss = 0.00109115\n",
      "Iteration 3929, loss = 0.00109196\n",
      "Iteration 3930, loss = 0.00109044\n",
      "Iteration 3931, loss = 0.00109041\n",
      "Iteration 3932, loss = 0.00109032\n",
      "Iteration 3933, loss = 0.00108860\n",
      "Iteration 3934, loss = 0.00108982\n",
      "Iteration 3935, loss = 0.00108856\n",
      "Iteration 3936, loss = 0.00108984\n",
      "Iteration 3937, loss = 0.00108754\n",
      "Iteration 3938, loss = 0.00108822\n",
      "Iteration 3939, loss = 0.00108743\n",
      "Iteration 3940, loss = 0.00108792\n",
      "Iteration 3941, loss = 0.00108761\n",
      "Iteration 3942, loss = 0.00108619\n",
      "Iteration 3943, loss = 0.00108576\n",
      "Iteration 3944, loss = 0.00108588\n",
      "Iteration 3945, loss = 0.00108492\n",
      "Iteration 3946, loss = 0.00108582\n",
      "Iteration 3947, loss = 0.00108470\n",
      "Iteration 3948, loss = 0.00108433\n",
      "Iteration 3949, loss = 0.00108591\n",
      "Iteration 3950, loss = 0.00108371\n",
      "Iteration 3951, loss = 0.00108470\n",
      "Iteration 3952, loss = 0.00108345\n",
      "Iteration 3953, loss = 0.00108384\n",
      "Iteration 3954, loss = 0.00108441\n",
      "Iteration 3955, loss = 0.00108360\n",
      "Iteration 3956, loss = 0.00108631\n",
      "Iteration 3957, loss = 0.00108174\n",
      "Iteration 3958, loss = 0.00108414\n",
      "Iteration 3959, loss = 0.00108088\n",
      "Iteration 3960, loss = 0.00108459\n",
      "Iteration 3961, loss = 0.00108120\n",
      "Iteration 3962, loss = 0.00108069\n",
      "Iteration 3963, loss = 0.00108146\n",
      "Iteration 3964, loss = 0.00108021\n",
      "Iteration 3965, loss = 0.00107976\n",
      "Iteration 3966, loss = 0.00107863\n",
      "Iteration 3967, loss = 0.00107892\n",
      "Iteration 3968, loss = 0.00107957\n",
      "Iteration 3969, loss = 0.00107966\n",
      "Iteration 3970, loss = 0.00107797\n",
      "Iteration 3971, loss = 0.00107769\n",
      "Iteration 3972, loss = 0.00107668\n",
      "Iteration 3973, loss = 0.00107767\n",
      "Iteration 3974, loss = 0.00107743\n",
      "Iteration 3975, loss = 0.00107601\n",
      "Iteration 3976, loss = 0.00107765\n",
      "Iteration 3977, loss = 0.00107575\n",
      "Iteration 3978, loss = 0.00107622\n",
      "Iteration 3979, loss = 0.00107769\n",
      "Iteration 3980, loss = 0.00107481\n",
      "Iteration 3981, loss = 0.00107536\n",
      "Iteration 3982, loss = 0.00107392\n",
      "Iteration 3983, loss = 0.00107482\n",
      "Iteration 3984, loss = 0.00107531\n",
      "Iteration 3985, loss = 0.00107625\n",
      "Iteration 3986, loss = 0.00107430\n",
      "Iteration 3987, loss = 0.00107763\n",
      "Iteration 3988, loss = 0.00107266\n",
      "Iteration 3989, loss = 0.00107451\n",
      "Iteration 3990, loss = 0.00107465\n",
      "Iteration 3991, loss = 0.00107170\n",
      "Iteration 3992, loss = 0.00107278\n",
      "Iteration 3993, loss = 0.00107160\n",
      "Iteration 3994, loss = 0.00107145\n",
      "Iteration 3995, loss = 0.00107116\n",
      "Iteration 3996, loss = 0.00107008\n",
      "Iteration 3997, loss = 0.00107229\n",
      "Iteration 3998, loss = 0.00106930\n",
      "Iteration 3999, loss = 0.00106876\n",
      "Iteration 4000, loss = 0.00107008\n",
      "Iteration 4001, loss = 0.00106849\n",
      "Iteration 4002, loss = 0.00106830\n",
      "Iteration 4003, loss = 0.00106923\n",
      "Iteration 4004, loss = 0.00106773\n",
      "Iteration 4005, loss = 0.00106891\n",
      "Iteration 4006, loss = 0.00106741\n",
      "Iteration 4007, loss = 0.00106859\n",
      "Iteration 4008, loss = 0.00106703\n",
      "Iteration 4009, loss = 0.00106686\n",
      "Iteration 4010, loss = 0.00106599\n",
      "Iteration 4011, loss = 0.00106626\n",
      "Iteration 4012, loss = 0.00106504\n",
      "Iteration 4013, loss = 0.00106627\n",
      "Iteration 4014, loss = 0.00106606\n",
      "Iteration 4015, loss = 0.00106527\n",
      "Iteration 4016, loss = 0.00106538\n",
      "Iteration 4017, loss = 0.00106402\n",
      "Iteration 4018, loss = 0.00106424\n",
      "Iteration 4019, loss = 0.00106445\n",
      "Iteration 4020, loss = 0.00106272\n",
      "Iteration 4021, loss = 0.00106251\n",
      "Iteration 4022, loss = 0.00106172\n",
      "Iteration 4023, loss = 0.00106370\n",
      "Iteration 4024, loss = 0.00106107\n",
      "Iteration 4025, loss = 0.00106207\n",
      "Iteration 4026, loss = 0.00106110\n",
      "Iteration 4027, loss = 0.00106310\n",
      "Iteration 4028, loss = 0.00106105\n",
      "Iteration 4029, loss = 0.00106261\n",
      "Iteration 4030, loss = 0.00105979\n",
      "Iteration 4031, loss = 0.00106257\n",
      "Iteration 4032, loss = 0.00106379\n",
      "Iteration 4033, loss = 0.00105850\n",
      "Iteration 4034, loss = 0.00106501\n",
      "Iteration 4035, loss = 0.00106187\n",
      "Iteration 4036, loss = 0.00106065\n",
      "Iteration 4037, loss = 0.00106209\n",
      "Iteration 4038, loss = 0.00106135\n",
      "Iteration 4039, loss = 0.00105906\n",
      "Iteration 4040, loss = 0.00105791\n",
      "Iteration 4041, loss = 0.00105943\n",
      "Iteration 4042, loss = 0.00105690\n",
      "Iteration 4043, loss = 0.00105768\n",
      "Iteration 4044, loss = 0.00105632\n",
      "Iteration 4045, loss = 0.00105695\n",
      "Iteration 4046, loss = 0.00105615\n",
      "Iteration 4047, loss = 0.00105525\n",
      "Iteration 4048, loss = 0.00105651\n",
      "Iteration 4049, loss = 0.00105377\n",
      "Iteration 4050, loss = 0.00105531\n",
      "Iteration 4051, loss = 0.00105630\n",
      "Iteration 4052, loss = 0.00105457\n",
      "Iteration 4053, loss = 0.00105533\n",
      "Iteration 4054, loss = 0.00105815\n",
      "Iteration 4055, loss = 0.00105656\n",
      "Iteration 4056, loss = 0.00105474\n",
      "Iteration 4057, loss = 0.00105397\n",
      "Iteration 4058, loss = 0.00105536\n",
      "Iteration 4059, loss = 0.00105257\n",
      "Iteration 4060, loss = 0.00105277\n",
      "Iteration 4061, loss = 0.00105378\n",
      "Iteration 4062, loss = 0.00105312\n",
      "Iteration 4063, loss = 0.00105230\n",
      "Iteration 4064, loss = 0.00105168\n",
      "Iteration 4065, loss = 0.00105186\n",
      "Iteration 4066, loss = 0.00105116\n",
      "Iteration 4067, loss = 0.00105011\n",
      "Iteration 4068, loss = 0.00105191\n",
      "Iteration 4069, loss = 0.00105130\n",
      "Iteration 4070, loss = 0.00104909\n",
      "Iteration 4071, loss = 0.00105069\n",
      "Iteration 4072, loss = 0.00105292\n",
      "Iteration 4073, loss = 0.00104855\n",
      "Iteration 4074, loss = 0.00105090\n",
      "Iteration 4075, loss = 0.00105191\n",
      "Iteration 4076, loss = 0.00105344\n",
      "Iteration 4077, loss = 0.00104795\n",
      "Iteration 4078, loss = 0.00105247\n",
      "Iteration 4079, loss = 0.00104928\n",
      "Iteration 4080, loss = 0.00104672\n",
      "Iteration 4081, loss = 0.00104875\n",
      "Iteration 4082, loss = 0.00104699\n",
      "Iteration 4083, loss = 0.00104935\n",
      "Iteration 4084, loss = 0.00104741\n",
      "Iteration 4085, loss = 0.00104743\n",
      "Iteration 4086, loss = 0.00104521\n",
      "Iteration 4087, loss = 0.00104649\n",
      "Iteration 4088, loss = 0.00104317\n",
      "Iteration 4089, loss = 0.00104454\n",
      "Iteration 4090, loss = 0.00104365\n",
      "Iteration 4091, loss = 0.00104357\n",
      "Iteration 4092, loss = 0.00104302\n",
      "Iteration 4093, loss = 0.00104317\n",
      "Iteration 4094, loss = 0.00104211\n",
      "Iteration 4095, loss = 0.00104297\n",
      "Iteration 4096, loss = 0.00104276\n",
      "Iteration 4097, loss = 0.00104046\n",
      "Iteration 4098, loss = 0.00104209\n",
      "Iteration 4099, loss = 0.00104384\n",
      "Iteration 4100, loss = 0.00104984\n",
      "Iteration 4101, loss = 0.00104328\n",
      "Iteration 4102, loss = 0.00104372\n",
      "Iteration 4103, loss = 0.00104504\n",
      "Iteration 4104, loss = 0.00104161\n",
      "Iteration 4105, loss = 0.00104126\n",
      "Iteration 4106, loss = 0.00104011\n",
      "Iteration 4107, loss = 0.00103947\n",
      "Iteration 4108, loss = 0.00103970\n",
      "Iteration 4109, loss = 0.00103885\n",
      "Iteration 4110, loss = 0.00103852\n",
      "Iteration 4111, loss = 0.00103931\n",
      "Iteration 4112, loss = 0.00103807\n",
      "Iteration 4113, loss = 0.00103759\n",
      "Iteration 4114, loss = 0.00103702\n",
      "Iteration 4115, loss = 0.00103664\n",
      "Iteration 4116, loss = 0.00103872\n",
      "Iteration 4117, loss = 0.00103703\n",
      "Iteration 4118, loss = 0.00103633\n",
      "Iteration 4119, loss = 0.00103610\n",
      "Iteration 4120, loss = 0.00103552\n",
      "Iteration 4121, loss = 0.00103453\n",
      "Iteration 4122, loss = 0.00103498\n",
      "Iteration 4123, loss = 0.00103556\n",
      "Iteration 4124, loss = 0.00103476\n",
      "Iteration 4125, loss = 0.00103555\n",
      "Iteration 4126, loss = 0.00103508\n",
      "Iteration 4127, loss = 0.00103526\n",
      "Iteration 4128, loss = 0.00103440\n",
      "Iteration 4129, loss = 0.00103396\n",
      "Iteration 4130, loss = 0.00103425\n",
      "Iteration 4131, loss = 0.00103203\n",
      "Iteration 4132, loss = 0.00103430\n",
      "Iteration 4133, loss = 0.00103313\n",
      "Iteration 4134, loss = 0.00103636\n",
      "Iteration 4135, loss = 0.00103475\n",
      "Iteration 4136, loss = 0.00103312\n",
      "Iteration 4137, loss = 0.00104074\n",
      "Iteration 4138, loss = 0.00104543\n",
      "Iteration 4139, loss = 0.00103303\n",
      "Iteration 4140, loss = 0.00103688\n",
      "Iteration 4141, loss = 0.00104043\n",
      "Iteration 4142, loss = 0.00103703\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(activation='logistic', alpha=0.001, batch_size=256, beta_1=0.9,\n              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n              hidden_layer_sizes=(300, 150), learning_rate='adaptive',\n              learning_rate_init=0.001, max_fun=15000, max_iter=5000,\n              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n              tol=1e-08, validation_fraction=0.1, verbose=True,\n              warm_start=False)"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.81%\n"
     ]
    }
   ],
   "source": [
    "# predict 25% of data to measure how good we are\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we save the model\n",
    "# make result directory if doesn't exist yet\n",
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "pickle.dump(model, open(\"result/mlp_classifier.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}